# main.py

import os
import sys
import json
import argparse
import logging
import traceback
import math
import random
import re
import numpy as np
from pathlib import Path
from collections import defaultdict, Counter

# Аудио библиотеки
from pydub import AudioSegment, effects
import soundfile as sf
import librosa

# Локальные модули
from config import Config
from smart_mixer import smart_mix
from musicgen_wrapper import generate_music
from self_check import verify_mix

# Настройка логирования
logging.basicConfig(
    level=logging.INFO, 
    format='[%(levelname)s] %(asctime)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('wavedream.log', encoding='utf-8')
    ]
)

# === ЖАНРОВАЯ ДЕТЕКЦИЯ (из старого стека) ===
GENRE_INFO = {
    "trap": {
        "bpm": (130, 150), 
        "core_instruments": ["kick", "snare", "808", "trap_hat"],
        "optional_instruments": ["bell", "lead_synth", "vocal_fx", "clap"],
        "default_tags": ["808", "clap", "trap_hat", "hi-hat", "urban", "drill", "dirty south"],
        "mastering_style": "punchy_aggressive"
    },
    "phonk": {
        "bpm": (85, 115), 
        "core_instruments": ["kick_808", "snare", "phonk_cowbell"],
        "optional_instruments": ["vinyl_fx", "sub", "choir"],
        "default_tags": ["808", "cowbell", "vinyl_fx", "memphis", "slowed"],
        "mastering_style": "vintage_gritty"
    },
    "lofi": {
        "bpm": (60, 80), 
        "core_instruments": ["soft_snare", "rim", "vinyl_fx"],
        "optional_instruments": ["pad", "piano_soft", "hat", "ambience"],
        "default_tags": ["rim", "soft_snare", "vinyl_fx", "lofi", "jazzy", "chillhop"],
        "mastering_style": "warm_cozy"
    },
    "ambient": {
        "bpm": (60, 75), 
        "core_instruments": ["pad", "drone", "texture"],
        "optional_instruments": ["bell", "piano", "fx", "ambience"],
        "default_tags": ["pad", "bell", "reverb_fx", "space", "drone", "meditation"],
        "mastering_style": "spacious_ethereal"
    },
    "edm": {
        "bpm": (120, 128), 
        "core_instruments": ["kick", "snare", "clap"],
        "optional_instruments": ["lead_synth", "riser", "pad", "arp", "bass"],
        "default_tags": ["kick", "clap", "lead_synth", "riser", "festival"],
        "mastering_style": "loud_festival"
    },
    "dnb": {
        "bpm": (170, 180), 
        "core_instruments": ["snare_dnb", "break", "reese_bass"],
        "optional_instruments": ["hat", "fx", "pad"],
        "default_tags": ["break", "reese_bass", "pad", "neurofunk", "industrial"],
        "mastering_style": "tight_punchy"
    },
    "techno": {
        "bpm": (125, 135), 
        "core_instruments": ["kick_techno", "hat", "tech_bass"],
        "optional_instruments": ["ride", "stab", "modular", "fx"],
        "default_tags": ["kick_techno", "hat", "ride", "tech_bass", "modular"],
        "mastering_style": "industrial_clean"
    },
    "house": {
        "bpm": (118, 125), 
        "core_instruments": ["kick", "clap", "hat"],
        "optional_instruments": ["house_loop", "groove", "bass", "pluck"],
        "default_tags": ["clap", "hat", "house_loop", "groove", "bass"],
        "mastering_style": "groovy_warm"
    },
    "cinematic": {
        "bpm": (60, 100), 
        "core_instruments": ["braam", "string_ensemble", "drone"],
        "optional_instruments": ["choir", "impact", "timpani", "texture"],
        "default_tags": ["braam", "string_ensemble", "choir", "impact"],
        "mastering_style": "epic_cinematic"
    },
    "hyperpop": {
        "bpm": (140, 180), 
        "core_instruments": ["glitchcore", "vocal_fx", "distorted"],
        "optional_instruments": ["overprocessed", "808", "lead_synth"],
        "default_tags": ["glitchcore", "overprocessed", "vocal_fx", "distorted"],
        "mastering_style": "hyper_saturated"
    }
}

GENRE_KEYWORDS = {
    "trap": [
        "trap", "dark trap", "drill", "cloud trap", "memphis", "southern trap", "trap metal", "emo trap",
        "rage trap", "russian trap", "pluggnb", "hypertrap", "грязный", "уличный", "дерзкий", "злой", 
        "агрессивный", "угрожающий", "жёсткий", "мрачный", "банда", "стрелка", "воронка", "гангста", "гетто"
    ],
    "phonk": [
        "phonk", "фанк", "memphis rap", "cowbell phonk", "drift phonk", "underground phonk",
        "олдскул", "грязный", "лоуфай", "уличный стиль", "ретро вайб", "напряжение", "разгон", "агрессия"
    ],
    "lofi": [
        "lofi", "lo-fi", "лоуфай", "лоу фай", "чилаут", "chillhop", "jazzhop", "sleep beats", "study beats", 
        "инди хип-хоп", "lazy beats", "dreamhop", "slowhop", "уют", "тепло", "кружка чая", "окно", "дождь", 
        "ночной город", "расслабление", "лампа", "вечер", "под одеялом", "шорохи", "потрескивание", "мягкий", 
        "спокойствие", "меланхолия"
    ],
    "dnb": [
        "dnb", "drum and bass", "драм", "драм-н-бэйс", "neurofunk", "liquid funk", "techstep",
        "jump up", "rollers", "atmospheric dnb", "intelligent dnb", "jungle", "джангл", "darkstep",
        "halftime", "hard dnb", "rough", "raw", "neuro", "разгон", "динамика", "теншн"
    ],
    "ambient": [
        "ambient", "эмбиент", "саундскейп", "drone", "meditation music", "space ambient", "textural ambient",
        "deep ambient", "slow wave", "soundscape", "nature ambient", "dark ambient", "liquid ambient",
        "тишина", "океан", "вода", "море", "космос", "звёзды", "время", "вечность", "покой", 
        "медитация", "безмятежность", "пространство", "ничто", "плавность", "сон", "отражение"
    ],
    "techno": [
        "techno", "техно", "acid", "industrial techno", "minimal techno", "hard techno", "raw", 
        "warehouse", "detroit techno", "hypnotic", "berghain", "underground", "плотно", "цифровой", 
        "техничный", "роботизированный", "механика", "строгий", "сухой", "массивный", "бесконечный ритм"
    ],
    "house": [
        "house", "deep house", "tech house", "progressive house", "chicago house", "french house",
        "groove", "кач", "вечеринка", "клуб", "пляж", "дискотека", "танец", "энергия", 
        "драйв", "hypnotic rhythm", "качает", "фанк", "соул вайб"
    ],
    "cinematic": [
        "cinematic", "саундтрек", "score", "film score", "epic", "orchestral", "trailer music", 
        "soundtrack", "drama score", "ambient score", "hybrid score", "fantasy music", "sci-fi music",
        "битва", "героизм", "вдохновение", "печаль", "опасность", "поворот сюжета", "развязка", 
        "напряжение", "мгновение", "катарсис", "величие", "трагизм", "мистика", "глубина"
    ],
    "edm": [
        "edm", "electronic dance music", "festival", "big room", "progressive", "electro house",
        "энергия", "фестиваль", "танцпол", "драйв", "массовость", "эйфория", "подъём"
    ],
    "hyperpop": [
        "hyperpop", "glitchcore", "digicore", "breakcore", "speedcore", "pc music",
        "гиперпоп", "глитчкор", "дисторшн", "перегруз", "хаотично", "агрессивно", "экспериментально"
    ]
}

def detect_genre(prompt: str):
    """Детекция жанра из промпта"""
    prompt_lower = prompt.lower()
    
    # 1. Прямое совпадение жанра
    for genre in GENRE_INFO.keys():
        if genre in prompt_lower:
            logging.info(f"🎭 Прямое совпадение жанра: {genre}")
            return genre, GENRE_INFO[genre]
    
    # 2. Совпадение по ключевым словам
    genre_scores = {}
    for genre, keywords in GENRE_KEYWORDS.items():
        score = sum(1 for keyword in keywords if keyword in prompt_lower)
        if score > 0:
            genre_scores[genre] = score
    
    if genre_scores:
        best_genre = max(genre_scores, key=genre_scores.get)
        logging.info(f"🎯 Детектированный жанр: {best_genre} (score: {genre_scores[best_genre]})")
        return best_genre, GENRE_INFO[best_genre]
    
    # 3. Попытка по BPM
    bpm_match = re.findall(r'\b(\d{2,3})\s*bpm\b', prompt_lower)
    if bpm_match:
        target_bpm = int(bpm_match[0])
        best_genre = None
        min_diff = float('inf')
        
        for genre, info in GENRE_INFO.items():
            bpm_range = info["bpm"]
            avg_bpm = (bpm_range[0] + bpm_range[1]) / 2
            diff = abs(avg_bpm - target_bpm)
            if diff < min_diff:
                min_diff = diff
                best_genre = genre
        
        if best_genre:
            logging.info(f"🎵 Жанр по BPM {target_bpm}: {best_genre}")
            return best_genre, GENRE_INFO[best_genre]
    
    # 4. Фолбэк
    logging.warning("⚠️ Жанр не определён, используется trap как дефолт")
    return "trap", GENRE_INFO["trap"]

# === РАСШИРЕННЫЕ ИНСТРУМЕНТАЛЬНЫЕ ТЕГИ ===
INSTRUMENT_TO_TAGS = {
    "kick": ["kick", "hard_kick", "low_drum", "bd", "bass_drum"],
    "snare": ["snare", "tight_snare", "snappy", "snr"],
    "trap_hat": ["trap_hat", "rolling_hat", "rapid_hat", "hat", "hi_hat"],
    "808": ["808", "sub_bass", "deep", "sub"],
    "clap": ["clap", "sharp_clap"],
    "bell": ["bell", "chime", "glockenspiel", "trap_bell", "dark_bell"],
    "lead_synth": ["lead", "synth", "melody", "lead_synth"],
    "vocal_fx": ["vocal_fx", "processed_vocal", "vox", "vocal"],
    "piano": ["piano", "keys", "soft_piano", "felt_piano"],
    "pad": ["pad", "ambient", "texture", "analog_pad", "warm_pad"],
    "fx": ["fx", "effect", "noise", "sweep", "impact", "reverse"],
    "bass": ["bass", "electric_bass", "low", "bassline"],
    "phonk_cowbell": ["cowbell", "phonk_cowbell", "memphis"],
    "vinyl_fx": ["vinyl", "lofi_texture", "crackle", "vinyl_fx"],
    "drone": ["drone", "low", "ambience", "ambient_drone"],
    "texture": ["texture", "grain", "soundscape", "background"],
    "braam": ["braam", "low_hit", "epic", "cinematic_hit"],
    "string_ensemble": ["string_ensemble", "orchestra", "strings", "violin", "cello"],
    "choir": ["choir", "choral", "voices", "male_choir", "female_choir"],
    "reese_bass": ["reese", "bass", "neuro", "reese_bass"],
    "break": ["break", "drum_break", "amen", "breakbeat"],
    "snare_dnb": ["dnb_snare", "crack_snare", "fast_snare", "snare_dnb"],
    "kick_techno": ["techno_kick", "punchy_kick", "deep_kick", "kick_techno"],
    "tech_bass": ["tech_bass", "rolling_bass", "techno_bass"],
    "modular": ["modular", "modular_synth", "analog", "eurorack"],
    "house_loop": ["house_loop", "groove_loop", "percussive_loop"],
    "pluck": ["pluck", "synth_pluck", "short", "house_pluck"]
}

def expand_instrument_tags(instrument):
    """Расширение тегов инструмента"""
    return INSTRUMENT_TO_TAGS.get(instrument, [instrument])

class EnhancedSamplePicker:
    """Улучшенная система подбора сэмплов с семантическим анализом и жанровой детекцией"""
    
    def __init__(self, sample_dir, index_file="enhanced_sample_index.json"):
        self.sample_dir = sample_dir
        self.index_file = os.path.join(sample_dir, index_file)
        self.config = Config()
        
        # Семантическая карта расширенная
        self.semantic_map = {**self.config.SEMANTIC_MAP, **INSTRUMENT_TO_TAGS}
        self.genre_settings = GENRE_INFO
        
        self.index = self.load_or_build_index()
    
    def analyze_filename_advanced(self, filename):
        """Продвинутый анализ имени файла с жанровой привязкой"""
        name = filename.lower()
        tags = set()
        bpm = 120
        key = None
        
        # Извлечение BPM
        bpm_patterns = [r'(\d{2,3})bpm', r'(\d{2,3})_bpm', r'bpm(\d{2,3})', r'(\d{2,3})bp']
        for pattern in bpm_patterns:
            match = re.search(pattern, name)
            if match:
                bpm = int(match.group(1))
                break
        
        # Извлечение тональности
        key_patterns = [r'([A-G][#b]?)_?maj', r'([A-G][#b]?)_?min', r'key_([A-G][#b]?)', r'([A-G][#b]?)_key']
        for pattern in key_patterns:
            match = re.search(pattern, name)
            if match:
                key = match.group(1).upper()
                break
        
        # Семантический анализ через расширенную карту
        for instrument, synonyms in self.semantic_map.items():
            if isinstance(synonyms, list):
                for synonym in synonyms:
                    if synonym in name:
                        tags.add(instrument)
                        break
            elif isinstance(synonyms, dict):
                for synonym in synonyms.get("synonyms", []):
                    if synonym in name:
                        tags.add(instrument)
                        tags.update(synonyms.get("related", []))
                        break
        
        # Жанровые теги из имени файла
        for genre, keywords in GENRE_KEYWORDS.items():
            for keyword in keywords[:5]:  # Берём только первые 5 ключевых слов
                if keyword in name:
                    tags.add(f"genre_{genre}")
                    break
        
        return list(tags), bpm, key
    
    def analyze_audio_content(self, file_path, max_duration=10):
        """Анализ аудиоконтента с улучшенной детекцией"""
        try:
            y, sr = librosa.load(file_path, duration=max_duration, sr=22050)
            
            # Анализ темпа
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            tempo = float(tempo)
            
            # Анализ тональности
            chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
            if chroma.size > 0:
                chroma_mean = chroma.mean(axis=1)
                key_idx = chroma_mean.argmax()
                keys = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
                key = keys[key_idx]
            else:
                key = None
            
            # Спектральные характеристики
            spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr).mean()
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr).mean()
            zero_crossing_rate = librosa.feature.zero_crossing_rate(y).mean()
            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            
            # Определение типа контента
            content_tags = []
            
            # Классификация по частотному спектру
            if spectral_centroid < 800:
                content_tags.extend(["bass", "kick", "sub", "808"])
            elif spectral_centroid < 2000:
                content_tags.extend(["snare", "mid_freq", "vocal"])
            elif spectral_centroid < 8000:
                content_tags.extend(["lead", "melody", "synth"])
            else:
                content_tags.extend(["hihat", "cymbal", "fx", "bright"])
            
            # Ритмические характеристики
            if zero_crossing_rate > 0.15:
                content_tags.extend(["percussion", "rhythmic", "transient"])
            elif zero_crossing_rate < 0.05:
                content_tags.extend(["sustained", "pad", "drone"])
            
            # Определение loop vs oneshot
            duration_sec = len(y) / sr
            if duration_sec > 8:
                content_tags.append("loop")
            else:
                content_tags.append("oneshot")
            
            # MFCC-анализ для дополнительной классификации
            mfcc_mean = mfcc.mean(axis=1)
            if mfcc_mean[1] > 50:  # Первый коэффициент после энергии
                content_tags.append("bright_timbre")
            elif mfcc_mean[1] < -50:
                content_tags.append("dark_timbre")
            
            return {
                "tempo": max(60, min(200, tempo)),
                "key": key,
                "content_tags": content_tags,
                "spectral_centroid": float(spectral_centroid),
                "brightness": float(spectral_rolloff / sr),
                "rhythmic_complexity": float(zero_crossing_rate),
                "duration": duration_sec
            }
        except Exception as e:
            logging.warning(f"Ошибка анализа {file_path}: {e}")
            return {"tempo": 120, "key": None, "content_tags": [], "spectral_centroid": 0, "brightness": 0, "rhythmic_complexity": 0, "duration": 0}
    
    def build_enhanced_index(self):
        """Построение индекса сэмплов с жанровой привязкой"""
        logging.info("🔍 Начинаю расширенную индексацию сэмплов...")
        enhanced_index = []
        processed = 0
        
        for root, _, files in os.walk(self.sample_dir):
            for file in files:
                if file.lower().endswith(('.wav', '.mp3', '.aiff', '.flac')):
                    full_path = os.path.join(root, file)
                    try:
                        # Базовая информация
                        audio = AudioSegment.from_file(full_path)
                        duration = len(audio) / 1000
                        
                        # Анализ имени файла
                        filename_tags, filename_bpm, filename_key = self.analyze_filename_advanced(file)
                        
                        # Анализ аудиоконтента
                        audio_analysis = self.analyze_audio_content(full_path)
                        
                        # Объединение результатов
                        final_bpm = filename_bpm if filename_bpm != 120 else audio_analysis["tempo"]
                        final_key = filename_key or audio_analysis["key"]
                        all_tags = list(set(filename_tags + audio_analysis["content_tags"]))
                        
                        # Определение категории
                        category = "loop" if duration > 8 else "oneshot"
                        if "loop" in filename_tags or "loop" in file.lower():
                            category = "loop"
                        
                        # Жанровая классификация по пути
                        path_lower = full_path.lower()
                        detected_genres = []
                        for genre, keywords in GENRE_KEYWORDS.items():
                            for keyword in keywords[:3]:  # Топ-3 ключевых слова
                                if keyword in path_lower:
                                    detected_genres.append(genre)
                                    break
                        
                        entry = {
                            "path": full_path,
                            "filename": file,
                            "tempo": round(final_bpm),
                            "duration": round(duration, 3),
                            "key": final_key,
                            "category": category,
                            "tags": all_tags,
                            "genres": detected_genres,
                            "spectral_centroid": audio_analysis["spectral_centroid"],
                            "brightness": audio_analysis["brightness"],
                            "rhythmic_complexity": audio_analysis.get("rhythmic_complexity", 0),
                            "relative_path": os.path.relpath(full_path, self.sample_dir)
                        }
                        
                        enhanced_index.append(entry)
                        processed += 1
                        
                        if processed % 50 == 0:
                            logging.info(f"✅ Обработано: {processed} файлов")
                    
                    except Exception as e:
                        logging.warning(f"⚠️ Ошибка обработки {file}: {e}")
        
        logging.info(f"🎯 Расширенная индексация завершена: {len(enhanced_index)} сэмплов")
        return enhanced_index
    
    def load_or_build_index(self):
        """Загрузка или создание индекса"""
        if os.path.exists(self.index_file):
            try:
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    index = json.load(f)
                logging.info(f"📚 Загружен расширенный индекс: {len(index)} сэмплов")
                return index
            except Exception as e:
                logging.warning(f"⚠️ Ошибка загрузки индекса: {e}")
        
        # Создаём новый индекс
        index = self.build_enhanced_index()
        self.save_index(index)
        return index
    
    def save_index(self, index):
        """Сохранение индекса"""
        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(index, f, indent=2, ensure_ascii=False)
        logging.info(f"💾 Расширенный индекс сохранён: {self.index_file}")
    
    def score_sample_with_genre(self, sample, query_tags, target_tempo=120, genre_hint=None, mood_hint=None):
        """Расширенная система скоринга с учётом жанра и настроения"""
        score = 0
        sample_tags = sample.get("tags", [])
        sample_tempo = sample.get("tempo", 120)
        sample_genres = sample.get("genres", [])
        
        # 1. Семантический скоринг тегов (50% веса)
        tag_score = 0
        for query_tag in query_tags:
            # Прямое совпадение
            if query_tag in sample_tags:
                tag_score += 10
            else:
                # Семантическое совпадение
                expanded_tags = expand_instrument_tags(query_tag)
                for expanded in expanded_tags:
                    for sample_tag in sample_tags:
                        if expanded in sample_tag or sample_tag in expanded:
                            tag_score += 5
                        elif self.fuzzy_match(expanded, sample_tag):
                            tag_score += 3
        
        if query_tags:
            tag_score = tag_score / len(query_tags)
        score += tag_score * 0.5
        
        # 2. Жанровая совместимость (25% веса)
        genre_score = 0
        if genre_hint:
            if genre_hint in sample_genres:
                genre_score = 25
            elif any(genre_hint[:4] in g for g in sample_genres):
                genre_score = 15
            
            # Проверка по пути файла
            sample_path = sample.get("path", "").lower()
            if genre_hint in sample_path:
                genre_score += 10
        
        score += genre_score * 0.25
        
        # 3. Темповая совместимость (15% веса)
        tempo_diff = abs(sample_tempo - target_tempo)
        if tempo_diff <= 3:
            tempo_score = 20
        elif tempo_diff <= 10:
            tempo_score = 15 - (tempo_diff / 10) * 10
        elif tempo_diff <= 20:
            tempo_score = 5
        else:
            tempo_score = 1
        
        score += tempo_score * 0.15
        
        # 4. Качество и разнообразие (10% веса)
        quality_score = 0
        if len(sample_tags) > 2:
            quality_score += 5
        if sample.get("key"):
            quality_score += 3
        if 1 < sample.get("duration", 0) < 60:
            quality_score += 5
        if sample.get("brightness", 0) > 0:
            quality_score += 2
        
        score += quality_score * 0.1
        
        return score
    
    def fuzzy_match(self, a, b, threshold=0.6):
        """Улучшенное нечёткое сравнение"""
        a, b = a.lower(), b.lower()
        if a == b:
            return True
        if a in b or b in a:
            return True
        
        # Jaccard similarity
        set_a, set_b = set(a), set(b)
        intersection = len(set_a & set_b)
        union = len(set_a | set_b)
        return (intersection / union) > threshold if union > 0 else False
    
    def pick_samples_for_genre_structure(self, section, target_tempo, genre_hint=None, mood_hint=None, top_k=3):
        """Подбор сэмплов для секции с учётом жанра"""
        section_type = section.get("type", "unknown")
        required_instruments = []
        
        # Определяем инструменты для секции по жанру
        if genre_hint in self.genre_settings:
            genre_config = self.genre_settings[genre_hint]
            core_instruments = genre_config.get("core_instruments", [])
            optional_instruments = genre_config.get("optional_instruments", [])
            
            # Базовые инструменты для всех секций
            required_instruments.extend(core_instruments)
            
            # Дополнительные инструменты в зависимости от типа секции
            if section_type in ["hook", "drop", "climax", "peak", "chorus"]:
                required_instruments.extend(optional_instruments)
            elif section_type in ["verse", "build", "development"]:
                required_instruments.extend(optional_instruments[:2])
        else:
            # Дефолтные инструменты
            required_instruments = ["kick", "bass", "lead"]
        
        # Подбираем сэмплы для каждого инструмента
        section_samples = []
        for instrument in required_instruments:
            instrument_tags = expand_instrument_tags(instrument)
            
            instrument_samples = self.pick_samples_enhanced(
                required_tags=instrument_tags,
                target_tempo=target_tempo,
                genre_hint=genre_hint,
                mood_hint=mood_hint,
                top_k=1,
                min_score=3
            )
            
            if instrument_samples:
                best_sample = instrument_samples[0]
                best_sample["instrument_role"] = instrument
                section_samples.append(best_sample)
                logging.info(f"✅ [{section_type}] {instrument}: {best_sample['filename']}")
            else:
                logging.warning(f"⚠️ [{section_type}] Не найден сэмпл для {instrument}")
        
        return section_samples
    
    def pick_samples_enhanced(self, required_tags, target_tempo=120, genre_hint=None, mood_hint=None, top_k=10, min_score=5):
        """Улучшенный подбор сэмплов с жанровой привязкой"""
        if not self.index:
            logging.error("❌ Индекс пуст!")
            return []
        
        # Основной поиск с жанровым скорингом
        matches = []
        for sample in self.index:
            score = self.score_sample_with_genre(
                sample, required_tags, target_tempo, genre_hint, mood_hint
            )
            if score >= min_score:
                matches.append((score, sample))
        
        # Если мало совпадений - смягчаем критерии
        if len(matches) < top_k:
            for sample in self.index:
                if any((score, sample) in matches for score, _ in matches):
                    continue
                score = self.score_sample_with_genre(
                    sample, required_tags, target_tempo, genre_hint, mood_hint
                )
                if score >= min_score * 0.5:
                    matches.append((score, sample))
        
        # Фолбек по жанру и темпу
        if len(matches) < 3 and genre_hint:
            for sample in self.index:
                sample_path = sample.get("path", "").lower()
                sample_tempo = sample.get("tempo", 120)
                sample_genres = sample.get("genres", [])
                
                genre_match = genre_hint in sample_genres or genre_hint in sample_path
                tempo_match = abs(sample_tempo - target_tempo) <= 30
                
                if genre_match or tempo_match:
                    fallback_score = 3 + (10 if genre_match else 0) + (3 if tempo_match else 0)
                    matches.append((fallback_score, sample))
        
        # Сортировка и возврат
        matches.sort(key=lambda x: -x[0])
        return [sample for _, sample in matches[:top_k]]


def query_structured_music(prompt):
    """Запрос к LLaMA3 для получения структуры трека с жанровой детекцией"""
    try:
        import subprocess
        
        # Определяем жанр из промпта
        detected_genre, genre_info = detect_genre(prompt)
        target_bpm = random.randint(*genre_info["bpm"])
        
        # Формируем запрос к LLaMA3 с жанровой информацией
        llama_prompt = f"""
        Create a detailed music track structure for: "{prompt}"
        
        Detected genre: {detected_genre}
        Target BPM range: {genre_info["bpm"][0]}-{genre_info["bpm"][1]}
        Core instruments: {", ".join(genre_info["core_instruments"])}
        
        Return JSON with:
        - tempo (BPM number, prefer {target_bpm})
        - genre (string, use "{detected_genre}")
        - mood (array of strings)
        - structure (array of sections with type, start_time, duration)
        - recommended_instruments (array from genre-specific instruments)
        - mastering_style (string, use "{genre_info["mastering_style"]}")
        
        Structure types for {detected_genre}: intro, verse, hook, bridge, outro, build, drop, break
        Make realistic timing in seconds, total duration should be 60-120 seconds.
        
        Return only valid JSON, no other text.
        """
        
        # Запуск ollama
        result = subprocess.run([
            'ollama', 'run', 'llama3-music'
        ], input=llama_prompt, capture_output=True, text=True, encoding='utf-8')
        
        if result.returncode == 0:
            try:
                # Парсим JSON ответ
                response_text = result.stdout.strip()
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                if start_idx >= 0 and end_idx > start_idx:
                    json_text = response_text[start_idx:end_idx]
                    structure = json.loads(json_text)
                    logging.info(f"✅ Структура получена от LLaMA3 для жанра {detected_genre}")
                    return structure
                else:
                    logging.error("❌ Не найден JSON в ответе LLaMA3")
            except json.JSONDecodeError as e:
                logging.error(f"❌ Ошибка парсинга JSON от LLaMA3: {e}")
        else:
            logging.error(f"❌ Ошибка запуска LLaMA3: {result.stderr}")
    
    except Exception as e:
        logging.error(f"❌ Ошибка запроса к LLaMA3: {e}")
    
    # Фолбек структура с жанровой привязкой
    logging.warning(f"⚠️ Используется фолбек структура для жанра {detected_genre}")
    detected_genre, genre_info = detect_genre(prompt)
    target_bpm = random.randint(*genre_info["bpm"])
    
    return {
        "tempo": target_bpm,
        "genre": detected_genre,
        "mood": ["energetic"],
        "mastering_style": genre_info["mastering_style"],
        "structure": [
            {"type": "intro", "start_time": 0, "duration": 8},
            {"type": "verse", "start_time": 8, "duration": 16},
            {"type": "hook", "start_time": 24, "duration": 16},
            {"type": "verse", "start_time": 40, "duration": 16},
            {"type": "hook", "start_time": 56, "duration": 16},
            {"type": "outro", "start_time": 72, "duration": 8}
        ],
        "recommended_instruments": genre_info["core_instruments"] + genre_info["optional_instruments"][:2]
    }


def query_mastering_prompt(original_prompt, mastering_purpose="personal"):
    """Запрос к LLaMA3 для получения промпта мастеринга"""
    try:
        import subprocess
        
        purpose_descriptions = {
            "freelance": "продажа на заказ через фриланс биржу, коммерческое качество",
            "professional": "профессиональный продакшн в кино индустрии, киношный саундтрек",
            "personal": "для себя, домашнее прослушивание",
            "family": "монтаж для семьи, домашнее видео"
        }
        
        purpose_desc = purpose_descriptions.get(mastering_purpose, "универсальное применение")
        
        llama_prompt = f"""
        Create a mastering and post-processing prompt for music track: "{original_prompt}"
        
        Purpose: {purpose_desc}
        
        Return JSON with modern mastering effects and parameters:
        - eq_settings (object with low, mid, high adjustments)
        - compression (object with ratio, attack, release)
        - reverb (object with type, room_size, wet_level)
        - stereo_enhancement (object with width, imaging)
        - harmonic_enhancement (object with saturation, warmth)
        - limiter (object with threshold, ceiling)
        - creative_fx (array of modern effects like "tape_saturation", "vintage_compressor", "stereo_imaging")
        - overall_character (string describing the mastering approach)
        
        Make it sound professional and modern for {purpose_desc}.
        Return only valid JSON, no other text.
        """
        
        result = subprocess.run([
            'ollama', 'run', 'llama3-music'
        ], input=llama_prompt, capture_output=True, text=True, encoding='utf-8')
        
        if result.returncode == 0:
            try:
                response_text = result.stdout.strip()
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                if start_idx >= 0 and end_idx > start_idx:
                    json_text = response_text[start_idx:end_idx]
                    mastering_config = json.loads(json_text)
                    logging.info(f"✅ Конфиг мастеринга получен для цели: {mastering_purpose}")
                    return mastering_config
            except json.JSONDecodeError as e:
                logging.error(f"❌ Ошибка парсинга JSON мастеринга: {e}")
        else:
            logging.error(f"❌ Ошибка запуска LLaMA3 для мастеринга: {result.stderr}")
    
    except Exception as e:
        logging.error(f"❌ Ошибка запроса мастеринга к LLaMA3: {e}")
    
    # Фолбек конфиг мастеринга
    logging.warning("⚠️ Используется фолбек конфиг мастеринга")
    fallback_configs = {
        "freelance": {
            "eq_settings": {"low": 2, "mid": 0, "high": 3},
            "compression": {"ratio": 3.5, "attack": 5, "release": 100},
            "reverb": {"type": "hall", "room_size": 0.3, "wet_level": 0.15},
            "stereo_enhancement": {"width": 120, "imaging": "enhanced"},
            "harmonic_enhancement": {"saturation": "tube", "warmth": 0.3},
            "limiter": {"threshold": -1.5, "ceiling": -0.1},
            "creative_fx": ["tape_saturation", "vintage_compressor", "stereo_imaging"],
            "overall_character": "punchy commercial sound with modern loudness"
        },
        "professional": {
            "eq_settings": {"low": 1, "mid": -0.5, "high": 2},
            "compression": {"ratio": 2.5, "attack": 10, "release": 150},
            "reverb": {"type": "cinematic_hall", "room_size": 0.7, "wet_level": 0.25},
            "stereo_enhancement": {"width": 110, "imaging": "natural"},
            "harmonic_enhancement": {"saturation": "analog", "warmth": 0.4},
            "limiter": {"threshold": -3, "ceiling": -0.5},
            "creative_fx": ["analog_console", "tape_compression", "tube_warmth"],
            "overall_character": "cinematic professional sound with depth and space"
        },
        "personal": {
            "eq_settings": {"low": 0, "mid": 0, "high": 1},
            "compression": {"ratio": 2, "attack": 15, "release": 200},
            "reverb": {"type": "room", "room_size": 0.2, "wet_level": 0.1},
            "stereo_enhancement": {"width": 100, "imaging": "natural"},
            "harmonic_enhancement": {"saturation": "clean", "warmth": 0.2},
            "limiter": {"threshold": -6, "ceiling": -1},
            "creative_fx": ["gentle_compression", "smooth_eq"],
            "overall_character": "clean natural sound for home listening"
        },
        "family": {
            "eq_settings": {"low": 3, "mid": 2, "high": 2},
            "compression": {"ratio": 4, "attack": 3, "release": 80},
            "reverb": {"type": "bright_room", "room_size": 0.25, "wet_level": 0.12},
            "stereo_enhancement": {"width": 115, "imaging": "wide"},
            "harmonic_enhancement": {"saturation": "bright", "warmth": 0.25},
            "limiter": {"threshold": -2, "ceiling": -0.2},
            "creative_fx": ["brightness_enhancer", "vocal_clarity", "bass_punch"],
            "overall_character": "bright engaging sound perfect for family content"
        }
    }
    
    return fallback_configs.get(mastering_purpose, fallback_configs["personal"])


def apply_smart_mastering(audio_segment, mastering_config):
    """Применение умного мастеринга на основе конфига от LLaMA3"""
    try:
        logging.info("🎛️ Применяю умный мастеринг...")
        
        # Получаем параметры
        eq_settings = mastering_config.get("eq_settings", {})
        compression = mastering_config.get("compression", {})
        reverb = mastering_config.get("reverb", {})
        stereo_enhancement = mastering_config.get("stereo_enhancement", {})
        harmonic_enhancement = mastering_config.get("harmonic_enhancement", {})
        limiter = mastering_config.get("limiter", {})
        creative_fx = mastering_config.get("creative_fx", [])
        
        mastered = audio_segment
        
        # 1. EQ обработка
        low_gain = eq_settings.get("low", 0)
        mid_gain = eq_settings.get("mid", 0)
        high_gain = eq_settings.get("high", 0)
        
        if low_gain != 0:
            mastered = mastered.low_pass_filter(8000).overlay(
                mastered.high_pass_filter(80) + low_gain
            )
            logging.info(f"  🎚️ Low EQ: {low_gain:+.1f}dB")
        
        if high_gain != 0:
            mastered = mastered.high_pass_filter(80).overlay(
                mastered.low_pass_filter(8000) + high_gain
            )
            logging.info(f"  🎚️ High EQ: {high_gain:+.1f}dB")
        
        # 2. Компрессия (симуляция через нормализацию и лимитирование)
        ratio = compression.get("ratio", 2)
        if ratio > 1:
            # Мягкая компрессия через нормализацию
            peak_level = mastered.max_dBFS
            if peak_level > -6:
                compress_amount = min(6, (peak_level + 6) / ratio)
                mastered = mastered - compress_amount
                logging.info(f"  🗜️ Компрессия: {ratio}:1, снижение {compress_amount:.1f}dB")
        
        # 3. Гармонические улучшения
        saturation_type = harmonic_enhancement.get("saturation", "clean")
        warmth = harmonic_enhancement.get("warmth", 0)
        
        if saturation_type != "clean" and warmth > 0:
            # Симуляция теплоты через очень лёгкое изменение частотного баланса
            warmth_boost = warmth * 2  # dB
            mastered = mastered.low_pass_filter(12000) + warmth_boost
            logging.info(f"  🔥 {saturation_type.title()} saturation: {warmth:.1f}")
        
        # 4. Стерео улучшения
        width = stereo_enhancement.get("width", 100)
        if width != 100:
            # Симуляция через моно/стерео микширование
            if mastered.channels == 2:
                width_factor = width / 100
                if width_factor > 1:
                    # Расширение стерео
                    logging.info(f"  🎭 Стерео расширение: {width}%")
                elif width_factor < 1:
                    # Сужение стерео
                    mono_component = mastered.set_channels(1).set_channels(2)
                    mastered = mastered.overlay(mono_component - 6)
                    logging.info(f"  🎭 Стерео сужение: {width}%")
        
        # 5. Лимитирование
        threshold = limiter.get("threshold", -3)
        ceiling = limiter.get("ceiling", -0.1)
        
        if mastered.max_dBFS > threshold:
            # Мягкое лимитирование
            over_threshold = mastered.max_dBFS - threshold
            if over_threshold > 0:
                limit_reduction = min(over_threshold * 0.7, mastered.max_dBFS - ceiling)
                mastered = mastered - limit_reduction
                logging.info(f"  🚧 Лимитер: порог {threshold}dB, потолок {ceiling}dB")
        
        # 6. Креативные эффекты
        for fx in creative_fx:
            if "tape" in fx.lower():
                # Симуляция ленточного насыщения
                mastered = mastered + 0.5  # Лёгкий подъём
                logging.info(f"  📼 {fx}")
            elif "vintage" in fx.lower():
                # Винтажная обработка
                mastered = mastered.high_pass_filter(60).low_pass_filter(15000)
                logging.info(f"  🕰️ {fx}")
            elif "stereo" in fx.lower():
                # Стерео обработка
                logging.info(f"  🎵 {fx}")
            elif "brightness" in fx.lower():
                # Яркость
                mastered = mastered.high_pass_filter(100) + 1
                logging.info(f"  ✨ {fx}")
            elif "bass" in fx.lower():
                # Басовый удар
                mastered = mastered.low_pass_filter(200) + 1.5
                logging.info(f"  🥁 {fx}")
        
        # 7. Финальная нормализация
        target_level = -1 if "freelance" in str(mastering_config) else -3
        if mastered.max_dBFS < target_level - 6:
            normalize_gain = target_level - mastered.max_dBFS - 1
            mastered = mastered + normalize_gain
            logging.info(f"  📊 Финальная нормализация: {normalize_gain:+.1f}dB до {target_level}dB")
        
        character = mastering_config.get("overall_character", "professional mastering")
        logging.info(f"✅ Мастеринг завершён: {character}")
        
        return mastered
        
    except Exception as e:
        logging.error(f"❌ Ошибка мастеринга: {e}")
        # Фолбек - простая нормализация
        return effects.normalize(audio_segment)


class WaveDreamLauncher:
    """Главный лаунчер WaveDream Enhanced с жанровой детекцией и умным мастерингом"""
    
    def __init__(self):
        self.config = Config()
        self.setup_logging()
    
    def setup_logging(self):
        """Настройка логирования"""
        logging.basicConfig(
            level=getattr(logging, self.config.LOGGING["level"]),
            format=self.config.LOGGING["format"],
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler(self.config.LOGGING["file"], encoding='utf-8')
            ]
        )
    
    def run_enhanced_full_chain(self, prompt, sample_dir, output_dir, mastering_purpose="personal", export_stems=False):
        """
        Расширенная цепочка: LLaMA3 → MusicGen → Stem Mix → Merged → MusicGen Fix → Smart Mastering
        """
        os.makedirs(output_dir, exist_ok=True)
        
        logging.info(f"\n🚀 Запуск расширенной цепочки генерации")
        logging.info(f"📝 Промпт: '{prompt}'")
        logging.info(f"🎯 Назначение: {mastering_purpose}")
        logging.info(f"📁 Сэмплы: {sample_dir}")
        logging.info(f"📁 Вывод: {output_dir}")
        
        try:
            # === 1. Детекция жанра из промпта ===
            detected_genre, genre_info = detect_genre(prompt)
            logging.info(f"🎭 Детектированный жанр: {detected_genre}")
            logging.info(f"🎵 BPM диапазон: {genre_info['bpm']}")
            logging.info(f"🎛️ Стиль мастеринга: {genre_info['mastering_style']}")
            
            # === 2. Получение структуры от LLaMA3 с жанровой привязкой ===
            logging.info("🧠 Запрос жанровой структуры к LLaMA3...")
            structure_data = query_structured_music(prompt)
            
            # Сохраняем структуру
            structure_path = os.path.join(output_dir, "enhanced_structure.json")
            structure_data["detected_genre"] = detected_genre
            structure_data["genre_info"] = genre_info
            
            with open(structure_path, "w", encoding="utf-8") as f:
                json.dump(structure_data, f, indent=2, ensure_ascii=False)
            logging.info(f"📄 Жанровая структура сохранена: {structure_path}")
            
            tempo = structure_data.get("tempo", random.randint(*genre_info["bpm"]))
            genre = structure_data.get("genre", detected_genre)
            structure = structure_data.get("structures", [])
            mastering_style = structure_data.get("mastering_style", genre_info["mastering_style"])
            
            # Расчет общей длительности
            total_duration = max([s.get("start_time", 0) + s.get("duration", 0) for s in structure])
            if total_duration < 30:
                total_duration = 60
            
            logging.info(f"🎵 Темп: {tempo} BPM, Жанр: {genre}, Длительность: {total_duration}с")
            
            # === 3. Генерация основы через MusicGen ===
            logging.info("🎼 Генерация жанровой основы через MusicGen...")
            genre_enhanced_prompt = f"{prompt} {genre} style {tempo}bpm {mastering_style}"
            musicgen_wav, sr = generate_music(genre_enhanced_prompt, duration=total_duration)
            musicgen_path = os.path.join(output_dir, "01_musicgen_genre_base.wav")
            sf.write(musicgen_path, musicgen_wav.squeeze().numpy(), sr, format="WAV")
            
            # Загружаем как AudioSegment
            musicgen_base = AudioSegment.from_wav(musicgen_path)
            logging.info(f"✅ MusicGen жанровая основа: {len(musicgen_base)/1000:.1f}с")
            
            # === 4. Создание жанрового Stem Mix ===
            logging.info(f"🔍 Создание жанрового Stem Mix для {genre}...")
            sample_picker = EnhancedSamplePicker(sample_dir)
            
            # Создаём пустой stem mix
            stem_mix = AudioSegment.silent(duration=len(musicgen_base))
            used_samples = []
            
            # Обрабатываем каждую секцию структуры с жанровой привязкой
            for section in structure:
                section_type = section.get("type", "unknown")
                start_time = section.get("start_time", 0)
                duration = section.get("duration", 8)
                
                start_ms = int(start_time * 1000)
                duration_ms = int(duration * 1000)
                
                logging.info(f"🎯 {genre.title()} секция [{section_type}]: {start_time}с -> {duration}с")
                
                # Подбираем сэмплы для секции с жанровой привязкой
                section_samples = sample_picker.pick_samples_for_genre_structure(
                    section, tempo, genre, mood_hint=structure_data.get("mood", [])
                )
                
                # Размещаем сэмплы в stem mix
                for sample_info in section_samples:
                    try:
                        sample_path = sample_info["path"]
                        instrument_role = sample_info.get("instrument_role", "unknown")
                        
                        # Загружаем сэмпл
                        sample_audio = AudioSegment.from_file(sample_path)
                        
                        # Подгоняем длительность под секцию
                        if sample_info.get("category") == "loop":
                            # Для лупов - зацикливаем или обрезаем
                            if len(sample_audio) < duration_ms:
                                repeats = (duration_ms // len(sample_audio)) + 1
                                sample_audio = (sample_audio * repeats)[:duration_ms]
                            else:
                                sample_audio = sample_audio[:duration_ms]
                        else:
                            # Для one-shots - размещаем как есть + тишина если нужно
                            if len(sample_audio) > duration_ms:
                                sample_audio = sample_audio[:duration_ms]
                            elif len(sample_audio) < duration_ms:
                                pad_duration = duration_ms - len(sample_audio)
                                sample_audio += AudioSegment.silent(duration=pad_duration)
                        
                        # Применяем жанро-специфичные volume настройки
                        genre_volume_map = {
                            "trap": {"kick": -2, "808": -2, "snare": -4, "trap_hat": -8, "bell": -10},
                            "phonk": {"kick_808": -1, "snare": -5, "phonk_cowbell": -6, "vinyl_fx": -12},
                            "lofi": {"soft_snare": -8, "rim": -10, "vinyl_fx": -15, "piano_soft": -6},
                            "dnb": {"snare_dnb": -3, "reese_bass": -2, "break": -4, "pad": -10},
                            "techno": {"kick_techno": -1, "tech_bass": -3, "hat": -8, "modular": -8},
                            "house": {"kick": -2, "clap": -5, "hat": -8, "pluck": -6},
                            "ambient": {"pad": -6, "drone": -8, "texture": -12, "bell": -10},
                            "cinematic": {"braam": -2, "string_ensemble": -4, "choir": -6, "impact": -3}
                        }
                        
                        volume = genre_volume_map.get(genre, {}).get(instrument_role, -6)
                        sample_audio = sample_audio + volume
                        
                        # Накладываем на stem mix в нужной позиции
                        stem_mix = stem_mix.overlay(sample_audio, position=start_ms)
                        
                        used_samples.append({
                            "section": section_type,
                            "instrument": instrument_role,
                            "file": sample_info["filename"],
                            "genre": genre,
                            "start_time": start_time,
                            "duration": duration,
                            "volume": volume
                        })
                        
                        logging.info(f"  ✅ {instrument_role}: {sample_info['filename']} ({volume:+.1f}dB)")
                    
                    except Exception as e:
                        logging.error(f"  ❌ Ошибка обработки сэмпла: {e}")
            
            # Сохраняем жанровый stem mix
            stem_mix_path = os.path.join(output_dir, f"02_{genre}_stem_mix.wav")
            stem_mix.export(stem_mix_path, format="wav")
            logging.info(f"🎛️ {genre.title()} Stem Mix готов: {stem_mix_path}")
            
            # Сохраняем информацию об использованных сэмплах
            samples_info_path = os.path.join(output_dir, "used_samples_enhanced.json")
            with open(samples_info_path, "w", encoding="utf-8") as f:
                json.dump(used_samples, f, indent=2, ensure_ascii=False)
            
            # === 5. Создание жанрового Merged Mix ===
            logging.info(f"🎚️ Создание {genre.title()} Merged Mix...")
            
            # Жанро-специфичное микширование
            genre_mix_settings = {
                "trap": {"musicgen": -4, "stem": -5},
                "phonk": {"musicgen": -3, "stem": -6},
                "lofi": {"musicgen": -5, "stem": -8},
                "dnb": {"musicgen": -2, "stem": -4},
                "techno": {"musicgen": -3, "stem": -5},
                "house": {"musicgen": -4, "stem": -6},
                "ambient": {"musicgen": -6, "stem": -10},
                "cinematic": {"musicgen": -2, "stem": -4}
            }
            
            mix_settings = genre_mix_settings.get(genre, {"musicgen": -3, "stem": -6})
            
            musicgen_level = mix_settings["musicgen"]
            stem_level = mix_settings["stem"]
            
            merged_mix = (musicgen_base + musicgen_level).overlay(stem_mix + stem_level)
            merged_path = os.path.join(output_dir, f"03_{genre}_merged_mix.wav")
            merged_mix.export(merged_path, format="wav")
            logging.info(f"🔄 {genre.title()} Merged Mix готов: {merged_path}")
            
            # === 6. Финальная генерация через MusicGen (исправлена ошибка guidance_scale) ===
            logging.info("🎨 Финальная обработка через MusicGen...")
            
            # Создаём улучшенный промпт на основе merged mix (БЕЗ guidance_scale!)
            final_prompt = f"{prompt} {genre} professional mix mastered high quality {mastering_style}"
            
            final_musicgen_wav, sr = generate_music(
                final_prompt, 
                duration=total_duration
                # Убираем guidance_scale - его нет в функции!
            )
            
            final_base_path = os.path.join(output_dir, "04_final_musicgen_fix.wav")
            sf.write(final_base_path, final_musicgen_wav.squeeze().numpy(), sr, format="WAV")
            logging.info(f"🎼 Финальная MusicGen обработка: {final_base_path}")
            
            # === 7. НОВЫЙ ЭТАП: Запрос второго промпта для мастеринга ===
            logging.info("🎤 Запрос конфига мастеринга к LLaMA3...")
            mastering_config = query_mastering_prompt(prompt, mastering_purpose)
            
            # Сохраняем конфиг мастеринга
            mastering_config_path = os.path.join(output_dir, "mastering_config.json")
            with open(mastering_config_path, "w", encoding="utf-8") as f:
                json.dump(mastering_config, f, indent=2, ensure_ascii=False)
            logging.info(f"📋 Конфиг мастеринга сохранён: {mastering_config_path}")
            
            # === 8. НОВЫЙ ЭТАП: Умный мастеринг ===
            logging.info("🎛️ Применение умного мастеринга...")
            
            # Загружаем финальный микс для мастеринга
            final_for_mastering = AudioSegment.from_wav(final_base_path)
            
            # Применяем умный мастеринг на основе конфига от LLaMA3
            mastered_track = apply_smart_mastering(final_for_mastering, mastering_config)
            
            # Сохраняем мастерированный трек
            final_mastered_path = os.path.join(output_dir, f"05_FINAL_{genre}_{mastering_purpose}_MASTERED.wav")
            mastered_track.export(final_mastered_path, format="wav")
            logging.info(f"🎉 Мастерированный трек готов: {final_mastered_path}")
            
            # === 9. Верификация ===
            logging.info("🔍 Верификация мастерированного результата...")
            verification_result = verify_mix(final_mastered_path)
            
            if verification_result.get("ok", False):
                logging.info("✅ Верификация пройдена успешно")
            else:
                logging.warning(f"⚠️ Проблемы при верификации: {verification_result.get('reason', 'Неизвестная ошибка')}")
            
            # === 10. Экспорт всех версий (опционально) ===
            if export_stems:
                logging.info("💾 Экспорт всех версий...")
                stems_dir = os.path.join(output_dir, "exported_all_versions")
                os.makedirs(stems_dir, exist_ok=True)
                
                # Копируем все промежуточные результаты
                import shutil
                stem_files = [
                    ("01_musicgen_genre_base.wav", f"01_MusicGen_{genre.title()}_Base.wav"),
                    (f"02_{genre}_stem_mix.wav", f"02_{genre.title()}_Stem_Mix.wav"), 
                    (f"03_{genre}_merged_mix.wav", f"03_{genre.title()}_Merged_Mix.wav"),
                    ("04_final_musicgen_fix.wav", f"04_Final_MusicGen_Fix.wav"),
                    (f"05_FINAL_{genre}_{mastering_purpose}_MASTERED.wav", f"05_FINAL_{genre.title()}_{mastering_purpose.upper()}_MASTERED.wav")
                ]
                
                for src_file, dst_file in stem_files:
                    src_path = os.path.join(output_dir, src_file)
                    dst_path = os.path.join(stems_dir, dst_file)
                    if os.path.exists(src_path):
                        shutil.copy2(src_path, dst_path)
                        logging.info(f"  📁 {dst_file} экспортирован")
                
                # Также копируем конфиги
                shutil.copy2(structure_path, os.path.join(stems_dir, "structure_config.json"))
                shutil.copy2(mastering_config_path, os.path.join(stems_dir, "mastering_config.json"))
                shutil.copy2(samples_info_path, os.path.join(stems_dir, "used_samples.json"))
                
                logging.info(f"✅ Все версии экспортированы в: {stems_dir}")
            
            # === 11. Финальный детальный отчет ===
            logging.info("=" * 70)
            logging.info("🎉 РАСШИРЕННАЯ ЦЕПОЧКА ЗАВЕРШЕНА!")
            logging.info("=" * 70)
            logging.info(f"📁 Мастерированный результат: {final_mastered_path}")
            logging.info(f"⏱️ Длительность: {len(mastered_track)/1000:.1f} секунд")
            logging.info(f"🎭 Детектированный жанр: {detected_genre}")
            logging.info(f"🎵 Темп: {tempo} BPM")
            logging.info(f"🎛️ Использовано сэмплов: {len(used_samples)}")
            logging.info(f"📊 Секций в структуре: {len(structure)}")
            logging.info(f"🎯 Назначение мастеринга: {mastering_purpose}")
            logging.info(f"🔧 Стиль мастеринга: {mastering_style}")
            
            mastering_character = mastering_config.get("overall_character", "professional")
            logging.info(f"🎚️ Характер мастеринга: {mastering_character}")
            
            if export_stems:
                logging.info(f"💾 Все версии экспортированы: {stems_dir}")
            
            logging.info("🎵 Этапы обработки:")
            logging.info("  1. ✅ Жанровая детекция из промпта")  
            logging.info("  2. ✅ LLaMA3 структурирование с жанровой привязкой")
            logging.info("  3. ✅ MusicGen жанровая основа")
            logging.info("  4. ✅ Жанро-специфичный Stem Mix")
            logging.info("  5. ✅ Жанровое микширование")
            logging.info("  6. ✅ MusicGen финальная доработка")
            logging.info("  7. ✅ LLaMA3 конфиг мастеринга")
            logging.info("  8. ✅ Умный мастеринг с современными FX")
            logging.info("=" * 70)
            
            return final_mastered_path, structure_data, used_samples, mastering_config
            
        except Exception as e:
            logging.error(f"❌ Критическая ошибка в расширенной цепочке: {e}")
            logging.error(f"🔍 Трассировка: {traceback.format_exc()}")
            return None, None, None, None
    
    def run_interactive_mode(self):
        """Интерактивный режим с расширенными возможностями"""
        print("""
╔══════════════════════════════════════════════════════════════════════════╗
║ 🎵 WaveDream Enhanced Pro - Genre Detection & Smart Mastering Edition 🎵 ║
║ LLaMA3 → MusicGen → Genre Stem Mix → Merged → Fix → Smart Mastering     ║
╚══════════════════════════════════════════════════════════════════════════╝
        """)
        
        # Проверка конфигурации
        errors = self.config.validate_config()
        if errors:
            print("❌ Ошибки конфигурации:")
            for error in errors:
                print(f"  • {error}")
            return
        
        sample_dir = self.config.get_sample_dir()
        print(f"📂 Директория сэмплов: {sample_dir}")
        
        while True:
            print("\n" + "="*80)
            print("Выберите действие:")
            print("1. 🚀 Полная расширенная цепочка (LLaMA3 + жанры + мастеринг)")
            print("2. 🎼 Сгенерировать трек (старый алгоритм)")
            print("3. 🎭 Тест жанровой детекции")
            print("4. 🔍 Тестировать подбор сэмплов по жанрам")
            print("5. 📊 Анализ индекса сэмплов")
            print("6. 🔄 Пересоздать расширенный индекс")
            print("7. 🎛️ Тест мастеринга")
            print("8. ⚙️ Настройки")
            print("0. 🚪 Выход")
            
            choice = input("\nВаш выбор: ").strip()
            
            if choice == "1":
                self.interactive_enhanced_generation()
            elif choice == "2":
                self.interactive_old_generation()
            elif choice == "3":
                self.interactive_genre_detection_test()
            elif choice == "4":
                self.interactive_test_genre_samples()
            elif choice == "5":
                self.interactive_analyze_index()
            elif choice == "6":
                self.interactive_rebuild_enhanced_index()
            elif choice == "7":
                self.interactive_test_mastering()
            elif choice == "8":
                self.interactive_settings()
            elif choice == "0":
                print("👋 До свидания!")
                break
            else:
                print("❌ Неверный выбор")
    
    def interactive_enhanced_generation(self):
        """Интерактивная расширенная генерация"""
        print("\n🚀 РАСШИРЕННАЯ ЦЕПОЧКА ГЕНЕРАЦИИ")
        print("-" * 50)
        print("Жанровая детекция + LLaMA3 + MusicGen + Smart Mastering")
        
        # Ввод промпта
        prompt = input("Введите описание трека: ").strip()
        if not prompt:
            print("❌ Промпт не может быть пустым")
            return
        
        # Предварительная детекция жанра для показа
        detected_genre, genre_info = detect_genre(prompt)
        print(f"\n🎭 Предварительная детекция жанра: {detected_genre}")
        print(f"🎵 BPM диапазон: {genre_info['bpm']}")
        print(f"🎛️ Стиль мастеринга: {genre_info['mastering_style']}")
        
        confirm_genre = input(f"Продолжить с жанром '{detected_genre}'? (Y/n): ").lower()
        if confirm_genre == 'n':
            available_genres = list(GENRE_INFO.keys())
            print(f"Доступные жанры: {', '.join(available_genres)}")
            manual_genre = input("Введите жанр вручную: ").strip().lower()
            if manual_genre in available_genres:
                # Перезаписываем промпт с явным жанром
                prompt = f"{manual_genre} {prompt}"
                print(f"📝 Промпт обновлён: {prompt}")
        
        # Выбор назначения мастеринга
        print("\n🎯 Выберите назначение трека:")
        print("1. Фриланс (коммерческая продажа)")
        print("2. Профессиональный (кино/ТВ)")  
        print("3. Личное (для себя)")
        print("4. Семейное (домашнее видео)")
        
        purpose_choice = input("Выбор (1-4, Enter для личного): ").strip()
        purpose_map = {
            "1": "freelance",
            "2": "professional", 
            "3": "personal",
            "4": "family"
        }
        mastering_purpose = purpose_map.get(purpose_choice, "personal")
        print(f"🎯 Назначение: {mastering_purpose}")
        
        # Выбор выходной директории
        output_dir = input("Выходная директория (Enter для 'output_enhanced'): ").strip()
        if not output_dir:
            output_dir = f"output_enhanced_{detected_genre}_{mastering_purpose}"
        
        # Дополнительные опции
        print("\nДополнительные опции:")
        rebuild_index = input("Пересоздать индекс сэмплов? (y/N): ").lower().startswith('y')
        export_stems = input("Экспортировать все промежуточные версии? (Y/n): ").lower() != 'n'
        
        try:
            sample_dir = self.config.get_sample_dir()
            
            # Пересоздание индекса если нужно
            if rebuild_index:
                print("🔄 Пересоздание расширенного индекса...")
                picker = EnhancedSamplePicker(sample_dir)
                picker.index = picker.build_enhanced_index()
                picker.save_index(picker.index)
            
            # Запуск расширенной цепочки
            print(f"\n🚀 Запуск расширенной цепочки для: '{prompt}'")
            print(f"🎭 Жанр: {detected_genre}, 🎯 Назначение: {mastering_purpose}")
            
            final_path, structure_data, used_samples, mastering_config = self.run_enhanced_full_chain(
                prompt, sample_dir, output_dir, mastering_purpose, export_stems
            )
            
            if final_path:
                print(f"\n🎉 РАСШИРЕННАЯ ГЕНЕРАЦИЯ ЗАВЕРШЕНА!")
                print(f"📁 Мастерированный результат: {final_path}")
                
                # Показываем детальную статистику
                if structure_data:
                    print(f"\n📊 Детальная статистика:")
                    print(f"  🎭 Детектированный жанр: {structure_data.get('detected_genre', 'неизвестно')}")
                    print(f"  🎵 Темп: {structure_data.get('tempo', 'неизвестно')} BPM")
                    print(f"  🎛️ Использовано сэмплов: {len(used_samples) if used_samples else 0}")
                    print(f"  📈 Секций в структуре: {len(structure_data.get('structure', []))}")
                    print(f"  🎯 Назначение мастеринга: {mastering_purpose}")
                    
                    if mastering_config:
                        print(f"  🎚️ Характер мастеринга: {mastering_config.get('overall_character', 'неизвестно')}")
                        print(f"  🔧 Креативные эффекты: {', '.join(mastering_config.get('creative_fx', []))}")
                
                # Предложение воспроизвести
                play_choice = input("\nВоспроизвести результат? (y/N): ").lower()
                if play_choice.startswith('y'):
                    try:
                        import platform
                        if platform.system() == "Windows":
                            os.system(f'start "" "{final_path}"')
                        elif platform.system() == "Darwin":  # macOS
                            os.system(f'open "{final_path}"')
                        else:  # Linux
                            os.system(f'xdg-open "{final_path}"')
                    except:
                        print("❌ Не удалось запустить воспроизведение")
            else:
                print("❌ Расширенная генерация не удалась")
        
        except Exception as e:
            logging.error(f"❌ Ошибка в интерактивной расширенной генерации: {e}")
            print(f"❌ Произошла ошибка: {e}")
    
    def interactive_genre_detection_test(self):
        """Интерактивное тестирование жанровой детекции"""
        print("\n🎭 ТЕСТ ЖАНРОВОЙ ДЕТЕКЦИИ")
        print("-" * 40)
        
        test_prompts = [
            "dark aggressive trap 160bpm with vocal chops",
            "мелодичный лоуфай для учёбы с винтажными текстурами",
            "liquid drum and bass neurofunk 174bpm",
            "атмосферный эмбиент космос медитация 70bpm",
            "phonk memphis cowbell drift aggressive",
            "техно минимал 130bpm industrial warehouse",
            "cinematic epic trailer orchestral heroic",
            "house deep groove плавный bassline 124bpm"
        ]
        
        while True:
            print("\nВведите промпт для тестирования (или 'test' для автотестов, 'exit' для выхода):")
            user_input = input("Промпт: ").strip()
            
            if user_input.lower() == 'exit':
                break
            elif user_input.lower() == 'test':
                print("\n🧪 АВТОМАТИЧЕСКОЕ ТЕСТИРОВАНИЕ:")
                for i, test_prompt in enumerate(test_prompts, 1):
                    print(f"\n{i}. Промпт: '{test_prompt}'")
                    detected_genre, genre_info = detect_genre(test_prompt)
                    print(f"   🎭 Жанр: {detected_genre}")
                    print(f"   🎵 BPM: {genre_info['bpm']}")
                    print(f"   🎛️ Мастеринг: {genre_info['mastering_style']}")
                    print(f"   🎼 Инструменты: {', '.join(genre_info['core_instruments'][:3])}")
            elif user_input:
                print(f"\n🔍 Анализ промпта: '{user_input}'")
                detected_genre, genre_info = detect_genre(user_input)
                print(f"🎭 Детектированный жанр: {detected_genre}")
                print(f"🎵 BPM диапазон: {genre_info['bpm']}")
                print(f"🎛️ Стиль мастеринга: {genre_info['mastering_style']}")
                print(f"🎼 Основные инструменты: {', '.join(genre_info['core_instruments'])}")
                print(f"🎹 Дополнительные инструменты: {', '.join(genre_info['optional_instruments'])}")
                print(f"🏷️ Дефолтные теги: {', '.join(genre_info['default_tags'][:5])}")
    
    def interactive_test_genre_samples(self):
        """Интерактивное тестирование подбора сэмплов по жанрам"""
        print("\n🧪 ТЕСТ ПОДБОРА СЭМПЛОВ ПО ЖАНРАМ")
        print("-" * 45)
        
        sample_dir = self.config.get_sample_dir()
        picker = EnhancedSamplePicker(sample_dir)
        
        available_genres = list(GENRE_INFO.keys())
        print(f"Доступные жанры: {', '.join(available_genres)}")
        
        while True:
            genre_input = input("Введите жанр для тестирования (или 'exit'): ").strip().lower()
            if genre_input == 'exit':
                break
            
            if genre_input not in available_genres:
                print(f"❌ Неизвестный жанр. Доступные: {', '.join(available_genres)}")
                continue
            
            genre_info = GENRE_INFO[genre_input]
            target_tempo = random.randint(*genre_info["bpm"])
            
            print(f"\n🎭 Тестирование жанра: {genre_input}")
            print(f"🎵 Целевой темп: {target_tempo} BPM")
            print(f"🎼 Основные инструменты: {', '.join(genre_info['core_instruments'])}")
            
            # Тестируем подбор сэмплов для каждого основного инструмента
            for instrument in genre_info['core_instruments']:
                print(f"\n🎯 Поиск сэмплов для: {instrument}")
                instrument_tags = expand_instrument_tags(instrument)
                print(f"   Расширенные теги: {', '.join(instrument_tags)}")
                
                results = picker.pick_samples_enhanced(
                    required_tags=instrument_tags,
                    target_tempo=target_tempo,
                    genre_hint=genre_input,
                    top_k=3
                )
                
                if results:
                    for i, sample in enumerate(results, 1):
                        print(f"   {i}. {sample['filename']}")
                        print(f"      Теги: {sample.get('tags', [])}")
                        print(f"      Темп: {sample.get('tempo', 'неизвестно')} BPM")
                        print(f"      Жанры: {sample.get('genres', [])}")
                        print(f"      Категория: {sample.get('category', 'неизвестно')}")
                else:
                    print("   ❌ Совпадений не найдено")
    
    def interactive_test_mastering(self):
        """Интерактивное тестирование мастеринга"""
        print("\n🎛️ ТЕСТ УМНОГО МАСТЕРИНГА")
        print("-" * 35)
        
        # Тест промпты для мастеринга
        test_cases = [
            ("aggressive trap dark", "freelance"),
            ("melodic lofi chill", "personal"),
            ("cinematic epic orchestral", "professional"),
            ("happy family song", "family")
        ]
        
        print("Выберите тест кейс:")
        for i, (prompt, purpose) in enumerate(test_cases, 1):
            print(f"{i}. '{prompt}' для {purpose}")
        print("5. Ввести свой промпт")
        
        choice = input("Выбор (1-5): ").strip()
        
        if choice in ['1', '2', '3', '4']:
            test_prompt, test_purpose = test_cases[int(choice) - 1]
        elif choice == '5':
            test_prompt = input("Введите промпт: ").strip()
            if not test_prompt:
                return
            
            print("Выберите назначение:")
            print("1. freelance, 2. professional, 3. personal, 4. family")
            purpose_choice = input("Выбор (1-4): ").strip()
            purpose_map = {"1": "freelance", "2": "professional", "3": "personal", "4": "family"}
            test_purpose = purpose_map.get(purpose_choice, "personal")
        else:
            print("❌ Неверный выбор")
            return
        
        print(f"\n🧪 Тестирование мастеринга:")
        print(f"📝 Промпт: '{test_prompt}'")
        print(f"🎯 Назначение: {test_purpose}")
        
        # Получаем конфиг мастеринга
        mastering_config = query_mastering_prompt(test_prompt, test_purpose)
        
        print(f"\n🎛️ Конфигурация мастеринга:")
        print(f"EQ: Low {mastering_config.get('eq_settings', {}).get('low', 0):+.1f}dB, "
              f"Mid {mastering_config.get('eq_settings', {}).get('mid', 0):+.1f}dB, "
              f"High {mastering_config.get('eq_settings', {}).get('high', 0):+.1f}dB")
        
        compression = mastering_config.get('compression', {})
        print(f"Компрессия: {compression.get('ratio', 2)}:1, "
              f"Attack {compression.get('attack', 10)}ms, "
              f"Release {compression.get('release', 100)}ms")
        
        reverb = mastering_config.get('reverb', {})
        print(f"Реверб: {reverb.get('type', 'room')}, "
              f"Size {reverb.get('room_size', 0.3)}, "
              f"Wet {reverb.get('wet_level', 0.1)}")
        
        stereo = mastering_config.get('stereo_enhancement', {})
        print(f"Стерео: Width {stereo.get('width', 100)}%, "
              f"Imaging {stereo.get('imaging', 'natural')}")
        
        creative_fx = mastering_config.get('creative_fx', [])
        print(f"Креативные FX: {', '.join(creative_fx)}")
        
        character = mastering_config.get('overall_character', 'professional')
        print(f"Общий характер: {character}")
        
        # Сохраняем тестовый конфиг
        test_config_path = f"test_mastering_{test_purpose}.json"
        with open(test_config_path, 'w', encoding='utf-8') as f:
            json.dump(mastering_config, f, indent=2, ensure_ascii=False)
        print(f"\n💾 Тестовый конфиг сохранён: {test_config_path}")
    
    def interactive_rebuild_enhanced_index(self):
        """Интерактивное пересоздание расширенного индекса"""
        print("\n🔄 ПЕРЕСОЗДАНИЕ РАСШИРЕННОГО ИНДЕКСА")
        print("-" * 45)
        
        confirm = input("Это займёт значительно больше времени. Продолжить? (y/N): ")
        if not confirm.lower().startswith('y'):
            return
        
        try:
            sample_dir = self.config.get_sample_dir()
            picker = EnhancedSamplePicker(sample_dir)
            
            print("🔄 Пересоздание расширенного индекса с жанровой привязкой...")
            picker.index = picker.build_enhanced_index()
            picker.save_index(picker.index)
            
            print("✅ Расширенный индекс пересоздан!")
            print(f"📊 Проиндексировано: {len(picker.index)} сэмплов")
            
            # Показываем статистику по жанрам
            genre_stats = {}
            for sample in picker.index:
                for genre in sample.get("genres", []):
                    genre_stats[genre] = genre_stats.get(genre, 0) + 1
            
            if genre_stats:
                print(f"\n🎭 Статистика по жанрам:")
                for genre, count in sorted(genre_stats.items(), key=lambda x: -x[1])[:10]:
                    print(f"  {genre}: {count} сэмплов")
            
        except Exception as e:
            print(f"❌ Ошибка: {e}")
    
    def interactive_old_generation(self):
        """Интерактивная генерация старым методом (для совместимости)"""
        print("\n🎼 ГЕНЕРАЦИЯ ТРЕКА (старый алгоритм)")
        print("-" * 30)
        
        prompt = input("Введите описание трека: ").strip()
        if not prompt:
            print("❌ Промпт не может быть пустым")
            return
        
        output_dir = input("Выходная директория (Enter для 'output_legacy'): ").strip()
        if not output_dir:
            output_dir = "output_legacy"
        
        print("\nДополнительные опции:")
        professional_mix = input("Профессиональное микширование? (Y/n): ").lower() != 'n'
        export_stems = input("Экспортировать стемы? (Y/n): ").lower() != 'n'
        
        try:
            sample_dir = self.config.get_sample_dir()
            
            print(f"\n🚀 Генерация трека (legacy): '{prompt}'")
            # Здесь можно вызвать старую функцию, если она есть
            # final_path = self.full_track_generation(prompt, sample_dir, output_dir, professional_mix, export_stems)
            print("⚠️ Старый алгоритм временно недоступен. Используйте расширенную цепочку (пункт 1)")
                
        except Exception as e:
            logging.error(f"❌ Ошибка генерации: {e}")
            print(f"❌ Произошла ошибка: {e}")
    
    def interactive_analyze_index(self):
        """Интерактивный анализ расширенного индекса"""
        print("\n📊 АНАЛИЗ РАСШИРЕННОГО ИНДЕКСА")
        print("-" * 40)
        
        sample_dir = self.config.get_sample_dir()
        picker = EnhancedSamplePicker(sample_dir)
        index = picker.index
        
        if not index:
            print("❌ Индекс пуст или не загружен")
            return
        
        # Статистика тегов
        all_tags = []
        empty_tags = 0
        tempo_distribution = []
        duration_distribution = []
        genre_distribution = {}
        brightness_distribution = []
        
        for sample in index:
            tags = sample.get("tags", [])
            if not tags:
                empty_tags += 1
            else:
                all_tags.extend(tags)
            
            tempo_distribution.append(sample.get("tempo", 120))
            duration_distribution.append(sample.get("duration", 0))
            brightness_distribution.append(sample.get("brightness", 0))
            
            # Статистика по жанрам
            for genre in sample.get("genres", []):
                genre_distribution[genre] = genre_distribution.get(genre, 0) + 1
        
        tag_counter = Counter(all_tags)
        
        print(f"📈 ОБЩАЯ СТАТИСТИКА:")
        print(f"  Всего сэмплов: {len(index)}")
        print(f"  Без тегов: {empty_tags} ({empty_tags/len(index)*100:.1f}%)")
        print(f"  Уникальных тегов: {len(tag_counter)}")
        print(f"  Детектированных жанров: {len(genre_distribution)}")
        
        print(f"\n🏷️ ТОП-10 ТЕГОВ:")
        for tag, count in tag_counter.most_common(10):
            percentage = count / len(index) * 100
            print(f"  {tag}: {count} ({percentage:.1f}%)")
        
        print(f"\n🎭 РАСПРЕДЕЛЕНИЕ ПО ЖАНРАМ:")
        for genre, count in sorted(genre_distribution.items(), key=lambda x: -x[1])[:10]:
            percentage = count / len(index) * 100
            print(f"  {genre}: {count} ({percentage:.1f}%)")
        
        print(f"\n🎵 РАСПРЕДЕЛЕНИЕ ТЕМПА:")
        tempo_ranges = {
            "Very Slow (60-80)": len([t for t in tempo_distribution if 60 <= t < 80]),
            "Slow (80-100)": len([t for t in tempo_distribution if 80 <= t < 100]),
            "Medium (100-130)": len([t for t in tempo_distribution if 100 <= t < 130]),
            "Fast (130-160)": len([t for t in tempo_distribution if 130 <= t < 160]),
            "Very Fast (160+)": len([t for t in tempo_distribution if t >= 160])
        }
        
        for range_name, count in tempo_ranges.items():
            percentage = count / len(index) * 100
            print(f"  {range_name}: {count} ({percentage:.1f}%)")
        
        print(f"\n⏱️ ДЛИТЕЛЬНОСТЬ СЭМПЛОВ:")
        avg_duration = sum(duration_distribution) / len(duration_distribution)
        loops = len([d for d in duration_distribution if d > 8])
        oneshots = len([d for d in duration_distribution if d <= 8])
        print(f"  Средняя длительность: {avg_duration:.1f}с")
        print(f"  Loops (>8с): {loops} ({loops/len(index)*100:.1f}%)")
        print(f"  One-shots (≤8с): {oneshots} ({oneshots/len(index)*100:.1f}%)")
        
        # Анализ качества индекса
        quality_samples = len([s for s in index if len(s.get("tags", [])) > 2 and s.get("key")])
        print(f"\n⭐ КАЧЕСТВО ИНДЕКСА:")
        print(f"  Высокое качество (>2 тегов + тональность): {quality_samples} ({quality_samples/len(index)*100:.1f}%)")
        
        if brightness_distribution:
            avg_brightness = sum([b for b in brightness_distribution if b > 0]) / len([b for b in brightness_distribution if b > 0])
            print(f"  Средняя яркость спектра: {avg_brightness:.3f}")
        
        input("\nНажмите Enter для продолжения...")
    
    def interactive_settings(self):
        """Интерактивные настройки"""
        print("\n⚙️ НАСТРОЙКИ WAVEDREAM ENHANCED")
        print("-" * 40)
        
        print(f"📂 Директория сэмплов: {self.config.get_sample_dir()}")
        print(f"📁 Выходная директория: {self.config.DEFAULT_OUTPUT_DIR}")
        print(f"⏱️ Макс. длительность анализа: {self.config.AUDIO_ANALYSIS['max_duration']} сек")
        print(f"🎯 Порог скора: {self.config.SAMPLE_MATCHING['min_score_threshold']}")
        print(f"🎵 Темповая толерантность: {self.config.SAMPLE_MATCHING['tempo_tolerance']} BPM")
        
        print(f"\n🎭 Поддерживаемые жанры: {', '.join(GENRE_INFO.keys())}")
        print(f"🎛️ Стили мастеринга: {', '.join(set([info['mastering_style'] for info in GENRE_INFO.values()]))}")
        
        change = input("\nИзменить настройки? (y/N): ")
        if change.lower().startswith('y'):
            print("💡 Редактируйте config.py для изменения настроек")
            print("💡 Жанровые настройки находятся в GENRE_INFO в этом файле")
    
    def run_single_generation(self, args):
        """Генерация одного трека из командной строки"""
        try:
            sample_dir = args.sample_dir or self.config.get_sample_dir()
            
            if args.rebuild_index:
                logging.info("🔄 Пересоздание расширенного индекса...")
                picker = EnhancedSamplePicker(sample_dir)
                picker.index = picker.build_enhanced_index()
                picker.save_index(picker.index)
            
            logging.info(f"🚀 Генерация: '{args.prompt}'")
            
            # Определяем назначение мастеринга
            mastering_purpose = getattr(args, 'mastering_purpose', 'personal')
            
            if args.enhanced or args.full_chain:
                # Расширенная цепочка
                final_path, structure_data, used_samples, mastering_config = self.run_enhanced_full_chain(
                    args.prompt, sample_dir, args.output_dir, mastering_purpose, args.export_stems
                )
                
                if final_path:
                    print(f"\n🎉 Расширенная генерация завершена!")
                    print(f"📁 Мастерированный результат: {final_path}")
                    if structure_data:
                        print(f"🎭 Жанр: {structure_data.get('detected_genre')}")
                        print(f"🎵 Темп: {structure_data.get('tempo')} BPM")
                        print(f"🎛️ Сэмплов: {len(used_samples) if used_samples else 0}")
                        print(f"🎯 Мастеринг: {mastering_purpose}")
                        if mastering_config:
                            print(f"🎚️ Характер: {mastering_config.get('overall_character', 'неизвестно')}")
                else:
                    print("❌ Расширенная генерация не удалась")
            else:
                # Старый алгоритм (заглушка)
                print("⚠️ Старый алгоритм временно недоступен. Используйте --enhanced или --full-chain")
        
        except Exception as e:
            logging.error(f"❌ Ошибка генерации: {e}")
            if args.debug:
                traceback.print_exc()
    
    def run_batch_mode(self, batch_file):
        """Пакетная обработка из JSON файла"""
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                batch_data = json.load(f)
            
            tasks = batch_data.get("tasks", [])
            default_settings = batch_data.get("default_settings", {})
            
            print(f"📦 Пакетная обработка: {len(tasks)} задач")
            
            for i, task in enumerate(tasks, 1):
                print(f"\n🔄 Задача {i}/{len(tasks)}: {task.get('name', f'task_{i}')}") 
                
                # Объединение настроек
                task_settings = {**default_settings, **task}
                
                # Генерация
                prompt = task_settings.get("prompt")
                output_dir = os.path.join(
                    task_settings.get("output_dir", "batch_output"), 
                    f"task_{i}"
                )
                mastering_purpose = task_settings.get("mastering_purpose", "personal")
                
                if prompt:
                    if task_settings.get("enhanced", True):
                        final_path, _, _, _ = self.run_enhanced_full_chain(
                            prompt,
                            task_settings.get("sample_dir") or self.config.get_sample_dir(),
                            output_dir,
                            mastering_purpose,
                            task_settings.get("export_stems", True)
                        )
                    else:
                        print(f"  ⚠️ Старый алгоритм недоступен для задачи {i}")
                        continue
                    
                    if final_path:
                        print(f"  ✅ Готово: {final_path}")
                    else:
                        print(f"  ❌ Ошибка генерации")
            
            print(f"\n🎊 Пакетная обработка завершена!")
            
        except Exception as e:
            logging.error(f"❌ Ошибка пакетной обработки: {e}")


def main():
    """Главная функция с расширенными аргументами"""
    parser = argparse.ArgumentParser(
        description="🎵 WaveDream Enhanced Pro - Genre Detection & Smart Mastering Edition",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Примеры использования:

Интерактивный режим:
  python main.py

Расширенная цепочка (рекомендуется):
  python main.py --prompt "dark trap aggressive 160bpm" --enhanced --mastering-purpose freelance

С жанровой детекцией и мастерингом:
  python main.py --prompt "lofi chill study beats" --enhanced --mastering-purpose personal

С пересозданием индекса:
  python main.py --prompt "dnb liquid neurofunk 174bpm" --rebuild-index --enhanced

Тестирование жанровой детекции:
  python main.py --test-genre "phonk memphis cowbell drift"

Пакетная обработка:
  python main.py --batch enhanced_tasks.json

Анализ базы сэмплов:
  python main.py --analyze-index
        """
    )
    
    parser.add_argument("--prompt", type=str, help="Промпт для генерации")
    parser.add_argument("--sample-dir", type=str, help="Директория с сэмплами")
    parser.add_argument("--output-dir", type=str, default="output", help="Выходная директория")
    parser.add_argument("--rebuild-index", action="store_true", help="Пересоздать расширенный индекс")
    parser.add_argument("--enhanced", action="store_true", help="Расширенная цепочка с жанрами и мастерингом")
    parser.add_argument("--full-chain", action="store_true", help="Алиас для --enhanced")
    parser.add_argument("--export-stems", action="store_true", help="Экспорт всех промежуточных версий")
    parser.add_argument("--mastering-purpose", choices=["freelance", "professional", "personal", "family"], 
                        default="personal", help="Назначение мастеринга")
    parser.add_argument("--test-genre", type=str, help="Тестирование жанровой детекции")
    parser.add_argument("--analyze-index", action="store_true", help="Анализ качества расширенного индекса")
    parser.add_argument("--debug", action="store_true", help="Режим отладки")
    parser.add_argument("--batch", type=str, help="Пакетная обработка из JSON файла")
    
    args = parser.parse_args()
    
    # Настройка логирования
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    launcher = WaveDreamLauncher()
    
    # Различные режимы работы
    if args.test_genre:
        print(f"\n🎭 ТЕСТ ЖАНРОВОЙ ДЕТЕКЦИИ: '{args.test_genre}'")
        detected_genre, genre_info = detect_genre(args.test_genre)
        print(f"🎭 Детектированный жанр: {detected_genre}")
        print(f"🎵 BPM диапазон: {genre_info['bpm']}")
        print(f"🎛️ Стиль мастеринга: {genre_info['mastering_style']}")
        print(f"🎼 Основные инструменты: {', '.join(genre_info['core_instruments'])}")
        print(f"🎹 Дополнительные инструменты: {', '.join(genre_info['optional_instruments'])}")
    
    elif args.analyze_index:
        launcher.interactive_analyze_index()
    
    elif args.batch:
        launcher.run_batch_mode(args.batch)
    
    elif args.prompt:
        # Автоматически включаем расширенную цепочку, если не указано иное
        if not hasattr(args, 'enhanced'):
            args.enhanced = True
        launcher.run_single_generation(args)
    
    else:
        # Интерактивный режим
        launcher.run_interactive_mode()


def quick_start():
    """Быстрый старт с жанровыми примерами"""
    examples = [
        {
            "name": "Dark Trap Pro",
            "prompt": "dark aggressive trap 160bpm с вокальными чопами и 808",
            "purpose": "freelance",
            "expected": "Мрачный trap для коммерческой продажи"
        },
        {
            "name": "Melodic Lofi", 
            "prompt": "мелодичный lofi study beats 75bpm с винтажными текстурами",
            "purpose": "personal",
            "expected": "Мелодичный lofi для личного пользования"
        },
        {
            "name": "Cinematic Epic",
            "prompt": "cinematic epic orchestral trailer music heroic 90bpm", 
            "purpose": "professional",
            "expected": "Эпический саундтрек для профессионального применения"
        },
        {
            "name": "Family House",
            "prompt": "house happy upbeat family dance 124bpm bright",
            "purpose": "family",
            "expected": "Яркий house для семейного контента"
        }
    ]
    
    print("🚀 Быстрый старт WaveDream Enhanced Pro")
    print("Выберите пример для генерации:")
    
    for i, example in enumerate(examples, 1):
        print(f"{i}. {example['name']} - {example['expected']}")
        print(f"   Назначение: {example['purpose']}")
    
    choice = input("\nВыбор (1-4): ").strip()
    
    if choice in ['1', '2', '3', '4']:
        idx = int(choice) - 1
        example = examples[idx]
        
        print(f"\n🎵 Генерирую: {example['name']}")
        print(f"📝 Промпт: {example['prompt']}")
        print(f"🎯 Назначение: {example['purpose']}")
        
        launcher = WaveDreamLauncher()
        output_dir = f"quick_start_{example['name'].lower().replace(' ', '_')}"
        
        final_path, structure_data, used_samples, mastering_config = launcher.run_enhanced_full_chain(
            example['prompt'],
            launcher.config.get_sample_dir(),
            output_dir,
            example['purpose'],
            export_stems=True
        )
        
        if final_path:
            print(f"\n🎉 Готово: {final_path}")
            if structure_data:
                detected_genre = structure_data.get('detected_genre', 'неизвестно')
                print(f"🎭 Детектированный жанр: {detected_genre}")
                print(f"🎛️ Использовано сэмплов: {len(used_samples) if used_samples else 0}")
        else:
            print("❌ Ошибка генерации")


if __name__ == "__main__":
    # Проверка аргументов для quick start
    if len(sys.argv) == 1:
        # Если нет аргументов - интерактивный режим
        launcher = WaveDreamLauncher()
        launcher.run_interactive_mode()
    elif len(sys.argv) == 2 and sys.argv[1] == "--quick-start":
        quick_start()
    else:
        main()

# config.py

# config.py - Централизованная конфигурация WD

import os
from pathlib import Path

class Config:
    """Центральная конфигурация проекта"""
    
    # Пути
    BASE_DIR = Path(__file__).parent
    DEFAULT_SAMPLE_DIR = r"D:\0\шаблоны\Samples for AKAI"
    DEFAULT_OUTPUT_DIR = "wavedream_output"
    
    # Файлы индексов
    ENHANCED_INDEX_FILE = "enhanced_sample_index.json"
    BACKUP_INDEX_FILE = "backup_sample_index.json"
    
    # Параметры анализа аудио
    AUDIO_ANALYSIS = {
        "max_duration": 10,  # секунд для анализа
        "sample_rate": 22050,
        "hop_length": 512,
        "frame_size": 2048
    }
    
    # Параметры подбора сэмплов
    SAMPLE_MATCHING = {
        "min_score_threshold": 5,
        "tempo_tolerance": 30,  # BPM отклонение
        "semantic_weight": 0.6,
        "tempo_weight": 0.2,
        "genre_weight": 0.1,
        "quality_weight": 0.1
    }
    
    # Жанровые настройки
    GENRE_SETTINGS = {
        "trap": {
            "bpm_range": (130, 170),
            "default_structure": [
                {"type": "intro", "duration": 8},
                {"type": "verse", "duration": 16},
                {"type": "hook", "duration": 16},
                {"type": "verse", "duration": 16},
                {"type": "hook", "duration": 16},
                {"type": "outro", "duration": 8}
            ],
            "core_instruments": ["kick", "snare", "hihat", "bass", "808"],
            "optional_instruments": ["lead", "vocal", "fx", "pad"]
        },
        "house": {
            "bpm_range": (118, 128),
            "default_structure": [
                {"type": "intro", "duration": 16},
                {"type": "build", "duration": 16},
                {"type": "drop", "duration": 32},
                {"type": "break", "duration": 16},
                {"type": "drop", "duration": 32},
                {"type": "outro", "duration": 16}
            ],
            "core_instruments": ["kick", "hihat", "bass", "clap"],
            "optional_instruments": ["piano", "vocal", "fx", "percussion"]
        },
        "techno": {
            "bpm_range": (120, 135),
            "default_structure": [
                {"type": "intro", "duration": 32},
                {"type": "build", "duration": 32},
                {"type": "peak", "duration": 64},
                {"type": "breakdown", "duration": 32},
                {"type": "outro", "duration": 32}
            ],
            "core_instruments": ["kick", "hihat", "bass", "fx"],
            "optional_instruments": ["lead", "pad", "percussion"]
        },
        "dnb": {
            "bpm_range": (160, 180),
            "default_structure": [
                {"type": "intro", "duration": 16},
                {"type": "buildup", "duration": 16},
                {"type": "drop", "duration": 32},
                {"type": "breakdown", "duration": 16},
                {"type": "drop", "duration": 32},
                {"type": "outro", "duration": 16}
            ],
            "core_instruments": ["kick", "snare", "bass", "hihat"],
            "optional_instruments": ["lead", "vocal", "fx", "percussion"]
        },
        "ambient": {
            "bpm_range": (60, 90),
            "default_structure": [
                {"type": "intro", "duration": 30},
                {"type": "development", "duration": 60},
                {"type": "climax", "duration": 45},
                {"type": "resolution", "duration": 45}
            ],
            "core_instruments": ["pad", "texture", "ambient"],
            "optional_instruments": ["piano", "fx", "vocal", "drone"]
        }
    }
    
    # Продвинутая семантическая карта тегов
    SEMANTIC_MAP = {
        # Ударные
        "kick": {
            "synonyms": ["kick", "bd", "bass_drum", "thump", "punch", "boom", "sub_kick"],
            "related": ["808", "sub", "low"],
            "genre_variants": {
                "trap": ["808_kick", "hard_kick", "punchy_kick"],
                "techno": ["techno_kick", "industrial_kick", "pounding_kick"],
                "house": ["house_kick", "four_on_floor", "groove_kick"]
            }
        },
        "snare": {
            "synonyms": ["snare", "snr", "crack", "snap", "backbeat"],
            "related": ["clap", "rim", "percussion"],
            "genre_variants": {
                "trap": ["trap_snare", "snappy_snare", "tight_snare"],
                "dnb": ["dnb_snare", "rolling_snare", "break_snare"],
                "house": ["house_clap", "deep_clap"]
            }
        },
        "hihat": {
            "synonyms": ["hat", "hh", "hi_hat", "closed_hat", "open_hat"],
            "related": ["cymbal", "shaker", "percussion"],
            "genre_variants": {
                "trap": ["trap_hat", "rolling_hat", "drill_hat"],
                "house": ["house_hat", "swing_hat"],
                "techno": ["tech_hat", "minimal_hat"]
            }
        },
        
        # Бас
        "bass": {
            "synonyms": ["bass", "sub", "low", "bassline", "low_end"],
            "related": ["808", "reese", "wobble", "growl"],
            "genre_variants": {
                "trap": ["808", "sub_bass", "sliding_bass"],
                "dnb": ["reese", "neurobass", "growl"],
                "house": ["house_bass", "deep_bass", "groove_bass"],
                "techno": ["acid_bass", "modular_bass"]
            }
        },
        
        # Мелодические
        "lead": {
            "synonyms": ["lead", "melody", "synth", "keys", "main"],
            "related": ["arp", "sequence", "hook"],
            "genre_variants": {
                "trap": ["trap_melody", "dark_lead", "minor_lead"],
                "house": ["piano", "organ", "electric_piano"],
                "techno": ["acid_lead", "analog_lead"],
                "ambient": ["soft_lead", "ethereal_lead"]
            }
        },
        
        "pad": {
            "synonyms": ["pad", "strings", "ambient", "texture", "atmosphere"],
            "related": ["drone", "wash", "background"],
            "genre_variants": {
                "ambient": ["ambient_pad", "space_pad", "ethereal_pad"],
                "house": ["warm_pad", "analog_pad"],
                "techno": ["dark_pad", "industrial_pad"]
            }
        },
        
        # Вокал
        "vocal": {
            "synonyms": ["vocal", "voice", "vox", "vocals", "sung"],
            "related": ["choir", "chant", "rap", "spoken"],
            "genre_variants": {
                "trap": ["rap", "autotune", "vocal_chop"],
                "house": ["soulful_vocal", "disco_vocal"],
                "ambient": ["ethereal_vocal", "choir", "chant"]
            }
        },
        
        # Эффекты
        "fx": {
            "synonyms": ["fx", "effect", "sfx", "sound_effect"],
            "related": ["sweep", "riser", "impact", "whoosh", "transition"],
            "genre_variants": {
                "trap": ["trap_fx", "reverse_fx", "vinyl_stop"],
                "house": ["filter_sweep", "vocal_fx"],
                "techno": ["industrial_fx", "noise_fx"],
                "ambient": ["nature_fx", "space_fx"]
            }
        }
    }
    
    # Мудротехческие паттерны для улучшения подбора
    MOOD_MODIFIERS = {
        "dark": {
            "tag_boost": ["minor", "dark", "evil", "horror", "deep"],
            "tempo_modifier": 0.95,  # Чуть медленнее
            "volume_modifier": 1.1   # Чуть громче
        },
        "aggressive": {
            "tag_boost": ["hard", "aggressive", "punchy", "distorted"],
            "tempo_modifier": 1.05,  # Чуть быстрее
            "volume_modifier": 1.2   # Громче
        },
        "melodic": {
            "tag_boost": ["melodic", "beautiful", "harmonic", "musical"],
            "tempo_modifier": 1.0,
            "volume_modifier": 0.9   # Чуть тише
        },
        "chill": {
            "tag_boost": ["chill", "relaxed", "soft", "gentle"],
            "tempo_modifier": 0.9,   # Медленнее
            "volume_modifier": 0.8   # Тише
        }
    }
    
    # Расширенные правила именования файлов
    FILENAME_PATTERNS = {
        "bpm_extraction": [
            r'(\d{2,3})\s*bpm',
            r'(\d{2,3})\s*beats',
            r'bpm[\s_-]*(\d{2,3})',
            r'tempo[\s_-]*(\d{2,3})',
            r'(\d{2,3})[\s_-]*beat'
        ],
        "key_extraction": [
            r'\b([a-g]#?)\s*m(?:inor)?(?:\s|$)',
            r'\b([a-g]#?)\s*maj(?:or)?(?:\s|$)',
            r'key[\s_-]*([a-g]#?)',
            r'in[\s_-]*([a-g]#?)',
            r'([a-g]#?)[\s_-]*(?:key|scale)'
        ],
        "instrument_patterns": {
            "kick": [r'\bkick\b', r'\bbd\b', r'\bbass[\s_-]*drum\b'],
            "snare": [r'\bsnare\b', r'\bsnr\b', r'\bcrack\b'],
            "hihat": [r'\bhat\b', r'\bhi[\s_-]*hat\b', r'\bhh\b'],
            "clap": [r'\bclap\b', r'\bhand[\s_-]*clap\b'],
            "bass": [r'\bbass\b', r'\bsub\b', r'\b808\b'],
            "vocal": [r'\bvocal\b', r'\bvox\b', r'\bvoice\b', r'\brap\b'],
            "fx": [r'\bfx\b', r'\beffect\b', r'\bsweep\b', r'\briser\b']
        }
    }
    
    # Качественные фильтры
    QUALITY_FILTERS = {
        "min_duration": 0.5,      # минимум 0.5 сек
        "max_duration": 300,      # максимум 5 минут
        "min_sample_rate": 44100, # минимальное качество
        "exclude_extensions": [".tmp", ".bak", ".old"],
        "exclude_folders": ["backup", "temp", "trash", "old"]
    }
    
    # Настройки производительности
    PERFORMANCE = {
        "batch_size": 100,        # сколько файлов обрабатывать за раз
        "max_workers": 4,         # потоки для параллельной обработки
        "cache_size": 1000,       # размер кэша результатов
        "index_rebuild_threshold": 0.1  # порог для пересоздания индекса
    }
    
    # Настройки логирования
    LOGGING = {
        "level": "INFO",
        "format": "[%(levelname)s] %(asctime)s - %(message)s",
        "file": "wavedream.log",
        "max_size_mb": 50
    }

    @classmethod
    def get_sample_dir(cls):
        """Получение рабочей директории с сэмплами"""
        if os.path.exists(cls.DEFAULT_SAMPLE_DIR):
            return cls.DEFAULT_SAMPLE_DIR
        
        # Альтернативные пути
        alternatives = [
            "samples",
            "audio_samples", 
            os.path.join(os.path.expanduser("~"), "Documents", "Samples"),
            "D:\\Samples",
            "C:\\Samples"
        ]
        
        for alt in alternatives:
            if os.path.exists(alt):
                return alt
        
        # Создаём дефолтную
        os.makedirs("samples", exist_ok=True)
        return "samples"

    @classmethod
    def validate_config(cls):
        """Валидация конфигурации"""
        errors = []
        
        sample_dir = cls.get_sample_dir()
        if not os.path.exists(sample_dir):
            errors.append(f"Sample directory not found: {sample_dir}")
        
        if cls.PERFORMANCE["max_workers"] < 1:
            errors.append("max_workers must be >= 1")
            
        if cls.AUDIO_ANALYSIS["max_duration"] < 1:
            errors.append("max_duration must be >= 1")
            
        return errors

# smart_mixer.py

import os
import logging
from pydub import AudioSegment
from sample_picker import pick_samples
from SIG import load_index
from musicgen_wrapper import generate_music
import soundfile as sf
import uuid

logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

def smart_mix(json_data, sample_dir, output_dir="output", ignore_bpm=False):
    os.makedirs(output_dir, exist_ok=True)
    tempo = json_data.get("tempo", 120)
    structure = json_data.get("structure", [])
    tracks = json_data.get("tracks", [])

    total_duration_sec = sum([s["duration"] for s in structure])
    total_duration_ms = int(total_duration_sec * 1000)

    final_mix = AudioSegment.silent(duration=total_duration_ms)

    for track in tracks:
        name = track.get("name", "unknown")
        tags = track.get("sample_tags", [])
        volume = track.get("volume", -6)

        starts_at_beats = track.get("starts_at", 0)
        ends_at_beats = track.get("ends_at", None)

        beat_time = 60.0 / tempo
        starts_at_ms = int(starts_at_beats * beat_time * 1000)
        ends_at_ms = int(ends_at_beats * beat_time * 1000) if ends_at_beats else total_duration_ms

        duration_ms = ends_at_ms - starts_at_ms

        picked = pick_samples(tags, genre_hint=None, energy=0.5, tempo=tempo, sample_dir=sample_dir)

        if not picked:
            logging.warning(f"🧫 Fallback: генерим MusicGen stem для '{name}' (теги: {tags})")
            prompt = f"instrumental stem for {name} with tags {', '.join(tags)}"
            gen_duration = (ends_at_beats - starts_at_beats) if ends_at_beats else 8
            waveform, sr = generate_music(prompt, duration=gen_duration)
            mgen_path = os.path.join(output_dir, f"musicgen_{name}.wav")
            sf.write(mgen_path, waveform.squeeze().numpy(), sr)
            seg = AudioSegment.from_file(mgen_path)
        else:
            sample_path = picked[0]["path"]
            seg = AudioSegment.from_file(sample_path)

        # Подгонка длительности
        if len(seg) > duration_ms:
            seg = seg[:duration_ms]
        elif len(seg) < duration_ms:
            pad = AudioSegment.silent(duration=duration_ms - len(seg))
            seg += pad

        seg = seg.apply_gain(volume)
        final_mix = final_mix.overlay(seg, position=starts_at_ms)

        track_path = os.path.join(output_dir, f"{name}.wav")
        seg.export(track_path, format="wav")
        logging.info(f"🔊 [{name}] {starts_at_ms}ms → {ends_at_ms}ms  ({tags})")

    final_path = os.path.join(output_dir, "final_mix.wav")
    final_mix.export(final_path, format="wav")
    logging.info(f"🎛 Финал микс: {final_path}")
    return final_mix

# self_check.py

import os
import logging
from pydub import AudioSegment
import numpy as np
import librosa


def check_rms(audio: AudioSegment) -> float:
    samples = np.array(audio.get_array_of_samples())
    return np.sqrt(np.mean(samples**2))


def is_too_silent(audio: AudioSegment, threshold_db: float = -40.0) -> bool:
    rms_db = audio.dBFS
    logging.info(f"🔍 RMS dBFS: {rms_db:.2f}")
    return rms_db < threshold_db


def has_enough_duration(audio: AudioSegment, min_duration_sec: float = 10.0) -> bool:
    return len(audio) >= min_duration_sec * 1000


def is_mostly_silence(path, threshold_db=-45.0, max_silent_ratio=0.5) -> bool:
    try:
        y, sr = librosa.load(path, sr=None)
        S = librosa.feature.rms(y=y)[0]
        silence = S < librosa.db_to_amplitude(threshold_db)
        silent_ratio = np.mean(silence)
        logging.info(f"🔍 Silent frames: {silent_ratio * 100:.1f}%")
        return silent_ratio > max_silent_ratio
    except Exception as e:
        logging.warning(f"⚠️ Ошибка анализа тишины: {e}")
        return False


def verify_mix(path: str) -> dict:
    logging.info(f"🔍 Проверка финального микса: {path}")

    if not os.path.exists(path):
        return {"ok": False, "reason": "no_file"}

    try:
        audio = AudioSegment.from_file(path)
    except Exception as e:
        logging.error(f"❌ Ошибка загрузки: {e}")
        return {"ok": False, "reason": "load_fail"}

    if not has_enough_duration(audio):
        return {"ok": False, "reason": "too_short"}

    if is_too_silent(audio):
        return {"ok": False, "reason": "too_silent"}

    if is_mostly_silence(path):
        return {"ok": False, "reason": "mostly_silent"}

    return {"ok": True}

# musicgen_wrapper.py

import torch
from audiocraft.models import musicgen
import torchaudio
from audiocraft.models.musicgen import MusicGen

model = None

def load_musicgen_model(path="D:/2027/audiocraft/audiocraft/models/facebook/musicgen-medium"):
    global model
    if model is None:
        model = musicgen.MusicGen.get_pretrained(path)
    return model

def generate_music(prompt: str, duration: int = 30):
    model = load_musicgen_model()
    model.set_generation_params(duration=duration)
    output = model.generate([prompt])
    return output[0].cpu(), model.sample_rate
