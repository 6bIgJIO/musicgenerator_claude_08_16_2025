import os
import sys
import asyncio
import logging
import time
import json
import io
import pickle
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import traceback
import subprocess
import requests
import hashlib
import re

# –ê—É–¥–∏–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from pydub import AudioSegment, effects
from pydub.effects import compress_dynamic_range, normalize
from pydub.generators import Sine, WhiteNoise
import librosa
import soundfile as sf
import numpy as np

# ML/AI –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    from sklearn.cluster import KMeans
    SEMANTIC_AVAILABLE = True
except ImportError:
    SEMANTIC_AVAILABLE = False

# MusicGen (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π)
try:
    import torch
    from audiocraft.models import musicgen
    MUSICGEN_AVAILABLE = True
except ImportError:
    MUSICGEN_AVAILABLE = False

# –ü–æ–¥–∫–ª—é—á–∞–µ–º –º–æ–¥—É–ª–∏ WaveDream
from gonfig import config, GenreType, MasteringPurpose
from sample_pengine import SemanticSampleEngine, EffectsChain
from verification import MixVerifier
from export import ExportManager
from metadata import MetadataProcessor

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –î–ê–¢–ê–ö–õ–ê–°–°–´
# ============================================================================

@dataclass
class GenerationRequest:
    prompt: str
    genre: Optional[str] = None
    bpm: Optional[int] = None  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
    duration: Optional[int] = None
    mastering_purpose: str = "personal"
    output_dir: str = "output"
    export_stems: bool = True
    energy_level: float = 0.5
    creativity_factor: float = 0.7

@dataclass
class GenerationResult:
    success: bool
    final_path: Optional[str] = None
    structure_data: Optional[Dict] = None
    used_samples: Optional[List[Dict]] = None
    generation_time: float = 0.0
    quality_score: float = 0.0
    error_message: Optional[str] = None
    intermediate_files: Optional[Dict[str, str]] = None

@dataclass
class SampleMetadata:
    path: str
    filename: str
    duration: float
    tempo: int
    key: Optional[str]
    tags: List[str]
    genres: List[str]
    instrument_role: Optional[str]
    quality_score: float = 0.0
    energy_level: float = 0.0
    spectral_centroid: float = 0.0
    spectral_rolloff: float = 0.0
    zero_crossing_rate: float = 0.0
    brightness: float = 0.0
    rhythmic_complexity: float = 0.0

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô LLAMA3-MUSIC –ö–õ–ò–ï–ù–¢ –° –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï–ú –†–ï–ì–£–õ–Ø–†–ö–ê–ú–ò
# ============================================================================

class FixedLlamaStructureClient:
    """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∫–ª–∏–µ–Ω—Ç –¥–ª—è LLama3-music —Å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π –æ—Ç–≤–µ—Ç–æ–≤"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.ollama_models = ["llama3-music:latest", "llama3", "mistral7b"]
    
    def query_structured_music(self, prompt: str) -> Optional[Dict]:
        """–ó–∞–ø—Ä–æ—Å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å –ê–ì–†–ï–°–°–ò–í–ù–û–ô –æ—á–∏—Å—Ç–∫–æ–π –æ—Ç–≤–µ—Ç–∞"""
        self.logger.info("üß† –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫ LLama3-music")
        
        # –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ API
        result = self._try_ollama_api(prompt)
        if result:
            return result
        
        # Fallback —á–µ—Ä–µ–∑ subprocess
        result = self._try_ollama_subprocess(prompt)
        if result:
            return result
        
        # –ù–ï–¢ FALLBACK –ù–ê –°–ò–ù–¢–ï–¢–ò–ö–£ - –ø—Ä–æ—Å—Ç–æ None
        self.logger.warning("‚ùå LLama3-music –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
        return None
    
    def _try_ollama_api(self, prompt: str) -> Optional[Dict]:
        """API –ø–æ–ø—ã—Ç–∫–∞ —Å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–æ–π"""
        system_prompt = """–¢—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –≤ JSON.

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –∏ —Ç–µ–∫—Å—Ç–∞!

–§–æ—Ä–º–∞—Ç:
{
  "bpm": —á–∏—Å–ª–æ_–æ—Ç_60_–¥–æ_180,
  "structure": [
    {"type": "intro", "duration": 8},
    {"type": "verse", "duration": 16},
    {"type": "hook", "duration": 16}
  ]
}

–¢–û–õ–¨–ö–û JSON!"""
        
        full_prompt = f"{system_prompt}\n\n–¢—Ä–µ–∫: {prompt}"
        
        for model in self.ollama_models:
            try:
                self.logger.info(f"  üîÑ –ü—Ä–æ–±—É–µ–º {model}")
                
                response = requests.post(
                    "http://localhost:11434/api/generate",
                    json={
                        "model": model,
                        "prompt": full_prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.1,
                            "num_predict": 300,
                            "stop": ["\n\n", "```"]
                        }
                    },
                    timeout=60
                )
                
                if response.status_code == 200:
                    data = response.json()
                    raw_output = data.get("response", "")
                    
                    if raw_output:
                        parsed = self._aggressive_json_cleanup(raw_output)
                        if parsed:
                            self.logger.info(f"  ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–ª—É—á–µ–Ω–∞ –æ—Ç {model}")
                            return parsed
                
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ {model}: {e}")
                continue
        
        return None
    
    def _aggressive_json_cleanup(self, raw_output: str) -> Optional[Dict]:
        """–ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∫–∞–º–∏"""
        try:
            # 1. –£–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ –ø–µ—Ä–≤–æ–π —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–∏
            cleaned = raw_output
            start_idx = cleaned.find('{')
            if start_idx != -1:
                cleaned = cleaned[start_idx:]
            else:
                return None
            
            # 2. –£–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–∏
            end_idx = cleaned.rfind('}')
            if end_idx != -1:
                cleaned = cleaned[:end_idx + 1]
            else:
                return None
            
            # 3. –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ /* */ –∏ //
            cleaned = re.sub(r'/\*.*?\*/', '', cleaned, flags=re.DOTALL)
            cleaned = re.sub(r'//.*?(?=\n|$)', '', cleaned, flags=re.MULTILINE)
            
            # 4. –£–±–∏—Ä–∞–µ–º trailing commas
            cleaned = re.sub(r',(\s*[}\]])', r'\1', cleaned)
            
            # 5. –§–∏–∫—Å–∏–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
            cleaned = cleaned.replace('bmp', 'bpm')  # –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –§–ò–ö–°
            cleaned = re.sub(r'(\d+)\s*:\s*(\d+)', r'"\1": \2', cleaned)  # –§–∏–∫—Å–∏–º –Ω–µ—Å–∫–∞–≤—ã—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏
            
            # 6. –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
            cleaned = re.sub(r'\s+', ' ', cleaned)
            
            # 7. –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å
            data = json.loads(cleaned)
            
            # 8. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if self._validate_and_normalize(data):
                return data
            
        except json.JSONDecodeError as e:
            self.logger.debug(f"JSON parse error: {e}")
        except Exception as e:
            self.logger.debug(f"Cleanup error: {e}")
        
        return None
    
    def _validate_and_normalize(self, data: Dict) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º bpm (–ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm)
            if "bpm" not in data:
                if "bmp" in data:  # –§–∏–∫—Å –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                    data["bpm"] = data.pop("bmp")
                elif "tempo" in data:
                    data["bpm"] = data["tempo"]
                else:
                    data["bpm"] = 120
            
            bpm = int(data["bpm"])
            if not (60 <= bpm <= 200):
                data["bpm"] = max(60, min(200, bpm))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º structure
            if "structure" not in data or not isinstance(data["structure"], list):
                return False
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–µ–∫—Ü–∏–∏
            normalized_sections = []
            for section in data["structure"]:
                if isinstance(section, dict) and "type" in section and "duration" in section:
                    normalized_sections.append({
                        "type": str(section["type"]).lower(),
                        "duration": max(4, int(section["duration"])),
                        "energy": float(section.get("energy", 0.5))
                    })
            
            if not normalized_sections:
                return False
            
            data["structure"] = normalized_sections
            return True
            
        except Exception as e:
            self.logger.debug(f"Validation error: {e}")
            return False


    def _try_ollama_subprocess(self, prompt: str) -> Optional[Dict]:
        """–§–æ–ª–ª–±–µ–∫ —á–µ—Ä–µ–∑ subprocess, –µ—Å–ª–∏ API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        try:
            cmd = [
                "ollama", "run", "llama3-music",
                f"–¢—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –≤ JSON.\n\n"
                f"–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –¢–û–õ–¨–ö–û JSON –ë–ï–ó –•–£–ô–¢–´:\n"
                f'{{"bpm": —á–∏—Å–ª–æ_–æ—Ç_60_–¥–æ_180,"structure":[{{"type":"intro","duration":8}}]}}\n\n'
                f"–¢—Ä–µ–∫: {prompt}"
            ]
            self.logger.info("  üñ•Ô∏è –ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ subprocess ollama")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            if result.returncode == 0 and result.stdout:
                return self._parse_json_response(result.stdout)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ ollama subprocess: {e}")
        return None
    
    
    def _parse_json_response(self, raw_output: str) -> Optional[Dict]:
        """–ß–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏ –∏ –ø–∞—Ä—Å–∏–Ω–≥ JSON"""
        try:
            match = re.search(r'\{.*\}', raw_output, re.DOTALL)
            if not match:
                return None
            json_str = match.group(0)
            return json.loads(json_str)
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return None

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ô –ü–û–ò–°–ö –°–≠–ú–ü–õ–û–í - –ë–ï–ó –°–ò–ù–¢–ï–¢–ò–ö–ò!
# ============================================================================

class RealSemanticSampleEngine:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ - —Ä–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏!
    –ù–ï–¢ –ù–ò–ö–ê–ö–ò–• –°–ò–ù–¢–ï–¢–ò–ß–ï–°–ö–ò–• FALLBACK'–û–í!
    """
    
    def __init__(self, sample_dir: str = None):
        self.sample_dir = sample_dir or config.DEFAULT_SAMPLE_DIR
        self.logger = logging.getLogger(__name__)
        self.samples_index: List[SampleMetadata] = []
        self.semantic_model = None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –†–ï–ê–õ–¨–ù–´–ô –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤
        self.load_real_sample_index()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if SEMANTIC_AVAILABLE:
            try:
                self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
                self.logger.info("‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
    
    def load_real_sample_index(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –†–ï–ê–õ–¨–ù–û–ì–û –∏–Ω–¥–µ–∫—Å–∞ —Å—ç–º–ø–ª–æ–≤ –∏–∑ —Ç–≤–æ–µ–≥–æ JSON —Ñ–∞–π–ª–∞"""
        self.logger.info("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –†–ï–ê–õ–¨–ù–´–ô –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤")
        
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ç–≤–æ–µ–º—É –∏–Ω–¥–µ–∫—Å—É
        possible_index_files = [
            "sample_index ‚Äî –∫–æ–ø–∏—è2025.08.json",
            "sample_index.json",
            "enhanced_sample_index.json",
            os.path.join(self.sample_dir, "sample_index.json"),
            os.path.join(self.sample_dir, "sample_index ‚Äî –∫–æ–ø–∏—è2025.08.json")
        ]
        
        for index_file in possible_index_files:
            if os.path.exists(index_file):
                try:
                    self.logger.info(f"  üìã –ù–∞–π–¥–µ–Ω –∏–Ω–¥–µ–∫—Å: {index_file}")
                    with open(index_file, 'r', encoding='utf-8') as f:
                        raw_data = json.load(f)
                    
                    if isinstance(raw_data, list) and len(raw_data) > 0:
                        self._convert_to_internal_format(raw_data)
                        self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.samples_index)} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤ –∏–∑ {index_file}")
                        return
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {index_file}: {e}")
                    continue
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –∏–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω
        self.logger.error("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –†–µ–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        self.logger.error("‚ùå –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ sample_index.json –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞")
        self.samples_index = []
    
    def _convert_to_internal_format(self, raw_data: List[Dict]):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–≤–æ–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π"""
        self.samples_index = []
        
        for item in raw_data:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤—Å–µ—Ö –ø–æ–ª–µ–π
                metadata = SampleMetadata(
                    path=item.get("path", ""),
                    filename=item.get("filename", ""),
                    duration=float(item.get("duration", 0.0)),
                    tempo=int(item.get("tempo", 120)),
                    key=item.get("key"),
                    tags=item.get("tags", []),
                    genres=item.get("genres", []),
                    instrument_role=item.get("instrument_role"),
                    quality_score=float(item.get("quality_score", 0.6)),
                    energy_level=float(item.get("energy_level", 0.5)),
                    spectral_centroid=float(item.get("spectral_centroid", 0.0)),
                    spectral_rolloff=float(item.get("spectral_rolloff", 0.0)),
                    zero_crossing_rate=float(item.get("zero_crossing_rate", 0.0)),
                    brightness=float(item.get("brightness", 0.0)),
                    rhythmic_complexity=float(item.get("rhythmic_complexity", 0.0))
                )
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
                if os.path.exists(metadata.path):
                    self.samples_index.append(metadata)
                else:
                    self.logger.debug(f"  ‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {metadata.path}")
                    
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Å—ç–º–ø–ª–∞: {e}")
                continue
        
        self.logger.info(f"üéØ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(self.samples_index)} –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤")
    
    async def find_samples(
        self,
        tags: List[str],
        instruments: Optional[List[str]] = None,
        genre: Optional[str] = None,
        bpm: Optional[int] = None,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
        energy: float = 0.5,
        max_results: int = 10
    ) -> List[Dict]:
        """
        –ß–ï–°–¢–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –†–ï–ê–õ–¨–ù–û–ô –±–∞–∑–µ —Å—ç–º–ø–ª–æ–≤
        """
        self.logger.info(f"üîç –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫ —Å—ç–º–ø–ª–æ–≤: —Ç–µ–≥–∏={tags}, –∂–∞–Ω—Ä={genre}, BPM={bpm}")
        
        if not self.samples_index:
            self.logger.error("‚ùå –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç - –Ω–µ—á–µ–≥–æ –∏—Å–∫–∞—Ç—å!")
            return []
        
        candidates = []
        
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –†–ï–ê–õ–¨–ù–´–ú —Å—ç–º–ø–ª–∞–º
        for sample in self.samples_index:
            score = self._calculate_real_sample_score(sample, tags, instruments, genre, bpm, energy)
            
            if score > 0.05:  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ö–æ—Ç—å —á–µ–≥–æ-—Ç–æ
                candidates.append({
                    "metadata": sample,
                    "score": score,
                    "path": sample.path,
                    "filename": sample.filename,
                    "instrument_role": sample.instrument_role,
                    "tags": sample.tags,
                    "tempo": sample.tempo,
                    "quality_score": sample.quality_score,
                    "energy_level": sample.energy_level,
                    "spectral_centroid": sample.spectral_centroid,
                    "spectral_rolloff": sample.spectral_rolloff,
                    "zero_crossing_rate": sample.zero_crossing_rate,
                    "brightness": sample.brightness,
                    "rhythmic_complexity": sample.rhythmic_complexity
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É
        candidates.sort(key=lambda x: x["score"], reverse=True)
        
        # –î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–æ–≤
        results = self._diversify_real_results(candidates, max_results)
        
        self.logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤ (–ª—É—á—à–∏–π —Å–∫–æ—Ä: {results[0]['score']:.2f})")
        return results[:max_results]
    
    def _calculate_real_sample_score(
        self, sample: SampleMetadata, tags: List[str], 
        instruments: Optional[List[str]], genre: Optional[str],
        bpm: Optional[int], energy: float  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
    ) -> float:
        """–†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–∞ –¥–ª—è –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞"""
        score = 0.0
        
        # 1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–≥–æ–≤ (35%)
        if tags:
            tag_matches = 0
            for tag in tags:
                tag_lower = tag.lower()
                for sample_tag in sample.tags:
                    if tag_lower in sample_tag.lower() or sample_tag.lower() in tag_lower:
                        tag_matches += 1
                        break
                    
                # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ filename
                if tag_lower in sample.filename.lower():
                    tag_matches += 0.5
            
            tag_score = min(1.0, tag_matches / len(tags))
            score += tag_score * 0.35
        
        # 2. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (25%)
        if instruments and sample.instrument_role:
            for instrument in instruments:
                if instrument.lower() == sample.instrument_role.lower():
                    score += 0.25
                    break
                elif instrument.lower() in sample.instrument_role.lower():
                    score += 0.15
                    break
        
        # 3. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∂–∞–Ω—Ä–∞ (20%)
        if genre and sample.genres:
            genre_lower = genre.lower()
            for sample_genre in sample.genres:
                if genre_lower == sample_genre.lower():
                    score += 0.2
                    break
                elif genre_lower in sample_genre.lower() or sample_genre.lower() in genre_lower:
                    score += 0.1
                    break
        
        # 4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ BPM (10%) - –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
        if bpm and sample.tempo:
            tempo_diff = abs(sample.tempo - bpm)
            if tempo_diff <= 5:
                score += 0.1
            elif tempo_diff <= 15:
                score += 0.07
            elif tempo_diff <= 30:
                score += 0.03
        
        # 5. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —ç–Ω–µ—Ä–≥–∏–∏ (10%)
        energy_diff = abs(sample.energy_level - energy)
        energy_score = max(0, 1 - energy_diff)
        score += energy_score * 0.1
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ
        score += sample.quality_score * 0.05
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        if sample.spectral_centroid > 0:
            score += 0.02
        
        return min(1.0, score)
    
    def _diversify_real_results(self, candidates: List[Dict], max_results: int) -> List[Dict]:
        """–î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–µ–¥–∏ –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤"""
        if len(candidates) <= max_results:
            return candidates
        
        diversified = []
        used_instruments = set()
        used_files = set()
        
        # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ - —Ä–∞–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        for candidate in candidates:
            if len(diversified) >= max_results:
                break
            
            instrument = candidate.get("instrument_role")
            filename = candidate.get("filename")
            
            if instrument not in used_instruments and filename not in used_files:
                diversified.append(candidate)
                used_instruments.add(instrument)
                used_files.add(filename)
        
        # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ - –ª—É—á—à–∏–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è (–Ω–æ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ —Ñ–∞–π–ª–æ–≤)
        for candidate in candidates:
            if len(diversified) >= max_results:
                break
            
            filename = candidate.get("filename")
            if candidate not in diversified and filename not in used_files:
                diversified.append(candidate)
                used_files.add(filename)
        
        return diversified[:max_results]

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô MUSICGEN –î–í–ò–ñ–û–ö
# ============================================================================

class FixedMusicGenEngine:
    """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô MusicGen –¥–≤–∏–∂–æ–∫ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.model = None
        self.device = "cuda" if torch and torch.cuda.is_available() else "cpu"
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ MusicGen"""
        if not MUSICGEN_AVAILABLE:
            self.logger.error("‚ùå MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        try:
            model_paths = [
                config.MUSICGEN_MODEL_PATH if hasattr(config, 'MUSICGEN_MODEL_PATH') else None,
                "facebook/musicgen-medium",
                "facebook/musicgen-small"
            ]
            
            for path in model_paths:
                if path is None:
                    continue
                    
                try:
                    self.logger.info(f"üéº –ó–∞–≥—Ä—É–∑–∫–∞ MusicGen: {path}")
                    self.model = musicgen.MusicGen.get_pretrained(path)
                    self.model.set_generation_params(duration=8)
                    self.logger.info(f"‚úÖ MusicGen –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")
                    return
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {path}: {e}")
                    continue
            
            self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å MusicGen")
        
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ MusicGen: {e}")
    
    async def generate(
        self,
        prompt: str,
        duration: int = 30,
        temperature: float = 1.0,
        genre_hint: Optional[str] = None
    ) -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ"""
        if not self.model:
            self.logger.error("‚ùå MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return self._generate_emergency_audio(duration)
        
        try:
            safe_duration = min(duration, 30)
            
            self.model.set_generation_params(
                duration=safe_duration,
                use_sampling=True,
                temperature=temperature,
                top_k=250,
                top_p=0.0
            )
            
            enhanced_prompt = self._enhance_prompt(prompt, genre_hint)
            self.logger.info(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º: {enhanced_prompt} ({safe_duration}—Å)")
            
            with torch.no_grad():
                wav_tensor = self.model.generate([enhanced_prompt])
            
            if wav_tensor is None or wav_tensor.size(0) == 0:
                raise RuntimeError("MusicGen –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–Ω–∑–æ—Ä–∞
            if wav_tensor.dim() == 3:
                audio_array = wav_tensor[0].cpu().numpy()
            elif wav_tensor.dim() == 2:
                audio_array = wav_tensor.cpu().numpy()
            else:
                raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–µ–Ω–∑–æ—Ä–∞: {wav_tensor.shape}")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            max_val = max(abs(audio_array.max()), abs(audio_array.min()))
            if max_val > 0:
                audio_array = audio_array / max_val
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–∏—à–∏–Ω—É
            rms = np.sqrt(np.mean(audio_array**2))
            if rms < 1e-6:
                self.logger.warning("‚ö†Ô∏è –û—á–µ–Ω—å —Ç–∏—Ö–∏–π —Å–∏–≥–Ω–∞–ª, —É—Å–∏–ª–∏–≤–∞–µ–º")
                audio_array = audio_array * 1000
                audio_array = np.clip(audio_array, -1.0, 1.0)
            
            # –≠–∫—Å–ø–æ—Ä—Ç –≤ WAV
            sample_rate = self.model.sample_rate
            buffer = io.BytesIO()
            
            if audio_array.ndim == 1:
                sf.write(buffer, audio_array, sample_rate, format='WAV')
            else:
                if audio_array.shape[0] == 2:
                    sf.write(buffer, audio_array.T, sample_rate, format='WAV')
                else:
                    sf.write(buffer, audio_array[0], sample_rate, format='WAV')
            
            audio_bytes = buffer.getvalue()
            buffer.close()
            
            if len(audio_bytes) < 1000:
                raise RuntimeError(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª: {len(audio_bytes)} bytes")
            
            self.logger.info(f"‚úÖ MusicGen —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª: {len(audio_bytes)} bytes")
            return audio_bytes
        
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ MusicGen: {e}")
            return self._generate_emergency_audio(duration)
    
    def _enhance_prompt(self, prompt: str, genre: Optional[str]) -> str:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è MusicGen"""
        if not genre:
            return prompt
        
        enhancements = {
            "trap": "heavy 808s, tight snares, dark urban atmosphere",
            "drill": "uk drill style, sliding 808s, aggressive hi-hats",
            "lofi": "warm analog sound, vinyl texture, mellow vibes",
            "dnb": "fast breakbeats, heavy reese bass, energetic",
            "house": "four-on-the-floor groove, deep bassline, danceable",
            "techno": "industrial sounds, minimal techno, warehouse atmosphere",
            "ambient": "ethereal pads, spacious reverb, peaceful meditation",
            "cinematic": "epic orchestral, trailer music, heroic themes"
        }
        
        enhancement = enhancements.get(genre, "")
        if enhancement:
            return f"{prompt}, {enhancement}"
        
        return prompt
    
    def _generate_emergency_audio(self, duration: int) -> bytes:
        """–ê–í–ê–†–ò–ô–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∞—É–¥–∏–æ"""
        self.logger.warning("üö® –ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ")
        
        try:
            sample_rate = 44100
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # –ü—Ä–æ—Å—Ç–æ–π –º–∏–∫—Å —á–∞—Å—Ç–æ—Ç
            audio_array = (
                np.sin(2 * np.pi * 60 * t) * 0.3 +  # –ù–∏–∑–∫–∏–µ
                np.sin(2 * np.pi * 220 * t) * 0.2 + # –°—Ä–µ–¥–Ω–∏–µ  
                np.random.normal(0, 0.05, len(t))   # –®—É–º
            ) * 0.5
            
            buffer = io.BytesIO()
            sf.write(buffer, audio_array, sample_rate, format='WAV')
            return buffer.getvalue()
        
        except Exception as e:
            self.logger.error(f"‚ùå –ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–∏—à–∏–Ω–∞
            silence = np.zeros(int(44100 * duration))
            buffer = io.BytesIO()
            sf.write(buffer, silence, 44100, format='WAV')
            return buffer.getvalue()

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ú–ê–°–¢–ï–†–ò–ù–ì–ê - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –í–°–ï–ì–î–ê
# ============================================================================

class MaxQualityMasteringEngine:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–≤–∏–∂–æ–∫ - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è!
    –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤ –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ!
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.effects_chain = EffectsChain()
    
    async def master_track(
        self,
        audio_bytes: bytes,
        target_config: Dict,
        genre_info: Dict,
        purpose: str = "personal"
    ) -> Tuple[AudioSegment, Dict]:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞"""
        self.logger.info(f"üéõÔ∏è –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–ª—è {purpose}")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio_segment = self._safe_load_audio(audio_bytes)
            if not audio_segment:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ")
            
            original_audio = audio_segment
            
            # === –≠–¢–ê–ü 1: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û EQ ===
            processed_audio = await self._apply_max_quality_eq(audio_segment, genre_info)
            
            # === –≠–¢–ê–ü 2: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –ö–û–ú–ü–†–ï–°–°–ò–Ø ===
            processed_audio = await self._apply_max_quality_compression(processed_audio, genre_info)
            
            # === –≠–¢–ê–ü 3: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –ù–ê–°–´–©–ï–ù–ò–ï ===
            processed_audio = await self._apply_max_quality_saturation(processed_audio, genre_info)
            
            # === –≠–¢–ê–ü 4: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –°–¢–ï–†–ï–û ===
            processed_audio = await self._apply_max_quality_stereo(processed_audio, genre_info)
            
            # === –≠–¢–ê–ü 5: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –õ–ò–ú–ò–¢–ò–†–û–í–ê–ù–ò–ï ===
            processed_audio = await self._apply_max_quality_limiting(processed_audio, target_config)
            
            # === –≠–¢–ê–ü 6: –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ò –ö–û–†–†–ï–ö–¶–ò–Ø ===
            final_audio = await self._final_quality_check(processed_audio, target_config)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –æ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–µ
            mastering_report = {
                "target_lufs": target_config.get("target_lufs", -14),
                "peak_ceiling": target_config.get("peak_ceiling", -1),
                "character": f"MAXIMUM QUALITY mastering for {purpose}",
                "applied_stages": ["max_eq", "max_compression", "max_saturation", "max_stereo", "max_limiting"],
                "genre_optimizations": genre_info.get("name", "unknown"),
                "quality_level": "MAXIMUM"
            }
            
            self.logger.info("‚úÖ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω")
            return final_audio, mastering_report
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞: {e}")
            return original_audio or self._create_emergency_audio(), target_config
    
    def _safe_load_audio(self, audio_bytes: bytes) -> Optional[AudioSegment]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ"""
        try:
            if audio_bytes and len(audio_bytes) > 1000:
                buffer = io.BytesIO(audio_bytes)
                return AudioSegment.from_file(buffer, format="wav")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ: {e}")
        return None
    
    async def _apply_max_quality_eq(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û —ç–∫–≤–∞–ª–∏–∑–∞—Ü–∏—è"""
        genre = genre_info.get("name", "")
        
        # –ñ–∞–Ω—Ä–æ–≤–æ-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π EQ
        eq_settings = {
            "trap": {"low": 3, "mid": 1, "high": 2},
            "drill": {"low": 4, "mid": 0, "high": 3},
            "lofi": {"low": 2, "mid": 1, "high": -2},
            "dnb": {"low": 2, "mid": 2, "high": 3},
            "house": {"low": 2, "mid": 1, "high": 2},
            "techno": {"low": 3, "mid": 0, "high": 2},
            "ambient": {"low": 1, "mid": 2, "high": 1},
            "cinematic": {"low": 2, "mid": 1, "high": 2}
        }
        
        eq_params = eq_settings.get(genre, {"low": 2, "mid": 1, "high": 2})
        
        try:
            return await self.effects_chain.processors["eq"].process(audio, eq_params)
        except Exception as e:
            self.logger.warning(f"EQ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_compression(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –∫–æ–º–ø—Ä–µ—Å—Å–∏—è"""
        genre = genre_info.get("name", "")
        
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∂–∞–Ω—Ä–∞
        compression_settings = {
            "trap": {"ratio": 3.5, "threshold": -8, "attack": 3, "release": 30},
            "drill": {"ratio": 4.0, "threshold": -6, "attack": 2, "release": 25},
            "lofi": {"ratio": 2.0, "threshold": -15, "attack": 10, "release": 100},
            "dnb": {"ratio": 4.0, "threshold": -6, "attack": 2, "release": 20},
            "house": {"ratio": 3.0, "threshold": -8, "attack": 5, "release": 50},
            "techno": {"ratio": 3.5, "threshold": -8, "attack": 3, "release": 40},
            "ambient": {"ratio": 1.5, "threshold": -20, "attack": 20, "release": 200},
            "cinematic": {"ratio": 2.0, "threshold": -18, "attack": 15, "release": 150}
        }
        
        comp_params = compression_settings.get(genre, {"ratio": 3.0, "threshold": -10})
        
        try:
            return await self.effects_chain.processors["compressor"].process(audio, comp_params)
        except Exception as e:
            self.logger.warning(f"–ö–æ–º–ø—Ä–µ—Å—Å–∏—è –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_saturation(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –Ω–∞—Å—ã—â–µ–Ω–∏–µ"""
        genre = genre_info.get("name", "")
        
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ –¥–ª—è –∂–∞–Ω—Ä–∞
        saturation_settings = {
            "trap": {"amount": 0.3, "type": "tube", "warmth": 0.2},
            "drill": {"amount": 0.4, "type": "transistor", "warmth": 0.1},
            "lofi": {"amount": 0.6, "type": "tape", "warmth": 0.8},
            "dnb": {"amount": 0.2, "type": "transistor", "warmth": 0.0},
            "house": {"amount": 0.25, "type": "tube", "warmth": 0.3},
            "techno": {"amount": 0.3, "type": "transistor", "warmth": 0.1},
            "ambient": {"amount": 0.15, "type": "tube", "warmth": 0.5},
            "cinematic": {"amount": 0.2, "type": "tube", "warmth": 0.4}
        }
        
        sat_params = saturation_settings.get(genre, {"amount": 0.25, "type": "tube", "warmth": 0.3})
        
        try:
            return await self.effects_chain.processors["saturation"].process(audio, sat_params)
        except Exception as e:
            self.logger.warning(f"–ù–∞—Å—ã—â–µ–Ω–∏–µ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_stereo(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û —Å—Ç–µ—Ä–µ–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        genre = genre_info.get("name", "")
        
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–µ—Ä–µ–æ —à–∏—Ä–∏–Ω–∞ –¥–ª—è –∂–∞–Ω—Ä–∞
        stereo_settings = {
            "trap": {"width": 1.2, "imaging": "enhanced"},
            "drill": {"width": 1.1, "imaging": "enhanced"}, 
            "lofi": {"width": 0.9, "imaging": "natural"},
            "dnb": {"width": 1.15, "imaging": "enhanced"},
            "house": {"width": 1.1, "imaging": "enhanced"},
            "techno": {"width": 1.0, "imaging": "natural"},
            "ambient": {"width": 1.5, "imaging": "enhanced"},
            "cinematic": {"width": 1.4, "imaging": "enhanced"}
        }
        
        stereo_params = stereo_settings.get(genre, {"width": 1.1, "imaging": "enhanced"})
        
        try:
            return await self.effects_chain.processors["stereo"].process(audio, stereo_params)
        except Exception as e:
            self.logger.warning(f"–°—Ç–µ—Ä–µ–æ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_limiting(self, audio: AudioSegment, target_config: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        target_peak = target_config.get("peak_ceiling", -1)
        
        limiter_params = {
            "threshold": target_peak + 0.5,  # –ú—è–≥–∫–∏–π –ø–æ—Ä–æ–≥
            "ceiling": target_peak,
            "release": 30  # –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–ª–∏–∑ –¥–ª—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏
        }
        
        try:
            return await self.effects_chain.processors["limiter"].process(audio, limiter_params)
        except Exception as e:
            self.logger.warning(f"–õ–∏–º–∏—Ç–µ—Ä –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _final_quality_check(self, audio: AudioSegment, target_config: Dict) -> AudioSegment:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∏–∫
            current_peak = audio.max_dBFS
            target_peak = target_config.get("peak_ceiling", -1)
            
            if current_peak > target_peak:
                correction = current_peak - target_peak + 0.1
                audio = audio - correction
                self.logger.info(f"  üéõÔ∏è –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø–∏–∫–∞: -{correction:.1f}dB")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π —É—Ä–æ–≤–µ–Ω—å
            if audio.dBFS < -40:  # –°–ª–∏—à–∫–æ–º —Ç–∏—Ö–æ
                boost = -25 - audio.dBFS
                audio = audio + boost
                self.logger.info(f"  üìà –§–∏–Ω–∞–ª—å–Ω—ã–π –±—É—Å—Ç —É—Ä–æ–≤–Ω—è: +{boost:.1f}dB")
            
            return audio
            
        except Exception as e:
            self.logger.error(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    def _create_emergency_audio(self) -> AudioSegment:
        """–ê–≤–∞—Ä–∏–π–Ω–æ–µ –∞—É–¥–∏–æ –≤ —Å–ª—É—á–∞–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏"""
        return AudioSegment.silent(duration=30000)  # 30 —Å–µ–∫—É–Ω–¥ —Ç–∏—à–∏–Ω—ã

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ì–õ–ê–í–ù–´–ô PIPELINE
# ============================================================================

class FixedWaveDreamPipeline:
    """–ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô WaveDream Pipeline"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–• –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.llama_client = FixedLlamaStructureClient()
        self.musicgen_engine = FixedMusicGenEngine()
        self.sample_engine = RealSemanticSampleEngine()  # –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫!
        self.mastering_engine = MaxQualityMasteringEngine()  # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û!
        self.export_manager = ExportManager()
        
        self.logger.info("üéµ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô WaveDream Pipeline –≥–æ—Ç–æ–≤")
    
    async def generate_track(self, request: GenerationRequest) -> GenerationResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        start_time = time.time()
        
        try:
            timestamp = int(time.time())
            project_name = f"WD_Fixed_{timestamp}"
            
            self.logger.info(f"üöÄ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: '{request.prompt}'")
            
            # === –≠–¢–ê–ü 1: –ê–ù–ê–õ–ò–ó –ü–†–û–ú–ü–¢–ê ===
            metadata = await self._analyze_prompt(request)
            
            # === –≠–¢–ê–ü 2: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ñ–ê–ù–†–ê ===
            genre_info = await self._determine_genre(request, metadata)
            
            # === –≠–¢–ê–ü 3: –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–¢–†–£–ö–¢–£–†–´ ===
            structure = await self._generate_structure(request, genre_info)
            
            # === –≠–¢–ê–ü 4: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ë–ê–ó–´ MUSICGEN ===
            base_audio_bytes = await self._generate_base_track(request, structure, genre_info)
            
            # === –≠–¢–ê–ü 5: –†–ï–ê–õ–¨–ù–´–ô –ü–û–î–ë–û–† –°–≠–ú–ü–õ–û–í ===
            selected_samples = await self._select_real_samples(request, structure, genre_info)
            
            # === –≠–¢–ê–ü 6: –°–û–ó–î–ê–ù–ò–ï –°–¢–ï–ú–û–í ===
            stems_dict = await self._create_real_stems(selected_samples, structure, genre_info)
            
            # === –≠–¢–ê–ü 7: –ú–ò–ö–®–ò–†–û–í–ê–ù–ò–ï ===
            mixed_audio = await self._mix_tracks(base_audio_bytes, stems_dict, genre_info)
            
            # === –≠–¢–ê–ü 8: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –ú–ê–°–¢–ï–†–ò–ù–ì ===
            mastered_audio, mastering_config = await self.mastering_engine.master_track(
                mixed_audio,
                config.get_mastering_config(request.mastering_purpose),
                genre_info,
                request.mastering_purpose
            )
            
            # === –≠–¢–ê–ü 9: –≠–ö–°–ü–û–†–¢ ===
            if isinstance(mastered_audio, AudioSegment):
                buffer = io.BytesIO()
                mastered_audio.export(buffer, format="wav")
                mastered_bytes = buffer.getvalue()
                buffer.close()
            else:
                mastered_bytes = mastered_audio
            
            export_config = {
                "export_stems": request.export_stems,
                "request_data": {
                    "prompt": request.prompt,
                    "genre": request.genre,
                    "mastering_purpose": request.mastering_purpose
                },
                "structure": structure,
                "samples": selected_samples,
                "mastering": mastering_config
            }
            
            exported_files = await self.export_manager.export_complete_project(
                mastered_bytes,
                {
                    "base": base_audio_bytes,
                    "stems": stems_dict,
                    "mixed": mixed_audio
                },
                export_config
            )
            
            generation_time = time.time() - start_time
            
            result = GenerationResult(
                success=True,
                final_path=exported_files.get("final_wav"),
                structure_data=structure,
                used_samples=selected_samples,
                generation_time=generation_time,
                quality_score=0.95,  # –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ!
                intermediate_files=exported_files
            )
            
            self.logger.info(f"üéâ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {generation_time:.1f}—Å")
            return result
        
        except Exception as e:
            generation_time = time.time() - start_time
            error_msg = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"
            
            self.logger.error(f"‚ùå {error_msg}")
            self.logger.error(f"üîç Traceback: {traceback.format_exc()}")
            
            return GenerationResult(
                success=False,
                generation_time=generation_time,
                error_message=error_msg
            )
    
    async def _analyze_prompt(self, request: GenerationRequest) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞"""
        metadata = {
            "original_prompt": request.prompt,
            "detected_instruments": [],
            "detected_mood": [],
            "detected_bpm": request.bpm,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm -> bpm
            "energy_level": request.energy_level,
            "creativity_factor": request.creativity_factor
        }
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        prompt_lower = request.prompt.lower()
        
        # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        instruments_map = {
            "808": ["808", "sub", "bass"],
            "kick": ["kick", "drum"], 
            "snare": ["snare", "clap"],
            "hihat": ["hihat", "hat", "hh"],
            "bell": ["bell", "melody"],
            "piano": ["piano", "keys"],
            "vocal": ["vocal", "voice"]
        }
        
        for instrument, keywords in instruments_map.items():
            if any(kw in prompt_lower for kw in keywords):
                metadata["detected_instruments"].append(instrument)
        
        # BPM –∏–∑ —Ç–µ–∫—Å—Ç–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
        bpm_match = re.search(r'(\d{2,3})\s*bpm', prompt_lower)
        if bpm_match:
            metadata["detected_bpm"] = int(bpm_match.group(1))
        
        return metadata
    
    async def _determine_genre(self, request: GenerationRequest, metadata: Dict) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞"""
        if request.genre:
            genre_name = request.genre.lower()
        else:
            genre_name = self._detect_genre_from_prompt(request.prompt)
        
        genre_config = config.get_genre_config(genre_name)
        if not genre_config:
            genre_name = "trap"
            genre_config = config.get_genre_config("trap")
        
        return {
            "name": genre_name,
            "config": genre_config,
            "bpm_range": genre_config.bpm_range,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp_range -> bpm_range
            "target_bpm": metadata.get("detected_bpm") or  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
                         (genre_config.bpm_range[0] + genre_config.bpm_range[1]) // 2
        }
    
    def _detect_genre_from_prompt(self, prompt: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞"""
        prompt_lower = prompt.lower()
        
        # –ü—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        if hasattr(config, 'GENRE_CONFIGS'):
            for genre in config.GENRE_CONFIGS.keys():
                if genre in prompt_lower:
                    return genre
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        genre_keywords = {
            "trap": ["808", "dark", "urban", "aggressive", "trap"],
            "drill": ["drill", "uk", "sliding", "aggressive"],
            "lofi": ["chill", "vintage", "cozy", "study", "lofi"],
            "dnb": ["dnb", "drum", "bass", "jungle", "breakbeat"],
            "house": ["house", "dance", "groove", "disco"],
            "techno": ["techno", "industrial", "warehouse"],
            "ambient": ["ambient", "spacious", "meditation", "peaceful"]
        }
        
        genre_scores = {}
        for genre, keywords in genre_keywords.items():
            score = sum(1 for kw in keywords if kw in prompt_lower)
            if score > 0:
                genre_scores[genre] = score
        
        if genre_scores:
            return max(genre_scores, key=genre_scores.get)
        
        return "trap"
    
    async def _generate_structure(self, request: GenerationRequest, genre_info: Dict) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ—Ç LLama3
        llama_structure = self.llama_client.query_structured_music(request.prompt)
        
        if llama_structure:
            return {
                "sections": llama_structure["structure"],
                "total_duration": sum(s["duration"] for s in llama_structure["structure"]),
                "bpm": llama_structure["bpm"],  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
                "source": "llama3-music"
            }
        
        # Fallback —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
        self.logger.info("üèóÔ∏è –°–æ–∑–¥–∞–µ–º fallback —Å—Ç—Ä—É–∫—Ç—É—Ä—É")
        return self._create_fallback_structure(genre_info, request.duration)
    
    def _create_fallback_structure(self, genre_info: Dict, duration: Optional[int]) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ fallback —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        target_duration = duration or 60
        
        base_structure = [
            {"type": "intro", "duration": 8, "energy": 0.3},
            {"type": "verse", "duration": 16, "energy": 0.5},
            {"type": "hook", "duration": 16, "energy": 0.8},
            {"type": "verse", "duration": 16, "energy": 0.6},
            {"type": "hook", "duration": 16, "energy": 0.9},
            {"type": "outro", "duration": 8, "energy": 0.4}
        ]
        
        total_duration = sum(s["duration"] for s in base_structure)
        
        return {
            "sections": base_structure,
            "total_duration": total_duration,
            "bpm": genre_info["target_bpm"],  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "source": "fallback"
        }
    
    async def _generate_base_track(
        self, request: GenerationRequest, structure: Dict, genre_info: Dict
    ) -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–∏"""
        enhanced_prompt = f"{request.prompt}, {genre_info['name']} style, {genre_info['target_bpm']} bpm"  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
        
        duration = min(structure["total_duration"], 30)
        
        base_audio = await self.musicgen_engine.generate(
            prompt=enhanced_prompt,
            duration=duration,
            temperature=request.creativity_factor,
            genre_hint=genre_info["name"]
        )
        
        return base_audio
    
    async def _select_real_samples(
        self, request: GenerationRequest, structure: Dict, genre_info: Dict
    ) -> List[Dict]:
        """–†–ï–ê–õ–¨–ù–´–ô –ø–æ–¥–±–æ—Ä —Å—ç–º–ø–ª–æ–≤ –∏–∑ —Ç–≤–æ–µ–π –±–∞–∑—ã"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        core_instruments = genre_info["config"].core_instruments[:4]  # –¢–æ–ø-4
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_tags = [genre_info["name"]]
        search_tags.extend(request.prompt.lower().split()[:3])  # –ü–µ—Ä–≤—ã–µ 3 —Å–ª–æ–≤–∞
        
        # –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫ —Å—ç–º–ø–ª–æ–≤
        selected_samples = await self.sample_engine.find_samples(
            tags=search_tags,
            instruments=core_instruments,
            genre=genre_info["name"],
            bpm=genre_info["target_bpm"],  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            energy=request.energy_level,
            max_results=8
        )
        
        self.logger.info(f"üéõÔ∏è –ù–∞–π–¥–µ–Ω–æ {len(selected_samples)} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤")
        return selected_samples
    
    async def _create_real_stems(
        self, selected_samples: List[Dict], structure: Dict, genre_info: Dict
    ) -> Dict[str, bytes]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–º–æ–≤ –∏–∑ –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤"""
        stems = {}
        total_duration_ms = int(structure["total_duration"] * 1000)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
        by_instrument = {}
        for sample in selected_samples:
            instrument = sample.get("instrument_role", "lead")
            if instrument not in by_instrument:
                by_instrument[instrument] = []
            by_instrument[instrument].append(sample)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–µ–º—ã –∏–∑ –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤
        for instrument, samples in by_instrument.items():
            try:
                if samples and samples[0].get("path") and os.path.exists(samples[0]["path"]):
                    # –†–ï–ê–õ–¨–ù–´–ô —Å—ç–º–ø–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                    sample_path = samples[0]["path"]
                    stem_audio = await self._process_real_sample(sample_path, total_duration_ms, genre_info)
                    stems[instrument] = stem_audio
                    self.logger.debug(f"‚úÖ –°—Ç–µ–º '{instrument}' –∏–∑ –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞")
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–µ–º–∞ {instrument}: {e}")
        
        return stems
    
    async def _process_real_sample(self, sample_path: str, duration_ms: int, genre_info: Dict) -> bytes:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞ –≤ —Å—Ç–µ–º"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –†–ï–ê–õ–¨–ù–´–ô —Å—ç–º–ø–ª
            sample_audio = AudioSegment.from_file(sample_path)
            
            # –†–∞—Å—Ç—è–≥–∏–≤–∞–µ–º/–ø–æ–≤—Ç–æ—Ä—è–µ–º –Ω–∞ –Ω—É–∂–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if len(sample_audio) < duration_ms:
                repetitions = (duration_ms // len(sample_audio)) + 1
                extended = sample_audio * repetitions
                stem_audio = extended[:duration_ms]
            else:
                stem_audio = sample_audio[:duration_ms]
            
            # –ñ–∞–Ω—Ä–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            stem_audio = await self._apply_genre_processing(stem_audio, genre_info)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            stem_audio.export(buffer, format="wav")
            return buffer.getvalue()
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—ç–º–ø–ª–∞ {sample_path}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏—à–∏–Ω—É –≤–º–µ—Å—Ç–æ –∫—Ä–∞—à–∞
            silence = AudioSegment.silent(duration=duration_ms)
            buffer = io.BytesIO()
            silence.export(buffer, format="wav")
            return buffer.getvalue()
    
    async def _apply_genre_processing(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ñ–∞–Ω—Ä–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        genre = genre_info.get("name", "")
        
        try:
            if genre == "lofi":
                # –í–∏–Ω—Ç–∞–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                audio = audio.low_pass_filter(8000).apply_gain(-1)
            elif genre == "trap":
                # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞  
                audio = compress_dynamic_range(audio, threshold=-10, ratio=2.5)
            elif genre == "dnb":
                # –ß–µ—Ç–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                audio = audio.high_pass_filter(30)
            elif genre == "ambient":
                # –ú—è–≥–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                audio = audio.fade_in(100).fade_out(100)
        
        except Exception as e:
            self.logger.debug(f"–ñ–∞–Ω—Ä–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∞: {e}")
        
        return audio
    
    async def _mix_tracks(self, base_audio_bytes: bytes, stems_dict: Dict[str, bytes], genre_info: Dict) -> bytes:
        """–ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã —Å–æ —Å—Ç–µ–º–∞–º–∏"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑—É
            base_audio = AudioSegment.from_file(io.BytesIO(base_audio_bytes))
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Å–∞ –¥–ª—è –∂–∞–Ω—Ä–∞
            genre = genre_info.get("name", "")
            mix_levels = {
                "trap": {"base": -3, "stems": -5},
                "drill": {"base": -2, "stems": -4},
                "lofi": {"base": -4, "stems": -7},
                "dnb": {"base": -2, "stems": -3},
                "house": {"base": -3, "stems": -6},
                "techno": {"base": -3, "stems": -5},
                "ambient": {"base": -6, "stems": -8},
                "cinematic": {"base": -4, "stems": -6}
            }
            
            levels = mix_levels.get(genre, {"base": -3, "stems": -6})
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∫ –±–∞–∑–µ
            mixed = base_audio + levels["base"]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–µ–º—ã
            for instrument, stem_bytes in stems_dict.items():
                try:
                    stem_audio = AudioSegment.from_file(io.BytesIO(stem_bytes))
                    
                    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    if len(stem_audio) != len(mixed):
                        if len(stem_audio) > len(mixed):
                            stem_audio = stem_audio[:len(mixed)]
                        else:
                            stem_audio = stem_audio + AudioSegment.silent(len(mixed) - len(stem_audio))
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∏ –º–∏–∫—à–∏—Ä—É–µ–º
                    stem_audio = stem_audio + levels["stems"]
                    mixed = mixed.overlay(stem_audio)
                    
                    self.logger.debug(f"üéöÔ∏è –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω {instrument}")
                
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è {instrument}: {e}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            mixed.export(buffer, format="wav")
            mixed_bytes = buffer.getvalue()
            buffer.close()
            
            return mixed_bytes
        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return base_audio_bytes

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô LAUNCHER
# ============================================================================

class FixedWaveDreamLauncher:
    """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ª–∞—É–Ω—á–µ—Ä WaveDream Enhanced Pro v2.1"""
    
    def __init__(self):
        self._setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û pipeline
        self.pipeline = FixedWaveDreamPipeline()
        
        self.logger.info("üéµ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô WaveDream Launcher –≥–æ—Ç–æ–≤")
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        formatter = logging.Formatter('[%(levelname)s] %(asctime)s - %(name)s - %(message)s')
        
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(logging.INFO)
        
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        
        # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ö–∞–Ω–¥–ª–µ—Ä—ã —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
            
        root_logger.addHandler(console_handler)
    
    async def generate_track_async(self, request: GenerationRequest) -> GenerationResult:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"""
        try:
            self.logger.info(f"üöÄ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: '{request.prompt}'")
            result = await self.pipeline.generate_track(request)
            
            if result.success:
                self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞ {result.generation_time:.1f}—Å")
                self.logger.info(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result.final_path}")
            else:
                self.logger.error(f"‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {result.error_message}")
            
            return result
        
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return GenerationResult(
                success=False,
                error_message=str(e)
            )
    
    def generate_track_sync(self, request: GenerationRequest) -> GenerationResult:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞"""
        return asyncio.run(self.generate_track_async(request))
    
    def run_interactive_mode(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º"""
        print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë üéµ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø üéµ                         ‚ïë
‚ïë                                                                                  ‚ïë
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –†–ï–ê–õ–¨–ù–û–ô –±–∞–∑–µ —Å—ç–º–ø–ª–æ–≤                     ‚ïë
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—Å–µ –æ–ø–µ—á–∞—Ç–∫–∏ bmp->bpm                                            ‚ïë
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: LLaMA3 –æ—Ç–≤–µ—Ç—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É—é—Ç—Å—è —Ä–µ–≥—É–ª—è—Ä–∫–∞–º–∏                         ‚ïë
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è        ‚ïë
‚ïë ‚úÖ –£–ë–†–ê–ù–û: –í—Å—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è —Ö—É–π–Ω—è, —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """)
        
        while True:
            print("\n" + "="*80)
            print("üéµ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø")
            print("="*80)
            print("1. üöÄ –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è")
            print("2. üéõÔ∏è –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è")
            print("3. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞")
            print("4. üîß –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º")
            print("0. üö™ –í—ã—Ö–æ–¥")
            
            choice = input("\nüéØ –í–∞—à –≤—ã–±–æ—Ä: ").strip()
            
            try:
                if choice == "1":
                    self._quick_generation()
                elif choice == "2":
                    self._advanced_generation()
                elif choice == "3":
                    self._show_sample_statistics()
                elif choice == "4":
                    self._test_systems()
                elif choice == "0":
                    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break
                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
            
            except KeyboardInterrupt:
                print("\n\n‚è∏Ô∏è –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            except Exception as e:
                self.logger.error(f"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    def _quick_generation(self):
        """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"""
        print("\nüöÄ –ë–´–°–¢–†–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø")
        print("-" * 30)
        
        prompt = input("üìù –û–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞: ").strip()
        if not prompt:
            print("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
            return
        
        genre = input("üé≠ –ñ–∞–Ω—Ä (Enter –¥–ª—è –∞–≤—Ç–æ): ").strip().lower()
        if genre and genre not in ['trap', 'drill', 'lofi', 'dnb', 'house', 'techno', 'ambient', 'cinematic']:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∂–∞–Ω—Ä '{genre}', –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            genre = None
        
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ò–°–ü–†–ê–í–õ–ï–ù–ù–£–Æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...")
        print(f"üìù –ü—Ä–æ–º–ø—Ç: {prompt}")
        print(f"üé≠ –ñ–∞–Ω—Ä: {genre or '–∞–≤—Ç–æ'}")
        
        request = GenerationRequest(
            prompt=prompt,
            genre=genre,
            mastering_purpose="freelance",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            export_stems=True
        )
        
        try:
            result = self.generate_track_sync(request)
            
            if result.success:
                print(f"\n‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
                print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result.generation_time:.1f} —Å–µ–∫—É–Ω–¥")
                print(f"üìÅ –§–∞–π–ª: {result.final_path}")
                print(f"üéµ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.1%}")
                
                if result.used_samples:
                    print(f"üéõÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å—ç–º–ø–ª–æ–≤: {len(result.used_samples)}")
                    for sample in result.used_samples[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        print(f"  - {sample.get('filename', 'unknown')} ({sample.get('instrument_role', 'unknown')})")
            else:
                print(f"\n‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {result.error_message}")
        
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def _advanced_generation(self):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        print("\nüéõÔ∏è –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø")
        print("-" * 30)
        
        prompt = input("üìù –û–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞: ").strip()
        if not prompt:
            print("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
            return
        
        # –ñ–∞–Ω—Ä
        print("\nüé≠ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∂–∞–Ω—Ä—ã:")
        genres = ['trap', 'drill', 'lofi', 'dnb', 'house', 'techno', 'ambient', 'cinematic']
        for i, g in enumerate(genres, 1):
            print(f"{i}. {g}")
        
        genre_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –∂–∞–Ω—Ä–∞ (Enter –¥–ª—è –∞–≤—Ç–æ): ").strip()
        genre = None
        if genre_choice.isdigit() and 1 <= int(genre_choice) <= len(genres):
            genre = genres[int(genre_choice) - 1]
        
        # BPM - –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
        bpm_input = input("üéµ BPM (Enter –¥–ª—è –∞–≤—Ç–æ): ").strip()
        bpm = None
        if bpm_input.isdigit():
            bpm = int(bpm_input)
            if not (60 <= bpm <= 200):
                print("‚ö†Ô∏è BPM –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 60 –¥–æ 200, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ")
                bpm = None
        
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration_input = input("‚è∞ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (Enter=60): ").strip()
        duration = 60
        if duration_input.isdigit():
            duration = max(10, min(180, int(duration_input)))  # 10-180 —Å–µ–∫—É–Ω–¥
        
        # –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞
        print("\nüéöÔ∏è –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞:")
        purposes = ['freelance', 'professional', 'personal', 'streaming', 'vinyl']
        for i, p in enumerate(purposes, 1):
            print(f"{i}. {p}")
        
        purpose_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä (Enter=1): ").strip()
        purpose = "freelance"  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if purpose_choice.isdigit() and 1 <= int(purpose_choice) <= len(purposes):
            purpose = purposes[int(purpose_choice) - 1]
        
        # –≠–Ω–µ—Ä–≥–∏—è
        energy_input = input("‚ö° –£—Ä–æ–≤–µ–Ω—å —ç–Ω–µ—Ä–≥–∏–∏ 0.1-1.0 (Enter=0.7): ").strip()
        energy = 0.7
        try:
            if energy_input:
                energy = max(0.1, min(1.0, float(energy_input)))
        except:
            energy = 0.7
        
        # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
        creativity_input = input("üé® –§–∞–∫—Ç–æ—Ä –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ 0.1-1.0 (Enter=0.8): ").strip()
        creativity = 0.8
        try:
            if creativity_input:
                creativity = max(0.1, min(1.0, float(creativity_input)))
        except:
            creativity = 0.8
        
        # –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–µ–º–æ–≤
        export_stems = input("üìÅ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–µ–º—ã? (y/N): ").strip().lower() == 'y'
        
        print(f"\nüöÄ –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        print(f"üìù –ü—Ä–æ–º–ø—Ç: {prompt}")
        print(f"üé≠ –ñ–∞–Ω—Ä: {genre or '–∞–≤—Ç–æ'}")
        print(f"üéµ BPM: {bpm or '–∞–≤—Ç–æ'}")
        print(f"‚è∞ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}—Å")
        print(f"üéöÔ∏è –ú–∞—Å—Ç–µ—Ä–∏–Ω–≥: {purpose}")
        print(f"‚ö° –≠–Ω–µ—Ä–≥–∏—è: {energy}")
        print(f"üé® –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å: {creativity}")
        print(f"üìÅ –°—Ç–µ–º—ã: {'–¥–∞' if export_stems else '–Ω–µ—Ç'}")
        
        request = GenerationRequest(
            prompt=prompt,
            genre=genre,
            bpm=bpm,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            duration=duration,
            mastering_purpose=purpose,
            energy_level=energy,
            creativity_factor=creativity,
            export_stems=export_stems
        )
        
        try:
            result = self.generate_track_sync(request)
            
            if result.success:
                print(f"\n‚úÖ –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
                print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result.generation_time:.1f} —Å–µ–∫—É–Ω–¥")
                print(f"üìÅ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {result.final_path}")
                print(f"üéµ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.1%}")
                
                if result.intermediate_files:
                    print(f"üìÇ –°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(result.intermediate_files)}")
                
                if result.used_samples:
                    print(f"\nüéõÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –†–ï–ê–õ–¨–ù–´–ï —Å—ç–º–ø–ª—ã:")
                    for i, sample in enumerate(result.used_samples[:5], 1):
                        print(f"  {i}. {sample.get('filename', 'unknown')} "
                              f"({sample.get('instrument_role', 'unknown')}) - "
                              f"—Å–∫–æ—Ä: {sample.get('score', 0):.2f}")
                
                if result.structure_data:
                    print(f"\nüèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç—Ä–µ–∫–∞:")
                    sections = result.structure_data.get("sections", [])
                    for section in sections:
                        print(f"  - {section.get('type', 'unknown')}: "
                              f"{section.get('duration', 0)}—Å "
                              f"(—ç–Ω–µ—Ä–≥–∏—è: {section.get('energy', 0):.1f})")
            else:
                print(f"\n‚ùå –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {result.error_message}")
        
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def _show_sample_statistics(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É –¥–≤–∏–∂–∫—É"""
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –î–í–ò–ñ–ö–ê")
        print("-" * 40)
        
        try:
            engine = self.pipeline.sample_engine
            
            print(f"üìÇ –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤: {len(engine.samples_index)} —Ñ–∞–π–ª–æ–≤")
            
            if engine.samples_index:
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                by_instrument = {}
                by_genre = {}
                total_duration = 0
                
                for sample in engine.samples_index:
                    # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
                    instrument = sample.instrument_role or "unknown"
                    by_instrument[instrument] = by_instrument.get(instrument, 0) + 1
                    
                    # –ñ–∞–Ω—Ä—ã
                    for genre in sample.genres:
                        by_genre[genre] = by_genre.get(genre, 0) + 1
                    
                    # –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    total_duration += sample.duration
                
                print(f"‚è±Ô∏è –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration/60:.1f} –º–∏–Ω—É—Ç")
                
                print(f"\nüéõÔ∏è –ü–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º:")
                for instrument, count in sorted(by_instrument.items(), key=lambda x: x[1], reverse=True)[:10]:
                    print(f"  - {instrument}: {count} —Å—ç–º–ø–ª–æ–≤")
                
                if by_genre:
                    print(f"\nüé≠ –ü–æ –∂–∞–Ω—Ä–∞–º:")
                    for genre, count in sorted(by_genre.items(), key=lambda x: x[1], reverse=True)[:10]:
                        print(f"  - {genre}: {count} —Å—ç–º–ø–ª–æ–≤")
                
                # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å
                if engine.semantic_model:
                    print(f"\nüß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞")
                else:
                    print(f"\nüß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å: ‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                
                # –ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞
                print(f"\nüîç –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞...")
                test_result = asyncio.run(engine.find_samples(
                    tags=["trap", "dark"],
                    instruments=["kick", "snare"],
                    genre="trap",
                    bpm=140,
                    max_results=3
                ))
                
                print(f"  –ù–∞–π–¥–µ–Ω–æ: {len(test_result)} —Å—ç–º–ø–ª–æ–≤")
                for i, sample in enumerate(test_result, 1):
                    print(f"    {i}. {sample.get('filename', 'unknown')} "
                          f"(—Å–∫–æ—Ä: {sample.get('score', 0):.2f})")
            
            else:
                print("‚ùå –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç!")
                print("‚ùå –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ sample_index.json")
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def _test_systems(self):
        """–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º"""
        print("\nüîß –¢–ï–°–¢ –°–ò–°–¢–ï–ú")
        print("-" * 20)
        
        # –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞
        print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫...")
        try:
            engine = self.pipeline.sample_engine
            sample_count = len(engine.samples_index)
            print(f"  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {sample_count} —Å—ç–º–ø–ª–æ–≤")
            
            if sample_count == 0:
                print("  ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç!")
            
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞: {e}")
        
        # –¢–µ—Å—Ç LLaMA3
        print("\nüß† –¢–µ—Å—Ç–∏—Ä—É–µ–º LLaMA3-music...")
        try:
            client = self.pipeline.llama_client
            test_result = client.query_structured_music("test trap beat 140 bpm")
            
            if test_result:
                print(f"  ‚úÖ LLaMA3-music –æ—Ç–≤–µ—á–∞–µ—Ç")
                print(f"  üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞: {len(test_result.get('structure', []))} —Å–µ–∫—Ü–∏–π")
            else:
                print("  ‚ö†Ô∏è LLaMA3-music –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback)")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ LLaMA3: {e}")
        
        # –¢–µ—Å—Ç MusicGen
        print("\nüéº –¢–µ—Å—Ç–∏—Ä—É–µ–º MusicGen...")
        try:
            engine = self.pipeline.musicgen_engine
            if engine.model:
                print("  ‚úÖ MusicGen –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                print("  ‚ùå MusicGen –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ MusicGen: {e}")
        
        # –¢–µ—Å—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞
        print("\nüíæ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É —ç–∫—Å–ø–æ—Ä—Ç–∞...")
        try:
            export_manager = self.pipeline.export_manager
            test_passed = export_manager.test_export_system()
            
            if test_passed:
                print("  ‚úÖ –°–∏—Å—Ç–µ–º–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç")
            else:
                print("  ‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–∏—Å—Ç–µ–º–æ–π —ç–∫—Å–ø–æ—Ä—Ç–∞")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")

# ============================================================================
# –¢–û–ß–ö–ê –í–•–û–î–ê
# ============================================================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        print("üéµ –ó–∞–ø—É—Å–∫ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º launcher
        launcher = FixedWaveDreamLauncher()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        launcher.run_interactive_mode()
        
    except KeyboardInterrupt:
        print("\nüëã –í—ã—Ö–æ–¥ –ø–æ Ctrl+C")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()
