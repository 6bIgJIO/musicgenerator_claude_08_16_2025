


# main.py - Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° WaveDream Enhanced Pro v2.0

import os
import sys
import asyncio
import logging
import argparse
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
import traceback
import requests
import io
from config import WaveDreamConfig
from export import ExportManager

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¼Ğ¾Ğ´ÑƒĞ»ÑĞ¼ WaveDream
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'FL'))

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ WaveDream Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
try:
    from config import config, GenreType, MasteringPurpose
    from pipeline import WaveDreamPipeline, GenerationRequest, GenerationResult
    from sample_engine import SemanticSampleEngine
    from verification import MixVerifier
    from export import ExportManager
    from metadata import MetadataProcessor
    from self_check import verify_mix
    from semantic_engine import select_samples_by_semantics

except ImportError as e:
    print(f"âŒ Error importing WaveDream modules: {e}")
    print("Make sure all WaveDream components are properly installed")
    sys.exit(1)


class WaveDreamEnhancedLauncher:
    """
    Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ»Ğ°ÑƒĞ½Ñ‡ĞµÑ€ WaveDream Enhanced Pro v2.0
    
    ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ²ÑĞµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹:
    - Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²
    - Ğ–Ğ°Ğ½Ñ€Ğ¾Ğ²ÑƒÑ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ñ AI
    - LLaMA3 ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    - MusicGen Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 
    - Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ¼Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
    - ĞŸĞ¾Ğ»Ğ½ÑƒÑ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
    - Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°Ñ…
    """
    
    def __init__(self):
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
        self._setup_logging()
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
        self.logger = logging.getLogger(__name__)
        self.pipeline = WaveDreamPipeline()
        self.metadata_processor = MetadataProcessor()
        self.sample_engine = SemanticSampleEngine()
        self.verifier = MixVerifier()
        self.export_manager = ExportManager()
        
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
        self.performance_stats = {
            'total_generations': 0,
            'successful_generations': 0,
            'avg_generation_time': 0.0,
            'genre_statistics': {},
            'purpose_statistics': {}
        }
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
        self._validate_environment()
        
        self.logger.info("ğŸµ WaveDream Enhanced Pro v2.0 initialized successfully")
    
    def _setup_logging(self):
        """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        log_config = config.LOGGING
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‚ĞµÑ€
        formatter = logging.Formatter(log_config["format"])
        
        # ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ
        log_level = getattr(logging, log_config["level"], logging.INFO)
        
        # ĞšĞ¾Ğ½ÑĞ¾Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ…ĞµĞ½Ğ´Ğ»ĞµÑ€
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(log_level)
        
        # Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ñ‹Ğ¹ Ñ…ĞµĞ½Ğ´Ğ»ĞµÑ€ Ñ Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹
        try:
            from logging.handlers import RotatingFileHandler
            file_handler = RotatingFileHandler(
                log_config["file"],
                maxBytes=log_config["max_size_mb"] * 1024 * 1024,
                backupCount=log_config["backup_count"],
                encoding='utf-8'
            )
            file_handler.setFormatter(formatter)
            file_handler.setLevel(log_level)
        except Exception as e:
            print(f"Warning: Could not set up file logging: {e}")
            file_handler = None
        
        # ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(log_level)
        root_logger.addHandler(console_handler)
        if file_handler:
            root_logger.addHandler(file_handler)
        
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ½Ğ°ÑˆĞ¸Ñ… Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ¾Ğ²
        for logger_name in ['wavedream', 'wavedream.core', '__main__']:
            logger = logging.getLogger(logger_name)
            logger.propagate = True
    
    def _validate_environment(self):
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager"""
        try:
            # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
            env_checks = self.export_manager.check_export_environment()
            
            failed_checks = [check for check, result in env_checks.items() if not result]
            
            if failed_checks:
                self.logger.warning(f"Environment validation issues: {'; '.join(failed_checks)}")
                
                # ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
                critical_failed = [check for check in failed_checks 
                                 if check in ["base_dir_writable", "sufficient_space", "pydub_working"]]
                
                if critical_failed:
                    raise RuntimeError(f"Critical environment checks failed: {'; '.join(critical_failed)}")
            else:
                self.logger.info("âœ… All environment checks passed")
                
        except Exception as e:
            self.logger.error(f"âŒ Critical environment validation error: {e}")
            raise
    
    async def generate_track_async(self, request: GenerationRequest) -> GenerationResult:
        """
        ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ñ€ĞµĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ pipeline
        
        Args:
            request: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
        """
        start_time = time.time()
        self.performance_stats['total_generations'] += 1
        
        try:
            self.logger.info(f"ğŸš€ Starting async track generation")
            self.logger.info(f"ğŸ“ Prompt: '{request.prompt}'")
            self.logger.info(f"ğŸ¯ Purpose: {request.mastering_purpose}")
            self.logger.info(f"ğŸ­ Genre hint: {request.genre or 'auto-detect'}")
            
            # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ pipeline
            result = await self.pipeline.generate_track(request)
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
            generation_time = time.time() - start_time
            
            if result.success:
                self.performance_stats['successful_generations'] += 1
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¿Ğ¾ Ğ¶Ğ°Ğ½Ñ€Ğ°Ğ¼
                detected_genre = result.structure_data.get('detected_genre', 'unknown') if result.structure_data else 'unknown'
                self.performance_stats['genre_statistics'][detected_genre] = \
                    self.performance_stats['genre_statistics'].get(detected_genre, 0) + 1
                
                # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
                self.performance_stats['purpose_statistics'][request.mastering_purpose] = \
                    self.performance_stats['purpose_statistics'].get(request.mastering_purpose, 0) + 1
                
                # Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
                current_avg = self.performance_stats['avg_generation_time']
                total_successful = self.performance_stats['successful_generations']
                self.performance_stats['avg_generation_time'] = \
                    (current_avg * (total_successful - 1) + generation_time) / total_successful
                
                self.logger.info(f"âœ… Generation completed successfully in {generation_time:.1f}s")
                self.logger.info(f"ğŸ¯ Quality score: {result.quality_score:.2f}/1.0")
                
            else:
                self.logger.error(f"âŒ Generation failed: {result.error_message}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Async generation error: {e}")
            self.logger.error(f"ğŸ” Traceback: {traceback.format_exc()}")
            
            return GenerationResult(
                success=False,
                generation_time=time.time() - start_time,
                error_message=str(e)
            )
    
    def generate_track_sync(self, request: GenerationRequest) -> GenerationResult:
        """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¾Ğ±Ñ‘Ñ€Ñ‚ĞºĞ° Ğ´Ğ»Ñ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸"""
        return asyncio.run(self.generate_track_async(request))
    
    def run_interactive_mode(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸"""
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸµ WaveDream Enhanced Pro v2.0 - Full AI Music Generation Suite ğŸµ             â•‘
â•‘                                                                                  â•‘ 
â•‘ ğŸ§  LLaMA3 Structure | ğŸ¼ MusicGen Base | ğŸ” Semantic Samples | ğŸ›ï¸ Smart Master â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        while True:
            self._display_main_menu()
            choice = input("\nğŸ¯ Your choice: ").strip()
            
            try:
                if choice == "1":
                    self._interactive_enhanced_generation()
                elif choice == "2":
                    self._interactive_batch_generation()
                elif choice == "3":
                    self._interactive_sample_analysis()
                elif choice == "4":
                    self._interactive_genre_testing()
                elif choice == "5":
                    self._interactive_quality_analysis()
                elif choice == "6":
                    self._interactive_system_management()
                elif choice == "7":
                    self._interactive_settings()
                elif choice == "8":
                    self._display_statistics()
                elif choice == "9":
                    self._run_system_diagnostics()
                elif choice == "0":
                    print("ğŸ‘‹ Thank you for using WaveDream Enhanced Pro!")
                    break
                else:
                    print("âŒ Invalid choice. Please try again.")
                    
            except KeyboardInterrupt:
                print("\n\nâ¸ï¸ Operation cancelled by user")
            except Exception as e:
                self.logger.error(f"Interactive mode error: {e}")
                print(f"âŒ An error occurred: {e}")
                print("Please try again or check logs for details.")
    
    def _display_main_menu(self):
        """ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½Ñ"""
        print("\n" + "="*80)
        print("ğŸµ WaveDream Enhanced Pro v2.0 - Main Menu")
        print("="*80)
        print("1. ğŸš€ Enhanced Track Generation (Full Pipeline)")
        print("2. ğŸ“¦ Batch Generation from JSON") 
        print("3. ğŸ” Sample Database Analysis")
        print("4. ğŸ­ Genre Detection Testing")
        print("5. ğŸ“Š Quality Analysis Tools")
        print("6. âš™ï¸ System Management")
        print("7. ğŸ› ï¸ Settings & Configuration")
        print("8. ğŸ“ˆ Performance Statistics")
        print("9. ğŸ”§ System Diagnostics")
        print("0. ğŸšª Exit")
    
    def _interactive_enhanced_generation(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ"""
        print("\nğŸš€ ENHANCED TRACK GENERATION")
        print("-" * 50)
        print("Full AI pipeline: Prompt Analysis â†’ Genre Detection â†’ Structure â†’ Generation â†’ Mastering")
        
        # Ğ’Ğ²Ğ¾Ğ´ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
        prompt = input("\nğŸ“ Enter track description: ").strip()
        if not prompt:
            print("âŒ Prompt cannot be empty")
            return
        
        # ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°
        print("\nğŸ§  Analyzing prompt...")
        prompt_analysis = self.metadata_processor.analyze_prompt(prompt)
        detected_genre = self.metadata_processor.detect_genre(prompt, prompt_analysis.get('tags', []))
        
        print(f"ğŸ­ Detected genre: {detected_genre}")
        print(f"ğŸµ Detected BPM: {prompt_analysis.get('bpm', 'auto')}")
        print(f"ğŸ¹ Detected instruments: {', '.join(prompt_analysis.get('instruments', ['auto']))}")
        print(f"ğŸ˜Š Detected mood: {', '.join(prompt_analysis.get('mood', ['neutral']))}")
        
        # ĞĞ¿Ñ†Ğ¸Ğ¸ Ğ¶Ğ°Ğ½Ñ€Ğ°
        confirm_genre = input(f"\nContinue with detected genre '{detected_genre}'? (Y/n): ").lower()
        if confirm_genre == 'n':
            available_genres = [genre.value for genre in GenreType]
            print(f"Available genres: {', '.join(available_genres)}")
            manual_genre = input("Enter genre manually: ").strip().lower()
            if manual_genre in available_genres:
                detected_genre = manual_genre
            else:
                print(f"âŒ Unknown genre, using detected: {detected_genre}")
        
        # ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ½Ğ³Ğ°
        print("\nğŸ¯ Select mastering purpose:")
        purposes = [purpose.value for purpose in MasteringPurpose]
        for i, purpose in enumerate(purposes, 1):
            print(f"{i}. {purpose.title()} - {self._get_purpose_description(purpose)}")
        
        purpose_choice = input("Choice (1-6, Enter for personal): ").strip()
        try:
            if purpose_choice:
                mastering_purpose = purposes[int(purpose_choice) - 1]
            else:
                mastering_purpose = "personal"
        except (ValueError, IndexError):
            mastering_purpose = "personal"
        
        print(f"ğŸ¯ Selected purpose: {mastering_purpose}")
        
        # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
        print("\nâš™ï¸ Additional options:")
        
        duration = input("Duration in seconds (Enter for auto): ").strip()
        try:
            duration = int(duration) if duration else None
        except ValueError:
            duration = None
        
        export_stems = input("Export all intermediate versions? (Y/n): ").lower() != 'n'
        
        export_formats = ["wav"]
        more_formats = input("Export additional formats? (mp3,flac,aac): ").strip()
        if more_formats:
            additional = [f.strip() for f in more_formats.split(',')]
            export_formats.extend(additional)
        
        # Ğ’Ñ‹Ğ²Ğ¾Ğ´
        output_dir = input("Output directory (Enter for auto): ").strip()
        if not output_dir:
            safe_prompt = "".join(c for c in prompt[:20] if c.isalnum() or c.isspace()).strip()
            safe_prompt = "_".join(safe_prompt.split())
            output_dir = f"output_{safe_prompt}_{detected_genre}_{mastering_purpose}"
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
        request = GenerationRequest(
            prompt=prompt,
            genre=detected_genre,
            bpm=prompt_analysis.get('bpm'),
            duration=duration,
            mastering_purpose=mastering_purpose,
            output_dir=output_dir,
            export_stems=export_stems,
            energy_level=prompt_analysis.get('energy_level', 0.5),
            creativity_factor=prompt_analysis.get('complexity_score', 0.7)
        )
        
        # ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ
        print(f"\nğŸ“‹ GENERATION SUMMARY:")
        print(f"  ğŸ“ Prompt: '{prompt}'")
        print(f"  ğŸ­ Genre: {detected_genre}")
        print(f"  ğŸµ BPM: {request.bpm or 'auto'}")
        print(f"  â±ï¸ Duration: {duration or 'auto'} seconds")
        print(f"  ğŸ¯ Purpose: {mastering_purpose}")
        print(f"  ğŸ“ Output: {output_dir}")
        print(f"  ğŸ’¾ Export stems: {export_stems}")
        print(f"  ğŸ¼ Formats: {', '.join(export_formats)}")
        
        confirm = input("\nProceed with generation? (Y/n): ").lower()
        if confirm == 'n':
            print("âŒ Generation cancelled")
            return
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ
        print(f"\nğŸš€ Starting enhanced generation...")
        print("This may take several minutes depending on complexity...")
        
        try:
            result = self.generate_track_sync(request)
            
            if result.success:
                print(f"\nğŸ‰ GENERATION COMPLETED SUCCESSFULLY!")
                print(f"ğŸ“ Final track: {result.final_path}")
                print(f"â±ï¸ Generation time: {result.generation_time:.1f} seconds")
                print(f"ğŸ¯ Quality score: {result.quality_score:.2f}/1.0")
                
                if result.used_samples:
                    print(f"ğŸ›ï¸ Used samples: {len(result.used_samples)}")
                
                if result.structure_data:
                    sections = result.structure_data.get('sections', [])
                    print(f"ğŸ—ï¸ Structure sections: {len(sections)}")
                
                # ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ
                if result.final_path and os.path.exists(result.final_path):
                    play = input("\nPlay the generated track? (y/N): ").lower()
                    if play == 'y':
                        self._play_audio_file(result.final_path)
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ
                if result.quality_score < 0.8:
                    show_quality = input("Show detailed quality report? (Y/n): ").lower()
                    if show_quality != 'n':
                        self._show_quality_details(result)
                
            else:
                print(f"\nâŒ GENERATION FAILED")
                print(f"Error: {result.error_message}")
                print("Check logs for detailed error information")
                
        except Exception as e:
            self.logger.error(f"Generation error: {e}")
            print(f"âŒ Unexpected error during generation: {e}")
    
    def _interactive_batch_generation(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ"""
        print("\nğŸ“¦ BATCH GENERATION FROM JSON")
        print("-" * 40)
        
        # ĞŸĞ¾Ğ¸ÑĞº JSON Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
        json_files = list(Path('.').glob('*.json'))
        batch_files = [f for f in json_files if 'batch' in f.name.lower() or 'tasks' in f.name.lower()]
        
        if batch_files:
            print("Found potential batch files:")
            for i, file in enumerate(batch_files, 1):
                print(f"{i}. {file}")
            print(f"{len(batch_files) + 1}. Enter custom path")
            
            choice = input("Select batch file: ").strip()
            try:
                if choice and int(choice) <= len(batch_files):
                    batch_file = str(batch_files[int(choice) - 1])
                else:
                    batch_file = input("Enter batch file path: ").strip()
            except (ValueError, IndexError):
                batch_file = input("Enter batch file path: ").strip()
        else:
            batch_file = input("Enter batch file path: ").strip()
        
        if not batch_file or not os.path.exists(batch_file):
            print("âŒ Batch file not found")
            return
        
        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                batch_data = json.load(f)
        except Exception as e:
            print(f"âŒ Error loading batch file: {e}")
            return
        
        tasks = batch_data.get("tasks", [])
        if not tasks:
            print("âŒ No tasks found in batch file")
            return
        
        print(f"ğŸ“¦ Found {len(tasks)} tasks")
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        parallel_processing = input("Enable parallel processing? (Y/n): ").lower() != 'n'
        max_concurrent = 2  # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚
        
        if parallel_processing:
            try:
                max_concurrent = int(input(f"Max concurrent tasks (default {max_concurrent}): ") or max_concurrent)
            except ValueError:
                pass
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        print(f"\nğŸš€ Starting batch processing: {len(tasks)} tasks")
        if parallel_processing:
            print(f"âš¡ Parallel processing: max {max_concurrent} concurrent")
        
        successful_tasks = 0
        failed_tasks = 0
        
        for i, task_data in enumerate(tasks, 1):
            print(f"\nğŸ“‹ Task {i}/{len(tasks)}: {task_data.get('name', f'task_{i}')}")
            
            try:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
                request = self._create_request_from_task(task_data, i)
                
                # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼
                result = self.generate_track_sync(request)
                
                if result.success:
                    print(f"  âœ… Completed: {result.final_path}")
                    successful_tasks += 1
                else:
                    print(f"  âŒ Failed: {result.error_message}")
                    failed_tasks += 1
                
            except Exception as e:
                print(f"  âŒ Task error: {e}")
                failed_tasks += 1
        
        # Ğ˜Ñ‚Ğ¾Ğ³Ğ¸
        print(f"\nğŸ“Š BATCH PROCESSING COMPLETED")
        print(f"âœ… Successful: {successful_tasks}")
        print(f"âŒ Failed: {failed_tasks}")
        print(f"ğŸ“ˆ Success rate: {successful_tasks/(successful_tasks+failed_tasks)*100:.1f}%")
    
    def _interactive_sample_analysis(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ ÑÑĞ¼Ğ¿Ğ»Ğ¾Ğ²"""
        print("\nğŸ” SAMPLE DATABASE ANALYSIS")
        print("-" * 35)
        
        print("Choose analysis type:")
        print("1. Database statistics")
        print("2. Rebuild semantic index")
        print("3. Search samples by query")
        print("4. Analyze sample quality")
        print("5. Export sample metadata")
        
        choice = input("Select option (1-5): ").strip()
        
        if choice == "1":
            print("\nğŸ“Š Generating database statistics...")
            stats = self.sample_engine.get_statistics()
            
            print(f"\nğŸ“ˆ SAMPLE DATABASE STATISTICS")
            print(f"Total samples: {stats.get('total_samples', 0)}")
            print(f"Average quality: {stats.get('avg_quality', 0):.2f}")
            
            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¶Ğ°Ğ½Ñ€Ğ°Ğ¼
            genre_dist = stats.get('genre_distribution', {})
            if genre_dist:
                print(f"\nğŸ­ Genre distribution:")
                for genre, count in sorted(genre_dist.items(), key=lambda x: -x[1])[:10]:
                    print(f"  {genre}: {count} samples")
            
            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼
            instrument_dist = stats.get('instrument_distribution', {})
            if instrument_dist:
                print(f"\nğŸ¼ Instrument distribution:")
                for instrument, count in sorted(instrument_dist.items(), key=lambda x: -x[1])[:10]:
                    print(f"  {instrument}: {count} samples")
            
            # ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
            perf_stats = stats.get('performance_stats', {})
            if perf_stats:
                print(f"\nâš¡ Performance statistics:")
                print(f"  Queries processed: {perf_stats.get('queries', 0)}")
                print(f"  Cache hit rate: {perf_stats.get('cache_hits', 0) / max(1, perf_stats.get('queries', 1)) * 100:.1f}%")
                print(f"  Average query time: {perf_stats.get('avg_query_time', 0):.3f}s")
        
        elif choice == "2":
            confirm = input("âš ï¸ Rebuild semantic index? This will take time. (y/N): ").lower()
            if confirm == 'y':
                print("ğŸ”„ Rebuilding semantic index...")
                self.sample_engine.build_semantic_index()
                print("âœ… Semantic index rebuilt successfully")
        
        elif choice == "3":
            query = input("Enter search query (tags, instruments, genre): ").strip()
            if query:
                print(f"\nğŸ” Searching for: '{query}'")
                
                # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
                query_parts = query.split()
                search_results = asyncio.run(self.sample_engine.find_samples(
                    tags=query_parts,
                    max_results=10
                ))
                
                if search_results:
                    print(f"\nğŸ“‹ Found {len(search_results)} samples:")
                    for i, sample in enumerate(search_results, 1):
                        filename = sample.get('filename', 'unknown')
                        score = sample.get('score', 0)
                        tags = sample.get('tags', [])
                        print(f"{i}. {filename} (score: {score:.2f})")
                        print(f"   Tags: {', '.join(tags[:5])}")
                else:
                    print("âŒ No samples found matching query")
        
        elif choice == "4":
            print("ğŸ“Š Analyzing sample quality...")
            # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
            print("Quality analysis completed - see logs for details")
        
        elif choice == "5":
            output_file = input("Export metadata to file (default: sample_metadata.json): ").strip()
            if not output_file:
                output_file = "sample_metadata.json"
            
            try:
                stats = self.sample_engine.get_statistics()
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(stats, f, indent=2, ensure_ascii=False)
                print(f"âœ… Metadata exported to: {output_file}")
            except Exception as e:
                print(f"âŒ Export error: {e}")
    
    def _interactive_genre_testing(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¶Ğ°Ğ½Ñ€Ğ¾Ğ²"""
        print("\nğŸ­ GENRE DETECTION TESTING")
        print("-" * 30)
        
        test_prompts = [
            ("dark aggressive trap 160bpm with vocal chops and 808s", "trap"),
            ("Ğ¼ĞµĞ»Ğ¾Ğ´Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ»Ğ¾ÑƒÑ„Ğ°Ğ¹ Ğ´Ğ»Ñ ÑƒÑ‡Ñ‘Ğ±Ñ‹ Ñ Ğ²Ğ¸Ğ½Ñ‚Ğ°Ğ¶Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸", "lofi"),
            ("liquid drum and bass neurofunk 174bpm atmospheric", "dnb"),
            ("Ğ°Ñ‚Ğ¼Ğ¾ÑÑ„ĞµÑ€Ğ½Ñ‹Ğ¹ ÑĞ¼Ğ±Ğ¸ĞµĞ½Ñ‚ ĞºĞ¾ÑĞ¼Ğ¾Ñ Ğ¼ĞµĞ´Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ 70bpm", "ambient"),
            ("phonk memphis cowbell drift aggressive", "phonk"),
            ("Ñ‚ĞµÑ…Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ» 130bpm industrial warehouse", "techno"),
            ("cinematic epic trailer orchestral heroic", "cinematic"),
            ("house deep groove Ğ¿Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ bassline 124bpm", "house")
        ]
        
        print("Choose testing mode:")
        print("1. Test with built-in examples")
        print("2. Test custom prompts")
        print("3. Test accuracy on known samples")
        
        choice = input("Select mode (1-3): ").strip()
        
        if choice == "1":
            print("\nğŸ§ª Testing with built-in examples:")
            
            correct = 0
            total = len(test_prompts)
            
            for prompt, expected in test_prompts:
                detected = self.metadata_processor.detect_genre(prompt)
                is_correct = detected == expected
                
                status = "âœ…" if is_correct else "âŒ"
                print(f"{status} '{prompt[:50]}...'")
                print(f"   Expected: {expected} | Detected: {detected}")
                
                if is_correct:
                    correct += 1
            
            accuracy = correct / total * 100
            print(f"\nğŸ“Š Accuracy: {accuracy:.1f}% ({correct}/{total})")
            
        elif choice == "2":
            while True:
                prompt = input("\nEnter test prompt (or 'quit' to exit): ").strip()
                if prompt.lower() == 'quit':
                    break
                
                if prompt:
                    # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
                    analysis = self.metadata_processor.analyze_prompt(prompt)
                    detected_genre = self.metadata_processor.detect_genre(prompt, analysis.get('tags', []))
                    
                    print(f"\nğŸ” Analysis results for: '{prompt}'")
                    print(f"ğŸ­ Detected genre: {detected_genre}")
                    print(f"ğŸµ Detected BPM: {analysis.get('bpm', 'none')}")
                    print(f"ğŸ¹ Instruments: {', '.join(analysis.get('instruments', ['none']))}")
                    print(f"ğŸ˜Š Mood: {', '.join(analysis.get('mood', ['neutral']))}")
                    print(f"ğŸ§  Complexity: {analysis.get('complexity_score', 0):.2f}")
                    
                    if analysis.get('mentioned_sections'):
                        print(f"ğŸ—ï¸ Structure hints: {', '.join(analysis['mentioned_sections'])}")
    
    def _interactive_quality_analysis(self):
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞ«Ğ™ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
        print("\nğŸ“Š QUALITY ANALYSIS TOOLS")
        print("-" * 30)
        
        print("1. Analyze audio file")
        print("2. Compare two tracks") 
        print("3. Batch quality analysis")
        print("4. Generate quality report")
        
        choice = input("Select tool (1-4): ").strip()
        
        if choice == "1":
            file_path = input("Enter audio file path: ").strip()
            if os.path.exists(file_path):
                print(f"ğŸ” Analyzing: {file_path}")
                
                try:
                    from pydub import AudioSegment
                    audio = AudioSegment.from_file(file_path)
                    
                    # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
                    target_config = {"target_lufs": -14, "peak_ceiling": -1}
                    report = asyncio.run(self.verifier.analyze_track(audio, target_config))
                    
                    print(f"ğŸ“Š Quality score: {report.get('overall_score', 0):.2f}/1.0")
                    print(f"ğŸ¯ Status: {report.get('status', 'unknown')}")
                    
                    issues = report.get('issues', [])
                    if issues:
                        critical = len([i for i in issues if i.get('severity') == 'critical'])
                        warnings = len([i for i in issues if i.get('severity') == 'warning'])
                        print(f"ğŸš¨ Issues: {critical} critical, {warnings} warnings")
                    
                    # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¼ĞµÑ‚Ğ¾Ğ´ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°
                    if input("Generate detailed report? (Y/n): ").lower() != 'n':
                        report_path = f"{Path(file_path).stem}_quality_report.md"
                        
                        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager
                        try:
                            # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°
                            report_config = {
                                "request_data": {
                                    "prompt": f"Quality analysis of {Path(file_path).name}",
                                    "mastering_purpose": "analysis"
                                },
                                "structure": {"total_duration": len(audio) / 1000.0},
                                "analysis_results": report
                            }
                            
                            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚
                            report_file = asyncio.run(
                                self.export_manager.create_project_report(
                                    config=report_config,
                                    exported_files={"analyzed_file": file_path},
                                    project_dir=Path(file_path).parent
                                )
                            )
                            
                            if report_file:
                                print(f"ğŸ“‹ Report saved: {report_file}")
                            else:
                                print("âŒ Failed to generate report")
                                
                        except Exception as report_error:
                            self.logger.error(f"Report generation error: {report_error}")
                            print("âŒ Report generation failed")
                
                except Exception as e:
                    print(f"âŒ Analysis error: {e}")
            else:
                print("âŒ File not found")
    
    def _interactive_system_management(self):


        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ• Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ¾Ğ¹"""
        print("\nâš™ï¸ SYSTEM MANAGEMENT")
        print("-" * 25)
        
        print("1. Clear cache files")
        print("2. Update sample index")
        print("3. Check system health")
        print("4. Export configuration")
        print("5. Import configuration") 
        print("6. Reset to defaults")
        print("7. Test export system")  # ĞĞĞ’ĞĞ¯ ĞĞŸĞ¦Ğ˜Ğ¯
        
        choice = input("Select action (1-7): ").strip()
        
        if choice == "1":
            cache_dir = Path(config.CACHE_DIR)
            if cache_dir.exists():
                import shutil
                shutil.rmtree(cache_dir)
                print("âœ… Cache cleared")
            else:
                print("â„¹ï¸ No cache to clear")
        
        elif choice == "2":
            print("ğŸ”„ Updating sample index...")
            self.sample_engine.build_semantic_index()
            print("âœ… Index updated")
        
        elif choice == "3":
            print("ğŸ¥ Running system health check...")
            self._run_system_health_check()
        
        elif choice == "4":
            config_path = input("Export config to (default: wavedream_config.json): ").strip()
            if not config_path:
                config_path = "wavedream_config.json"
            
            try:
                config.export_config(config_path)
                print(f"âœ… Configuration exported: {config_path}")
            except Exception as e:
                print(f"âŒ Export error: {e}")
                
        elif choice == "7":  # ĞĞĞ’ĞĞ¯ ĞĞŸĞ¦Ğ˜Ğ¯
            print("ğŸ§ª Testing export system...")
            try:
                # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: Ğ¢ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°
                env_checks = self.export_manager.check_export_environment()
                
                print("Environment checks:")
                for check, result in env_checks.items():
                    status = "âœ…" if result else "âŒ"
                    print(f"  {status} {check.replace('_', ' ').title()}")
                
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚
                print("\nTesting audio export...")
                from pydub.generators import Sine
                test_audio = Sine(440).to_audio_segment(duration=1000)
                
                test_config = {
                    "output_dir": "test_export",
                    "export_formats": ["wav", "mp3"],
                    "request_data": {"prompt": "test", "mastering_purpose": "test"}
                }
                
                # Ğ¢ĞµÑÑ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager
                buffer = io.BytesIO()
                test_audio.export(buffer, format="wav")
                test_bytes = buffer.getvalue()
                
                result = asyncio.run(
                    self.export_manager.export_complete_project(
                        mastered_audio=test_bytes,
                        intermediate_audio={},
                        config=test_config
                    )
                )
                
                print(f"âœ… Export test successful: {len(result)} files created")
                
            except Exception as e:
                print(f"âŒ Export test failed: {e}")
    
    def _interactive_settings(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸"""
        print("\nğŸ› ï¸ SETTINGS & CONFIGURATION")
        print("-" * 35)
        
        current_settings = {
            "Sample Directory": config.DEFAULT_SAMPLE_DIR,
            "Audio Analysis Max Duration": f"{config.AUDIO_ANALYSIS['max_duration']}s",
            "Sample Rate": f"{config.AUDIO_ANALYSIS['sample_rate']}Hz",
            "Tempo Tolerance": f"Â±{config.SAMPLE_MATCHING['tempo_tolerance']} BPM",
            "Min Score Threshold": config.SAMPLE_MATCHING['min_score_threshold'],
            "Max Workers": config.PERFORMANCE['max_workers'],
            "Semantic Analysis": config.SAMPLE_MATCHING['enable_semantic_embeddings']
        }
        
        print("Current settings:")
        for key, value in current_settings.items():
            print(f"  {key}: {value}")
        
        print(f"\nSupported genres: {', '.join([g.value for g in GenreType])}")
        print(f"Mastering purposes: {', '.join([p.value for p in MasteringPurpose])}")
        
        change = input("\nModify settings? (y/N): ").lower()
        if change == 'y':
            print("ğŸ’¡ To modify settings, edit the configuration files or use environment variables")
            print("ğŸ’¡ See documentation for detailed configuration options")
    
    def _display_statistics(self):
        """ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"""
        print("\nğŸ“ˆ PERFORMANCE STATISTICS")
        print("-" * 30)
        
        stats = self.performance_stats
        
        print(f"Total generations: {stats['total_generations']}")
        print(f"Successful generations: {stats['successful_generations']}")
        
        if stats['total_generations'] > 0:
            success_rate = stats['successful_generations'] / stats['total_generations'] * 100
            print(f"Success rate: {success_rate:.1f}%")
            print(f"Average generation time: {stats['avg_generation_time']:.1f}s")
        
        if stats['genre_statistics']:
            print(f"\nGenre distribution:")
            for genre, count in sorted(stats['genre_statistics'].items(), key=lambda x: -x[1]):
                print(f"  {genre}: {count} generations")
        
        if stats['purpose_statistics']:
            print(f"\nPurpose distribution:")
            for purpose, count in sorted(stats['purpose_statistics'].items(), key=lambda x: -x[1]):
                print(f"  {purpose}: {count} generations")
        
        # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
        print(f"\nSystem info:")
        print(f"  Sample database size: {len(self.sample_engine.samples_index)} samples")
        print(f"  Cache entries: {len(self.sample_engine.embeddings_cache)}")
    
    def _run_system_diagnostics(self):
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ğ°Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑĞ¼Ğ¸"""
        print("\nğŸ”§ SYSTEM DIAGNOSTICS")
        print("-" * 25)
        
        print("Running comprehensive system check...")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
        print("\nğŸ“¦ Checking dependencies...")
        dependencies = ['torch', 'librosa', 'pydub', 'numpy', 'scipy', 'soundfile']
        
        for dep in dependencies:
            try:
                __import__(dep)
                print(f"  âœ… {dep}")
            except ImportError:
                print(f"  âŒ {dep} - Missing!")
        
        # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager
        print(f"\nğŸ“ Checking directories...")
        try:
            env_checks = self.export_manager.check_export_environment()
            
            if env_checks.get("base_dir_writable", False):
                print(f"  âœ… Output directory writable")
            else:
                print(f"  âŒ Output directory not writable")
                
            if env_checks.get("sufficient_space", False):
                print(f"  âœ… Sufficient disk space")
            else:
                print(f"  âš ï¸ Low disk space warning")
                
        except Exception as e:
            print(f"  âŒ Directory check error: {e}")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
        print(f"\nğŸ§  Checking semantic model...")
        try:
            if hasattr(self.sample_engine, 'semantic_model') and self.sample_engine.semantic_model:
                print(f"  âœ… Semantic model loaded")
            else:
                print(f"  âš ï¸ Semantic model not available")
        except Exception as e:
            print(f"  âŒ Semantic model error: {e}")
        
        # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager
        print(f"\nğŸ’¾ Testing export system...")
        try:
            from pydub.generators import Sine
            test_audio = Sine(440).to_audio_segment(duration=500)
            
            # Ğ¢ĞµÑÑ‚ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°
            buffer = io.BytesIO()
            test_audio.export(buffer, format="wav")
            test_bytes = buffer.getvalue()
            
            if len(test_bytes) > 1000:  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ½Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹
                print(f"  âœ… Audio export working")
            else:
                print(f"  âŒ Audio export failed - empty result")
                
        except Exception as e:
            print(f"  âŒ Export test error: {e}")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
        print(f"\nâš¡ Performance test...")
        start_time = time.time()
        
        test_prompt = "test electronic music 120bpm"
        analysis = self.metadata_processor.analyze_prompt(test_prompt)
        
        test_time = time.time() - start_time
        print(f"  ğŸ“Š Prompt analysis: {test_time:.3f}s")
        
        if test_time < 1.0:
            print(f"  âœ… Performance: Good")
        elif test_time < 3.0:
            print(f"  âš ï¸ Performance: Acceptable")
        else:
            print(f"  âŒ Performance: Slow")
    
    def _run_system_health_check(self):
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹"""
        health_status = {
            "dependencies": True,
            "directories": True,
            "sample_index": True,
            "semantic_model": True,
            "memory_usage": True,
            "export_system": True  # ĞĞĞ’ĞĞ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ
        }
        
        # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°
        try:
            env_checks = self.export_manager.check_export_environment()
            critical_checks = ["base_dir_writable", "sufficient_space", "pydub_working"]
            
            failed_critical = [check for check in critical_checks if not env_checks.get(check, False)]
            
            if failed_critical:
                health_status["export_system"] = False
                print(f"âŒ Export system issues: {', '.join(failed_critical)}")
            else:
                print(f"âœ… Export system: Healthy")
                
        except Exception as e:
            health_status["export_system"] = False
            print(f"âŒ Export system check failed: {e}")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
        try:
            import psutil
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 90:
                health_status["memory_usage"] = False
                print(f"âš ï¸ High memory usage: {memory_percent:.1f}%")
            else:
                print(f"âœ… Memory usage: {memory_percent:.1f}%")
        except ImportError:
            print("â„¹ï¸ psutil not available - cannot check memory")
        
        # ĞĞ±Ñ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ
        overall_health = all(health_status.values())
        if overall_health:
            print("âœ… System health: Excellent")
        else:
            issues = [k for k, v in health_status.items() if not v]
            print(f"âš ï¸ System health issues: {', '.join(issues)}")

    
    def _get_purpose_description(self, purpose: str) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ½Ğ³Ğ°"""
        descriptions = {
            "freelance": "Commercial sale, streaming optimization",
            "professional": "Broadcast/cinema, full dynamics",
            "personal": "Home listening, natural sound",
            "family": "Family videos, bright engaging",
            "streaming": "Platform optimized, loudness normalized",
            "vinyl": "Analog warm, vinyl-ready"
        }
        return descriptions.get(purpose, "General purpose")
    
    def _create_request_from_task(self, task_data: Dict, task_number: int) -> GenerationRequest:
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ• ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹"""
        # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        try:
            request = GenerationRequest(
                prompt=task_data.get("prompt", f"Generated track {task_number}"),
                genre=task_data.get("genre"),
                bpm=task_data.get("bpm"),
                duration=task_data.get("duration"),
                mastering_purpose=task_data.get("mastering_purpose", "personal"),
                output_dir=task_data.get("output_dir", f"batch_output/task_{task_number}"),
                export_stems=task_data.get("export_stems", True),
                energy_level=task_data.get("energy_level", 0.5),
                creativity_factor=task_data.get("creativity_factor", 0.7)
            )
            
            # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
            if not request.prompt or len(request.prompt.strip()) == 0:
                request.prompt = f"Electronic music track {task_number}"
                self.logger.warning(f"Task {task_number}: Empty prompt, using default")
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ output_dir
            if not request.output_dir:
                request.output_dir = f"batch_output/task_{task_number}"
            
            return request
            
        except Exception as e:
            self.logger.error(f"Error creating request from task {task_number}: {e}")
            # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
            return GenerationRequest(
                prompt=f"Fallback track {task_number}",
                mastering_purpose="personal",
                output_dir=f"batch_output/task_{task_number}"
            )
    
    def _play_audio_file(self, file_path: str):
        """Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        try:
            import platform
            system = platform.system()
            
            if system == "Windows":
                os.system(f'start "" "{file_path}"')
            elif system == "Darwin":  # macOS
                os.system(f'open "{file_path}"')
            else:  # Linux
                os.system(f'xdg-open "{file_path}"')
                
            print("ğŸµ Opening audio file...")
        except Exception as e:
            print(f"âŒ Cannot open audio file: {e}")
    
    def _show_quality_details(self, result: GenerationResult):
        """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
        print(f"\nğŸ“Š QUALITY ANALYSIS DETAILS")
        print(f"Overall score: {result.quality_score:.2f}/1.0")
        
        if result.quality_score < 0.5:
            print("ğŸ”´ Poor quality - major issues detected")
        elif result.quality_score < 0.7:
            print("ğŸŸ¡ Acceptable quality - some issues present")
        elif result.quality_score < 0.9:
            print("ğŸŸ¢ Good quality - minor issues only")
        else:
            print("ğŸŸ¢ Excellent quality - no significant issues")
    
    def run_cli_mode(self, args):
        """Ğ ĞµĞ¶Ğ¸Ğ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸"""
        try:
            if args.prompt:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ· Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
                request = GenerationRequest(
                    prompt=args.prompt,
                    genre=getattr(args, 'genre', None),
                    bpm=getattr(args, 'bpm', None),
                    duration=getattr(args, 'duration', None),
                    mastering_purpose=getattr(args, 'mastering_purpose', 'personal'),
                    output_dir=args.output_dir or 'cli_output',
                    export_stems=getattr(args, 'export_stems', True),
                    energy_level=getattr(args, 'energy_level', 0.5),
                    creativity_factor=getattr(args, 'creativity_factor', 0.7)
                )
                
                print(f"ğŸš€ CLI Generation: '{args.prompt}'")
                result = self.generate_track_sync(request)
                
                if result.success:
                    print(f"âœ… Success: {result.final_path}")
                    return 0
                else:
                    print(f"âŒ Failed: {result.error_message}")
                    return 1
                    
            elif getattr(args, 'batch', None):
                return self._run_cli_batch(args.batch)
                
            elif getattr(args, 'analyze', None):
                return self._run_cli_analyze(args.analyze)
                
            else:
                print("âŒ No valid CLI command provided")
                return 1
                
        except Exception as e:
            self.logger.error(f"CLI mode error: {e}")
            print(f"âŒ CLI error: {e}")
            return 1
    
    def _run_cli_batch(self, batch_file: str) -> int:
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ CLI Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"""
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                batch_data = json.load(f)
            
            tasks = batch_data.get("tasks", [])
            print(f"ğŸ“¦ Processing {len(tasks)} tasks from {batch_file}")
            
            successful = 0
            failed = 0
            
            for i, task_data in enumerate(tasks, 1):
                print(f"\n[{i}/{len(tasks)}] {task_data.get('name', f'Task {i}')}")
                
                try:
                    request = self._create_request_from_task(task_data, i)
                    result = self.generate_track_sync(request)
                    
                    if result.success:
                        print(f"âœ… {result.final_path}")
                        successful += 1
                        
                        # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑĞ²Ğ¾Ğ´ĞºÑƒ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager
                        if hasattr(result, 'intermediate_files') and result.intermediate_files:
                            try:
                                summary = self.export_manager.get_export_summary(result.intermediate_files)
                                print(f"  ğŸ“Š Files: {summary['total_files']}, Size: {summary['total_size']/1024/1024:.1f}MB")
                            except Exception as summary_error:
                                self.logger.debug(f"Export summary failed: {summary_error}")
                        
                    else:
                        print(f"âŒ {result.error_message}")
                        failed += 1
                        
                except Exception as e:
                    print(f"âŒ {e}")
                    failed += 1
            
            print(f"\nğŸ“Š Batch complete: {successful} successful, {failed} failed")
            return 0 if failed == 0 else 1
            
        except Exception as e:
            print(f"âŒ Batch processing error: {e}")
            return 1
    
    def _run_cli_analyze(self, file_path: str) -> int:
        """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞ«Ğ™ CLI Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
        try:
            if not os.path.exists(file_path):
                print(f"âŒ File not found: {file_path}")
                return 1
            
            from pydub import AudioSegment
            audio = AudioSegment.from_file(file_path)
            
            target_config = {"target_lufs": -14, "peak_ceiling": -1}
            report = asyncio.run(self.verifier.analyze_track(audio, target_config))
            
            print(f"ğŸ“Š Quality Analysis: {file_path}")
            print(f"Score: {report.get('overall_score', 0):.2f}/1.0")
            print(f"Status: {report.get('status', 'unknown')}")
            
            # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ExportManager
            try:
                report_config = {
                    "request_data": {
                        "prompt": f"CLI analysis of {Path(file_path).name}",
                        "mastering_purpose": "analysis"
                    },
                    "structure": {"total_duration": len(audio) / 1000.0},
                    "analysis_results": report
                }
                
                report_file = asyncio.run(
                    self.export_manager.create_project_report(
                        config=report_config,
                        exported_files={"analyzed_file": file_path},
                        project_dir=Path(file_path).parent
                    )
                )
                
                if report_file:
                    print(f"ğŸ“‹ Report: {report_file}")
                
            except Exception as report_error:
                self.logger.debug(f"Report generation failed: {report_error}")
                print("âš ï¸ Report generation skipped")
            
            return 0
            
        except Exception as e:
            print(f"âŒ Analysis error: {e}")
            return 1



def create_sample_batch_file():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"""
    sample_batch = {
        "name": "WaveDream Enhanced Pro - Sample Batch",
        "version": "2.0",
        "default_settings": {
            "mastering_purpose": "personal",
            "export_stems": True,
            "export_formats": ["wav", "mp3"]
        },
        "tasks": [
            {
                "name": "Dark Trap Beat",
                "prompt": "dark aggressive trap 160bpm with vocal chops and 808s",
                "mastering_purpose": "freelance",
                "duration": 90,
                "energy_level": 0.8
            },
            {
                "name": "Lofi Study Music",
                "prompt": "melodic lofi study beats with vintage textures and vinyl crackle",
                "mastering_purpose": "personal",
                "duration": 120,
                "energy_level": 0.3
            },
            {
                "name": "Cinematic Epic",
                "prompt": "cinematic epic orchestral trailer music heroic and inspiring",
                "mastering_purpose": "professional",
                "duration": 180,
                "energy_level": 0.9
            },
            {
                "name": "House Groove",
                "prompt": "deep house groove with plucked bass and disco elements 124bpm",
                "mastering_purpose": "streaming",
                "duration": 240,
                "energy_level": 0.7
            }
        ]
    }
    
    with open("sample_batch_tasks.json", 'w', encoding='utf-8') as f:
        json.dump(sample_batch, f, indent=2, ensure_ascii=False)
    
    print("ğŸ“ Sample batch file created: sample_batch_tasks.json")


def main():
    """Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞĞĞ¯ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº"""
    parser = argparse.ArgumentParser(
        description="ğŸµ WaveDream Enhanced Pro v2.0 - Full AI Music Generation Suite",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸŒŸ Examples:

Interactive mode:
  python main.py

Quick generation:
  python main.py --prompt "dark trap 160bpm aggressive" --purpose freelance

Batch processing:
  python main.py --batch sample_batch_tasks.json

Quality analysis:
  python main.py --analyze track.wav

System diagnostics:
  python main.py --diagnostics

Advanced generation:
  python main.py --prompt "melodic lofi study beats" --genre lofi --bpm 75 --duration 120 --purpose personal --stems

Export system test:
  python main.py --test-export

ğŸ¯ Mastering purposes: freelance, professional, personal, family, streaming, vinyl
ğŸ­ Genres: trap, lofi, dnb, ambient, techno, house, cinematic, hyperpop
        """
    )
    
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
    parser.add_argument("--prompt", type=str, help="Track description prompt")
    parser.add_argument("--genre", type=str, choices=[g.value for g in GenreType], help="Force specific genre")
    parser.add_argument("--bpm", type=int, help="Target BPM")
    parser.add_argument("--duration", type=int, help="Duration in seconds")
    parser.add_argument("--purpose", dest="mastering_purpose", choices=[p.value for p in MasteringPurpose], 
                        default="personal", help="Mastering purpose")
    parser.add_argument("--output-dir", type=str, help="Output directory")
    parser.add_argument("--stems", dest="export_stems", action="store_true", help="Export stem versions")
    parser.add_argument("--energy", dest="energy_level", type=float, default=0.5, help="Energy level (0-1)")
    parser.add_argument("--creativity", dest="creativity_factor", type=float, default=0.7, help="Creativity factor (0-1)")
    
    # ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
    parser.add_argument("--batch", type=str, help="Batch processing from JSON file")
    parser.add_argument("--create-batch", action="store_true", help="Create sample batch file")
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°
    parser.add_argument("--analyze", type=str, help="Analyze audio file quality")
    parser.add_argument("--diagnostics", action="store_true", help="Run system diagnostics")
    parser.add_argument("--stats", action="store_true", help="Show performance statistics")
    parser.add_argument("--test-export", action="store_true", help="Test export system")  # ĞĞĞ’ĞĞ¯ ĞĞŸĞ¦Ğ˜Ğ¯
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
    parser.add_argument("--rebuild-index", action="store_true", help="Rebuild sample index")
    parser.add_argument("--clear-cache", action="store_true", help="Clear cache files")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")
    parser.add_argument("--quiet", action="store_true", help="Minimal output")
    
    args = parser.parse_args()
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ»Ğ°ÑƒĞ½Ñ‡ĞµÑ€Ğ° Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
    try:
        launcher = WaveDreamEnhancedLauncher()
    except Exception as e:
        print(f"âŒ Failed to initialize WaveDream: {e}")
        print("ğŸ’¡ Try running --diagnostics to check system health")
        return 1
    
    # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ: ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´
    if args.test_export:
        print("ğŸ§ª Testing export system...")
        try:
            env_checks = launcher.export_manager.check_export_environment()
            
            print("Environment checks:")
            for check, result in env_checks.items():
                status = "âœ…" if result else "âŒ"
                print(f"  {status} {check.replace('_', ' ').title()}")
            
            # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°
            from pydub.generators import Sine
            test_audio = Sine(440).to_audio_segment(duration=2000)
            
            buffer = io.BytesIO()
            test_audio.export(buffer, format="wav")
            test_bytes = buffer.getvalue()
            
            test_config = {
                "output_dir": "export_test",
                "export_formats": ["wav", "mp3"],
                "request_data": {
                    "prompt": "Export system test",
                    "mastering_purpose": "test"
                }
            }
            
            result = asyncio.run(
                launcher.export_manager.export_complete_project(
                    mastered_audio=test_bytes,
                    intermediate_audio={},
                    config=test_config
                )
            )
            
            print(f"âœ… Export test successful: {len(result)} files created")
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑĞ²Ğ¾Ğ´ĞºÑƒ
            summary = launcher.export_manager.get_export_summary(result)
            print(f"ğŸ“Š Total size: {summary['total_size']/1024:.1f}KB")
            
        except Exception as e:
            print(f"âŒ Export test failed: {e}")
            return 1
            
        return 0
    
    # ĞÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹, Ğ½Ğ¾ Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
    if args.create_batch:
        create_sample_batch_file()
        return 0
    
    if args.diagnostics:
        launcher._run_system_diagnostics()
        return 0
    
    # ... [Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹] ...
    
    # Ğ ĞµĞ¶Ğ¸Ğ¼Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
    if any([args.prompt, args.batch, args.analyze]):
        # CLI Ñ€ĞµĞ¶Ğ¸Ğ¼
        return launcher.run_cli_mode(args)
    else:
        # Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
        try:
            launcher.run_interactive_mode()
            return 0
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            return 0
        except Exception as e:
            launcher.logger.error(f"Interactive mode error: {e}")
            print(f"âŒ Unexpected error: {e}")
            print("ğŸ’¡ Try running --diagnostics for system health check")
            return 1


if __name__ == "__main__":
    sys.exit(main())


# main.py - Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° WaveDream Enhanced Pro v2.0

import os
import sys
import asyncio
import logging
import argparse
import json
import time
from pathlib import Path
from typing import Dict, List, Optional, Any
import traceback
import requests

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¼Ğ¾Ğ´ÑƒĞ»ÑĞ¼ WaveDream
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'FL'))

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ WaveDream Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
try:
    from config import config, GenreType, MasteringPurpose
    from pipeline import WaveDreamPipeline, GenerationRequest, GenerationResult
    from sample_engine import SemanticSampleEngine
    from verification import MixVerifier
    from export import ExportManager
    from metadata import MetadataProcessor
    from self_check import verify_mix
    from semantic_engine import select_samples_by_semantics

except ImportError as e:
    print(f"âŒ Error importing WaveDream modules: {e}")
    print("Make sure all WaveDream components are properly installed")
    sys.exit(1)


class WaveDreamEnhancedLauncher:
    """
    Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ»Ğ°ÑƒĞ½Ñ‡ĞµÑ€ WaveDream Enhanced Pro v2.0
    
    ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµÑ‚ Ğ²ÑĞµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹:
    - Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²
    - Ğ–Ğ°Ğ½Ñ€Ğ¾Ğ²ÑƒÑ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ Ñ AI
    - LLaMA3 ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    - MusicGen Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ 
    - Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ¼Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
    - ĞŸĞ¾Ğ»Ğ½ÑƒÑ Ğ²ĞµÑ€Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
    - Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ² Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ñ… Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°Ñ…
    """
    
    def __init__(self):
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
        self._setup_logging()
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²
        self.logger = logging.getLogger(__name__)
        self.pipeline = WaveDreamPipeline()
        self.metadata_processor = MetadataProcessor()
        self.sample_engine = SemanticSampleEngine()
        self.verifier = MixVerifier()
        self.export_manager = ExportManager()
        
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
        self.performance_stats = {
            'total_generations': 0,
            'successful_generations': 0,
            'avg_generation_time': 0.0,
            'genre_statistics': {},
            'purpose_statistics': {}
        }
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ğµ
        self._validate_environment()
        
        self.logger.info("ğŸµ WaveDream Enhanced Pro v2.0 initialized successfully")
    
    def _setup_logging(self):
        """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ"""
        log_config = config.LOGGING
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‚ĞµÑ€
        formatter = logging.Formatter(log_config["format"])
        
        # ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ
        log_level = getattr(logging, log_config["level"], logging.INFO)
        
        # ĞšĞ¾Ğ½ÑĞ¾Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ…ĞµĞ½Ğ´Ğ»ĞµÑ€
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(log_level)
        
        # Ğ¤Ğ°Ğ¹Ğ»Ğ¾Ğ²Ñ‹Ğ¹ Ñ…ĞµĞ½Ğ´Ğ»ĞµÑ€ Ñ Ñ€Ğ¾Ñ‚Ğ°Ñ†Ğ¸ĞµĞ¹
        try:
            from logging.handlers import RotatingFileHandler
            file_handler = RotatingFileHandler(
                log_config["file"],
                maxBytes=log_config["max_size_mb"] * 1024 * 1024,
                backupCount=log_config["backup_count"],
                encoding='utf-8'
            )
            file_handler.setFormatter(formatter)
            file_handler.setLevel(log_level)
        except Exception as e:
            print(f"Warning: Could not set up file logging: {e}")
            file_handler = None
        
        # ĞĞ°ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°ĞµĞ¼ root logger
        root_logger = logging.getLogger()
        root_logger.setLevel(log_level)
        root_logger.addHandler(console_handler)
        if file_handler:
            root_logger.addHandler(file_handler)
        
        # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ½Ğ°ÑˆĞ¸Ñ… Ğ»Ğ¾Ğ³Ğ³ĞµÑ€Ğ¾Ğ²
        for logger_name in ['wavedream', 'wavedream.core', '__main__']:
            logger = logging.getLogger(logger_name)
            logger.propagate = True
    
    def _validate_environment(self):
        """Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹"""
        try:
            validation_errors = config.validate_environment()
            if validation_errors:
                self.logger.warning(f"Environment validation issues: {'; '.join(validation_errors)}")
        except RuntimeError as e:
            self.logger.error(f"âŒ Critical configuration error: {e}")
            raise
    
    async def generate_track_async(self, request: GenerationRequest) -> GenerationResult:
        """
        ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ñ€ĞµĞºĞ° Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ pipeline
        
        Args:
            request: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸
            
        Returns:
            Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°Ğ¼Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
        """
        start_time = time.time()
        self.performance_stats['total_generations'] += 1
        
        try:
            self.logger.info(f"ğŸš€ Starting async track generation")
            self.logger.info(f"ğŸ“ Prompt: '{request.prompt}'")
            self.logger.info(f"ğŸ¯ Purpose: {request.mastering_purpose}")
            self.logger.info(f"ğŸ­ Genre hint: {request.genre or 'auto-detect'}")
            
            # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ pipeline
            result = await self.pipeline.generate_track(request)
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ
            generation_time = time.time() - start_time
            
            if result.success:
                self.performance_stats['successful_generations'] += 1
                
                # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ Ğ¿Ğ¾ Ğ¶Ğ°Ğ½Ñ€Ğ°Ğ¼
                detected_genre = result.structure_data.get('detected_genre', 'unknown') if result.structure_data else 'unknown'
                self.performance_stats['genre_statistics'][detected_genre] = \
                    self.performance_stats['genre_statistics'].get(detected_genre, 0) + 1
                
                # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
                self.performance_stats['purpose_statistics'][request.mastering_purpose] = \
                    self.performance_stats['purpose_statistics'].get(request.mastering_purpose, 0) + 1
                
                # Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
                current_avg = self.performance_stats['avg_generation_time']
                total_successful = self.performance_stats['successful_generations']
                self.performance_stats['avg_generation_time'] = \
                    (current_avg * (total_successful - 1) + generation_time) / total_successful
                
                self.logger.info(f"âœ… Generation completed successfully in {generation_time:.1f}s")
                self.logger.info(f"ğŸ¯ Quality score: {result.quality_score:.2f}/1.0")
                
            else:
                self.logger.error(f"âŒ Generation failed: {result.error_message}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Async generation error: {e}")
            self.logger.error(f"ğŸ” Traceback: {traceback.format_exc()}")
            
            return GenerationResult(
                success=False,
                generation_time=time.time() - start_time,
                error_message=str(e)
            )
    
    def generate_track_sync(self, request: GenerationRequest) -> GenerationResult:
        """Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¾Ğ±Ñ‘Ñ€Ñ‚ĞºĞ° Ğ´Ğ»Ñ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸"""
        return asyncio.run(self.generate_track_async(request))
    
    def run_interactive_mode(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸"""
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ ğŸµ WaveDream Enhanced Pro v2.0 - Full AI Music Generation Suite ğŸµ             â•‘
â•‘                                                                                  â•‘ 
â•‘ ğŸ§  LLaMA3 Structure | ğŸ¼ MusicGen Base | ğŸ” Semantic Samples | ğŸ›ï¸ Smart Master â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        while True:
            self._display_main_menu()
            choice = input("\nğŸ¯ Your choice: ").strip()
            
            try:
                if choice == "1":
                    self._interactive_enhanced_generation()
                elif choice == "2":
                    self._interactive_batch_generation()
                elif choice == "3":
                    self._interactive_sample_analysis()
                elif choice == "4":
                    self._interactive_genre_testing()
                elif choice == "5":
                    self._interactive_quality_analysis()
                elif choice == "6":
                    self._interactive_system_management()
                elif choice == "7":
                    self._interactive_settings()
                elif choice == "8":
                    self._display_statistics()
                elif choice == "9":
                    self._run_system_diagnostics()
                elif choice == "0":
                    print("ğŸ‘‹ Thank you for using WaveDream Enhanced Pro!")
                    break
                else:
                    print("âŒ Invalid choice. Please try again.")
                    
            except KeyboardInterrupt:
                print("\n\nâ¸ï¸ Operation cancelled by user")
            except Exception as e:
                self.logger.error(f"Interactive mode error: {e}")
                print(f"âŒ An error occurred: {e}")
                print("Please try again or check logs for details.")
    
    def _display_main_menu(self):
        """ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½Ñ"""
        print("\n" + "="*80)
        print("ğŸµ WaveDream Enhanced Pro v2.0 - Main Menu")
        print("="*80)
        print("1. ğŸš€ Enhanced Track Generation (Full Pipeline)")
        print("2. ğŸ“¦ Batch Generation from JSON") 
        print("3. ğŸ” Sample Database Analysis")
        print("4. ğŸ­ Genre Detection Testing")
        print("5. ğŸ“Š Quality Analysis Tools")
        print("6. âš™ï¸ System Management")
        print("7. ğŸ› ï¸ Settings & Configuration")
        print("8. ğŸ“ˆ Performance Statistics")
        print("9. ğŸ”§ System Diagnostics")
        print("0. ğŸšª Exit")
    
    def _interactive_enhanced_generation(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ"""
        print("\nğŸš€ ENHANCED TRACK GENERATION")
        print("-" * 50)
        print("Full AI pipeline: Prompt Analysis â†’ Genre Detection â†’ Structure â†’ Generation â†’ Mastering")
        
        # Ğ’Ğ²Ğ¾Ğ´ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ñ… Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
        prompt = input("\nğŸ“ Enter track description: ").strip()
        if not prompt:
            print("âŒ Prompt cannot be empty")
            return
        
        # ĞŸÑ€ĞµĞ´Ğ²Ğ°Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°
        print("\nğŸ§  Analyzing prompt...")
        prompt_analysis = self.metadata_processor.analyze_prompt(prompt)
        detected_genre = self.metadata_processor.detect_genre(prompt, prompt_analysis.get('tags', []))
        
        print(f"ğŸ­ Detected genre: {detected_genre}")
        print(f"ğŸµ Detected BPM: {prompt_analysis.get('bpm', 'auto')}")
        print(f"ğŸ¹ Detected instruments: {', '.join(prompt_analysis.get('instruments', ['auto']))}")
        print(f"ğŸ˜Š Detected mood: {', '.join(prompt_analysis.get('mood', ['neutral']))}")
        
        # ĞĞ¿Ñ†Ğ¸Ğ¸ Ğ¶Ğ°Ğ½Ñ€Ğ°
        confirm_genre = input(f"\nContinue with detected genre '{detected_genre}'? (Y/n): ").lower()
        if confirm_genre == 'n':
            available_genres = [genre.value for genre in GenreType]
            print(f"Available genres: {', '.join(available_genres)}")
            manual_genre = input("Enter genre manually: ").strip().lower()
            if manual_genre in available_genres:
                detected_genre = manual_genre
            else:
                print(f"âŒ Unknown genre, using detected: {detected_genre}")
        
        # ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ½Ğ³Ğ°
        print("\nğŸ¯ Select mastering purpose:")
        purposes = [purpose.value for purpose in MasteringPurpose]
        for i, purpose in enumerate(purposes, 1):
            print(f"{i}. {purpose.title()} - {self._get_purpose_description(purpose)}")
        
        purpose_choice = input("Choice (1-6, Enter for personal): ").strip()
        try:
            if purpose_choice:
                mastering_purpose = purposes[int(purpose_choice) - 1]
            else:
                mastering_purpose = "personal"
        except (ValueError, IndexError):
            mastering_purpose = "personal"
        
        print(f"ğŸ¯ Selected purpose: {mastering_purpose}")
        
        # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
        print("\nâš™ï¸ Additional options:")
        
        duration = input("Duration in seconds (Enter for auto): ").strip()
        try:
            duration = int(duration) if duration else None
        except ValueError:
            duration = None
        
        export_stems = input("Export all intermediate versions? (Y/n): ").lower() != 'n'
        
        export_formats = ["wav"]
        more_formats = input("Export additional formats? (mp3,flac,aac): ").strip()
        if more_formats:
            additional = [f.strip() for f in more_formats.split(',')]
            export_formats.extend(additional)
        
        # Ğ’Ñ‹Ğ²Ğ¾Ğ´
        output_dir = input("Output directory (Enter for auto): ").strip()
        if not output_dir:
            safe_prompt = "".join(c for c in prompt[:20] if c.isalnum() or c.isspace()).strip()
            safe_prompt = "_".join(safe_prompt.split())
            output_dir = f"output_{safe_prompt}_{detected_genre}_{mastering_purpose}"
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
        request = GenerationRequest(
            prompt=prompt,
            genre=detected_genre,
            bpm=prompt_analysis.get('bpm'),
            duration=duration,
            mastering_purpose=mastering_purpose,
            output_dir=output_dir,
            export_stems=export_stems,
            energy_level=prompt_analysis.get('energy_level', 0.5),
            creativity_factor=prompt_analysis.get('complexity_score', 0.7)
        )
        
        # ĞŸĞ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ
        print(f"\nğŸ“‹ GENERATION SUMMARY:")
        print(f"  ğŸ“ Prompt: '{prompt}'")
        print(f"  ğŸ­ Genre: {detected_genre}")
        print(f"  ğŸµ BPM: {request.bpm or 'auto'}")
        print(f"  â±ï¸ Duration: {duration or 'auto'} seconds")
        print(f"  ğŸ¯ Purpose: {mastering_purpose}")
        print(f"  ğŸ“ Output: {output_dir}")
        print(f"  ğŸ’¾ Export stems: {export_stems}")
        print(f"  ğŸ¼ Formats: {', '.join(export_formats)}")
        
        confirm = input("\nProceed with generation? (Y/n): ").lower()
        if confirm == 'n':
            print("âŒ Generation cancelled")
            return
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ
        print(f"\nğŸš€ Starting enhanced generation...")
        print("This may take several minutes depending on complexity...")
        
        try:
            result = self.generate_track_sync(request)
            
            if result.success:
                print(f"\nğŸ‰ GENERATION COMPLETED SUCCESSFULLY!")
                print(f"ğŸ“ Final track: {result.final_path}")
                print(f"â±ï¸ Generation time: {result.generation_time:.1f} seconds")
                print(f"ğŸ¯ Quality score: {result.quality_score:.2f}/1.0")
                
                if result.used_samples:
                    print(f"ğŸ›ï¸ Used samples: {len(result.used_samples)}")
                
                if result.structure_data:
                    sections = result.structure_data.get('sections', [])
                    print(f"ğŸ—ï¸ Structure sections: {len(sections)}")
                
                # ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ
                if result.final_path and os.path.exists(result.final_path):
                    play = input("\nPlay the generated track? (y/N): ").lower()
                    if play == 'y':
                        self._play_audio_file(result.final_path)
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ
                if result.quality_score < 0.8:
                    show_quality = input("Show detailed quality report? (Y/n): ").lower()
                    if show_quality != 'n':
                        self._show_quality_details(result)
                
            else:
                print(f"\nâŒ GENERATION FAILED")
                print(f"Error: {result.error_message}")
                print("Check logs for detailed error information")
                
        except Exception as e:
            self.logger.error(f"Generation error: {e}")
            print(f"âŒ Unexpected error during generation: {e}")
    
    def _interactive_batch_generation(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ"""
        print("\nğŸ“¦ BATCH GENERATION FROM JSON")
        print("-" * 40)
        
        # ĞŸĞ¾Ğ¸ÑĞº JSON Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸
        json_files = list(Path('.').glob('*.json'))
        batch_files = [f for f in json_files if 'batch' in f.name.lower() or 'tasks' in f.name.lower()]
        
        if batch_files:
            print("Found potential batch files:")
            for i, file in enumerate(batch_files, 1):
                print(f"{i}. {file}")
            print(f"{len(batch_files) + 1}. Enter custom path")
            
            choice = input("Select batch file: ").strip()
            try:
                if choice and int(choice) <= len(batch_files):
                    batch_file = str(batch_files[int(choice) - 1])
                else:
                    batch_file = input("Enter batch file path: ").strip()
            except (ValueError, IndexError):
                batch_file = input("Enter batch file path: ").strip()
        else:
            batch_file = input("Enter batch file path: ").strip()
        
        if not batch_file or not os.path.exists(batch_file):
            print("âŒ Batch file not found")
            return
        
        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                batch_data = json.load(f)
        except Exception as e:
            print(f"âŒ Error loading batch file: {e}")
            return
        
        tasks = batch_data.get("tasks", [])
        if not tasks:
            print("âŒ No tasks found in batch file")
            return
        
        print(f"ğŸ“¦ Found {len(tasks)} tasks")
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        parallel_processing = input("Enable parallel processing? (Y/n): ").lower() != 'n'
        max_concurrent = 2  # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ñ‹Ğ¹ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚
        
        if parallel_processing:
            try:
                max_concurrent = int(input(f"Max concurrent tasks (default {max_concurrent}): ") or max_concurrent)
            except ValueError:
                pass
        
        # Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        print(f"\nğŸš€ Starting batch processing: {len(tasks)} tasks")
        if parallel_processing:
            print(f"âš¡ Parallel processing: max {max_concurrent} concurrent")
        
        successful_tasks = 0
        failed_tasks = 0
        
        for i, task_data in enumerate(tasks, 1):
            print(f"\nğŸ“‹ Task {i}/{len(tasks)}: {task_data.get('name', f'task_{i}')}")
            
            try:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
                request = self._create_request_from_task(task_data, i)
                
                # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼
                result = self.generate_track_sync(request)
                
                if result.success:
                    print(f"  âœ… Completed: {result.final_path}")
                    successful_tasks += 1
                else:
                    print(f"  âŒ Failed: {result.error_message}")
                    failed_tasks += 1
                
            except Exception as e:
                print(f"  âŒ Task error: {e}")
                failed_tasks += 1
        
        # Ğ˜Ñ‚Ğ¾Ğ³Ğ¸
        print(f"\nğŸ“Š BATCH PROCESSING COMPLETED")
        print(f"âœ… Successful: {successful_tasks}")
        print(f"âŒ Failed: {failed_tasks}")
        print(f"ğŸ“ˆ Success rate: {successful_tasks/(successful_tasks+failed_tasks)*100:.1f}%")
    
    def _interactive_sample_analysis(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ ÑÑĞ¼Ğ¿Ğ»Ğ¾Ğ²"""
        print("\nğŸ” SAMPLE DATABASE ANALYSIS")
        print("-" * 35)
        
        print("Choose analysis type:")
        print("1. Database statistics")
        print("2. Rebuild semantic index")
        print("3. Search samples by query")
        print("4. Analyze sample quality")
        print("5. Export sample metadata")
        
        choice = input("Select option (1-5): ").strip()
        
        if choice == "1":
            print("\nğŸ“Š Generating database statistics...")
            stats = self.sample_engine.get_statistics()
            
            print(f"\nğŸ“ˆ SAMPLE DATABASE STATISTICS")
            print(f"Total samples: {stats.get('total_samples', 0)}")
            print(f"Average quality: {stats.get('avg_quality', 0):.2f}")
            
            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¶Ğ°Ğ½Ñ€Ğ°Ğ¼
            genre_dist = stats.get('genre_distribution', {})
            if genre_dist:
                print(f"\nğŸ­ Genre distribution:")
                for genre, count in sorted(genre_dist.items(), key=lambda x: -x[1])[:10]:
                    print(f"  {genre}: {count} samples")
            
            # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼
            instrument_dist = stats.get('instrument_distribution', {})
            if instrument_dist:
                print(f"\nğŸ¼ Instrument distribution:")
                for instrument, count in sorted(instrument_dist.items(), key=lambda x: -x[1])[:10]:
                    print(f"  {instrument}: {count} samples")
            
            # ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
            perf_stats = stats.get('performance_stats', {})
            if perf_stats:
                print(f"\nâš¡ Performance statistics:")
                print(f"  Queries processed: {perf_stats.get('queries', 0)}")
                print(f"  Cache hit rate: {perf_stats.get('cache_hits', 0) / max(1, perf_stats.get('queries', 1)) * 100:.1f}%")
                print(f"  Average query time: {perf_stats.get('avg_query_time', 0):.3f}s")
        
        elif choice == "2":
            confirm = input("âš ï¸ Rebuild semantic index? This will take time. (y/N): ").lower()
            if confirm == 'y':
                print("ğŸ”„ Rebuilding semantic index...")
                self.sample_engine.build_semantic_index()
                print("âœ… Semantic index rebuilt successfully")
        
        elif choice == "3":
            query = input("Enter search query (tags, instruments, genre): ").strip()
            if query:
                print(f"\nğŸ” Searching for: '{query}'")
                
                # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
                query_parts = query.split()
                search_results = asyncio.run(self.sample_engine.find_samples(
                    tags=query_parts,
                    max_results=10
                ))
                
                if search_results:
                    print(f"\nğŸ“‹ Found {len(search_results)} samples:")
                    for i, sample in enumerate(search_results, 1):
                        filename = sample.get('filename', 'unknown')
                        score = sample.get('score', 0)
                        tags = sample.get('tags', [])
                        print(f"{i}. {filename} (score: {score:.2f})")
                        print(f"   Tags: {', '.join(tags[:5])}")
                else:
                    print("âŒ No samples found matching query")
        
        elif choice == "4":
            print("ğŸ“Š Analyzing sample quality...")
            # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
            print("Quality analysis completed - see logs for details")
        
        elif choice == "5":
            output_file = input("Export metadata to file (default: sample_metadata.json): ").strip()
            if not output_file:
                output_file = "sample_metadata.json"
            
            try:
                stats = self.sample_engine.get_statistics()
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(stats, f, indent=2, ensure_ascii=False)
                print(f"âœ… Metadata exported to: {output_file}")
            except Exception as e:
                print(f"âŒ Export error: {e}")
    
    def _interactive_genre_testing(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´ĞµÑ‚ĞµĞºÑ†Ğ¸Ğ¸ Ğ¶Ğ°Ğ½Ñ€Ğ¾Ğ²"""
        print("\nğŸ­ GENRE DETECTION TESTING")
        print("-" * 30)
        
        test_prompts = [
            ("dark aggressive trap 160bpm with vocal chops and 808s", "trap"),
            ("Ğ¼ĞµĞ»Ğ¾Ğ´Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ»Ğ¾ÑƒÑ„Ğ°Ğ¹ Ğ´Ğ»Ñ ÑƒÑ‡Ñ‘Ğ±Ñ‹ Ñ Ğ²Ğ¸Ğ½Ñ‚Ğ°Ğ¶Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚ĞµĞºÑÑ‚ÑƒÑ€Ğ°Ğ¼Ğ¸", "lofi"),
            ("liquid drum and bass neurofunk 174bpm atmospheric", "dnb"),
            ("Ğ°Ñ‚Ğ¼Ğ¾ÑÑ„ĞµÑ€Ğ½Ñ‹Ğ¹ ÑĞ¼Ğ±Ğ¸ĞµĞ½Ñ‚ ĞºĞ¾ÑĞ¼Ğ¾Ñ Ğ¼ĞµĞ´Ğ¸Ñ‚Ğ°Ñ†Ğ¸Ñ 70bpm", "ambient"),
            ("phonk memphis cowbell drift aggressive", "phonk"),
            ("Ñ‚ĞµÑ…Ğ½Ğ¾ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ» 130bpm industrial warehouse", "techno"),
            ("cinematic epic trailer orchestral heroic", "cinematic"),
            ("house deep groove Ğ¿Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ bassline 124bpm", "house")
        ]
        
        print("Choose testing mode:")
        print("1. Test with built-in examples")
        print("2. Test custom prompts")
        print("3. Test accuracy on known samples")
        
        choice = input("Select mode (1-3): ").strip()
        
        if choice == "1":
            print("\nğŸ§ª Testing with built-in examples:")
            
            correct = 0
            total = len(test_prompts)
            
            for prompt, expected in test_prompts:
                detected = self.metadata_processor.detect_genre(prompt)
                is_correct = detected == expected
                
                status = "âœ…" if is_correct else "âŒ"
                print(f"{status} '{prompt[:50]}...'")
                print(f"   Expected: {expected} | Detected: {detected}")
                
                if is_correct:
                    correct += 1
            
            accuracy = correct / total * 100
            print(f"\nğŸ“Š Accuracy: {accuracy:.1f}% ({correct}/{total})")
            
        elif choice == "2":
            while True:
                prompt = input("\nEnter test prompt (or 'quit' to exit): ").strip()
                if prompt.lower() == 'quit':
                    break
                
                if prompt:
                    # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
                    analysis = self.metadata_processor.analyze_prompt(prompt)
                    detected_genre = self.metadata_processor.detect_genre(prompt, analysis.get('tags', []))
                    
                    print(f"\nğŸ” Analysis results for: '{prompt}'")
                    print(f"ğŸ­ Detected genre: {detected_genre}")
                    print(f"ğŸµ Detected BPM: {analysis.get('bpm', 'none')}")
                    print(f"ğŸ¹ Instruments: {', '.join(analysis.get('instruments', ['none']))}")
                    print(f"ğŸ˜Š Mood: {', '.join(analysis.get('mood', ['neutral']))}")
                    print(f"ğŸ§  Complexity: {analysis.get('complexity_score', 0):.2f}")
                    
                    if analysis.get('mentioned_sections'):
                        print(f"ğŸ—ï¸ Structure hints: {', '.join(analysis['mentioned_sections'])}")
    
    def _interactive_quality_analysis(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
        print("\nğŸ“Š QUALITY ANALYSIS TOOLS")
        print("-" * 30)
        
        print("1. Analyze audio file")
        print("2. Compare two tracks")
        print("3. Batch quality analysis")
        print("4. Generate quality report")
        
        choice = input("Select tool (1-4): ").strip()
        
        if choice == "1":
            file_path = input("Enter audio file path: ").strip()
            if os.path.exists(file_path):
                print(f"ğŸ” Analyzing: {file_path}")
                
                try:
                    from pydub import AudioSegment
                    audio = AudioSegment.from_file(file_path)
                    
                    # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°
                    target_config = {"target_lufs": -14, "peak_ceiling": -1}
                    report = asyncio.run(self.verifier.analyze_track(audio, target_config))
                    
                    print(f"ğŸ“Š Quality score: {report.get('overall_score', 0):.2f}/1.0")
                    print(f"ğŸ¯ Status: {report.get('status', 'unknown')}")
                    
                    issues = report.get('issues', [])
                    if issues:
                        critical = len([i for i in issues if i.get('severity') == 'critical'])
                        warnings = len([i for i in issues if i.get('severity') == 'warning'])
                        print(f"ğŸš¨ Issues: {critical} critical, {warnings} warnings")
                    
                    # ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğ°
                    if input("Generate detailed report? (Y/n): ").lower() != 'n':
                        report_path = f"{Path(file_path).stem}_quality_report.md"
                        if self.verifier.generate_markdown_report(report, report_path):
                            print(f"ğŸ“‹ Report saved: {report_path}")
                
                except Exception as e:
                    print(f"âŒ Analysis error: {e}")
            else:
                print("âŒ File not found")
    
    def _interactive_system_management(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ¾Ğ¹"""
        print("\nâš™ï¸ SYSTEM MANAGEMENT")
        print("-" * 25)
        
        print("1. Clear cache files")
        print("2. Update sample index")
        print("3. Check system health")
        print("4. Export configuration")
        print("5. Import configuration")
        print("6. Reset to defaults")
        
        choice = input("Select action (1-6): ").strip()
        
        if choice == "1":
            cache_dir = Path(config.CACHE_DIR)
            if cache_dir.exists():
                import shutil
                shutil.rmtree(cache_dir)
                print("âœ… Cache cleared")
            else:
                print("â„¹ï¸ No cache to clear")
        
        elif choice == "2":
            print("ğŸ”„ Updating sample index...")
            self.sample_engine.build_semantic_index()
            print("âœ… Index updated")
        
        elif choice == "3":
            print("ğŸ¥ Running system health check...")
            self._run_system_health_check()
        
        elif choice == "4":
            config_path = input("Export config to (default: wavedream_config.json): ").strip()
            if not config_path:
                config_path = "wavedream_config.json"
            
            try:
                config.export_config(config_path)
                print(f"âœ… Configuration exported: {config_path}")
            except Exception as e:
                print(f"âŒ Export error: {e}")
    
    def _interactive_settings(self):
        """Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸"""
        print("\nğŸ› ï¸ SETTINGS & CONFIGURATION")
        print("-" * 35)
        
        current_settings = {
            "Sample Directory": config.DEFAULT_SAMPLE_DIR,
            "Audio Analysis Max Duration": f"{config.AUDIO_ANALYSIS['max_duration']}s",
            "Sample Rate": f"{config.AUDIO_ANALYSIS['sample_rate']}Hz",
            "Tempo Tolerance": f"Â±{config.SAMPLE_MATCHING['tempo_tolerance']} BPM",
            "Min Score Threshold": config.SAMPLE_MATCHING['min_score_threshold'],
            "Max Workers": config.PERFORMANCE['max_workers'],
            "Semantic Analysis": config.SAMPLE_MATCHING['enable_semantic_embeddings']
        }
        
        print("Current settings:")
        for key, value in current_settings.items():
            print(f"  {key}: {value}")
        
        print(f"\nSupported genres: {', '.join([g.value for g in GenreType])}")
        print(f"Mastering purposes: {', '.join([p.value for p in MasteringPurpose])}")
        
        change = input("\nModify settings? (y/N): ").lower()
        if change == 'y':
            print("ğŸ’¡ To modify settings, edit the configuration files or use environment variables")
            print("ğŸ’¡ See documentation for detailed configuration options")
    
    def _display_statistics(self):
        """ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸"""
        print("\nğŸ“ˆ PERFORMANCE STATISTICS")
        print("-" * 30)
        
        stats = self.performance_stats
        
        print(f"Total generations: {stats['total_generations']}")
        print(f"Successful generations: {stats['successful_generations']}")
        
        if stats['total_generations'] > 0:
            success_rate = stats['successful_generations'] / stats['total_generations'] * 100
            print(f"Success rate: {success_rate:.1f}%")
            print(f"Average generation time: {stats['avg_generation_time']:.1f}s")
        
        if stats['genre_statistics']:
            print(f"\nGenre distribution:")
            for genre, count in sorted(stats['genre_statistics'].items(), key=lambda x: -x[1]):
                print(f"  {genre}: {count} generations")
        
        if stats['purpose_statistics']:
            print(f"\nPurpose distribution:")
            for purpose, count in sorted(stats['purpose_statistics'].items(), key=lambda x: -x[1]):
                print(f"  {purpose}: {count} generations")
        
        # Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
        print(f"\nSystem info:")
        print(f"  Sample database size: {len(self.sample_engine.samples_index)} samples")
        print(f"  Cache entries: {len(self.sample_engine.embeddings_cache)}")
    
    def _run_system_diagnostics(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ğ¾Ğ¹ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸"""
        print("\nğŸ”§ SYSTEM DIAGNOSTICS")
        print("-" * 25)
        
        print("Running comprehensive system check...")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
        print("\nğŸ“¦ Checking dependencies...")
        dependencies = ['torch', 'librosa', 'pydub', 'numpy', 'scipy', 'soundfile']
        
        for dep in dependencies:
            try:
                __import__(dep)
                print(f"  âœ… {dep}")
            except ImportError:
                print(f"  âŒ {dep} - Missing!")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹
        print(f"\nğŸ“ Checking directories...")
        dirs_to_check = [
            config.DEFAULT_SAMPLE_DIR,
            config.DEFAULT_OUTPUT_DIR,
            config.CACHE_DIR
        ]
        
        for dir_path in dirs_to_check:
            if os.path.exists(dir_path):
                print(f"  âœ… {dir_path}")
            else:
                print(f"  âš ï¸ {dir_path} - Not found")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        print(f"\nğŸ§  Checking semantic model...")
        try:
            if hasattr(self.sample_engine, 'semantic_model') and self.sample_engine.semantic_model:
                print(f"  âœ… Semantic model loaded")
            else:
                print(f"  âš ï¸ Semantic model not available")
        except Exception as e:
            print(f"  âŒ Semantic model error: {e}")
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
        print(f"\nâš¡ Performance test...")
        start_time = time.time()
        
        # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµÑÑ‚
        test_prompt = "test electronic music 120bpm"
        analysis = self.metadata_processor.analyze_prompt(test_prompt)
        
        test_time = time.time() - start_time
        print(f"  ğŸ“Š Prompt analysis: {test_time:.3f}s")
        
        if test_time < 1.0:
            print(f"  âœ… Performance: Good")
        elif test_time < 3.0:
            print(f"  âš ï¸ Performance: Acceptable")
        else:
            print(f"  âŒ Performance: Slow")
    
    def _run_system_health_check(self):
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹"""
        health_status = {
            "dependencies": True,
            "directories": True,
            "sample_index": True,
            "semantic_model": True,
            "memory_usage": True
        }
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        try:
            import psutil
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 90:
                health_status["memory_usage"] = False
                print(f"âš ï¸ High memory usage: {memory_percent:.1f}%")
            else:
                print(f"âœ… Memory usage: {memory_percent:.1f}%")
        except ImportError:
            print("â„¹ï¸ psutil not available - cannot check memory")
        
        # ĞĞ±Ñ‰Ğ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ
        overall_health = all(health_status.values())
        if overall_health:
            print("âœ… System health: Excellent")
        else:
            issues = [k for k, v in health_status.items() if not v]
            print(f"âš ï¸ System health issues: {', '.join(issues)}")
    
    def _get_purpose_description(self, purpose: str) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ°ÑÑ‚ĞµÑ€Ğ¸Ğ½Ğ³Ğ°"""
        descriptions = {
            "freelance": "Commercial sale, streaming optimization",
            "professional": "Broadcast/cinema, full dynamics",
            "personal": "Home listening, natural sound",
            "family": "Family videos, bright engaging",
            "streaming": "Platform optimized, loudness normalized",
            "vinyl": "Analog warm, vinyl-ready"
        }
        return descriptions.get(purpose, "General purpose")
    
    def _create_request_from_task(self, task_data: Dict, task_number: int) -> GenerationRequest:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"""
        return GenerationRequest(
            prompt=task_data.get("prompt", f"Generated track {task_number}"),
            genre=task_data.get("genre"),
            bpm=task_data.get("bpm"),
            duration=task_data.get("duration"),
            mastering_purpose=task_data.get("mastering_purpose", "personal"),
            output_dir=task_data.get("output_dir", f"batch_output/task_{task_number}"),
            export_stems=task_data.get("export_stems", True),
            energy_level=task_data.get("energy_level", 0.5),
            creativity_factor=task_data.get("creativity_factor", 0.7)
        )
    
    def _play_audio_file(self, file_path: str):
        """Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        try:
            import platform
            system = platform.system()
            
            if system == "Windows":
                os.system(f'start "" "{file_path}"')
            elif system == "Darwin":  # macOS
                os.system(f'open "{file_path}"')
            else:  # Linux
                os.system(f'xdg-open "{file_path}"')
                
            print("ğŸµ Opening audio file...")
        except Exception as e:
            print(f"âŒ Cannot open audio file: {e}")
    
    def _show_quality_details(self, result: GenerationResult):
        """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
        print(f"\nğŸ“Š QUALITY ANALYSIS DETAILS")
        print(f"Overall score: {result.quality_score:.2f}/1.0")
        
        if result.quality_score < 0.5:
            print("ğŸ”´ Poor quality - major issues detected")
        elif result.quality_score < 0.7:
            print("ğŸŸ¡ Acceptable quality - some issues present")
        elif result.quality_score < 0.9:
            print("ğŸŸ¢ Good quality - minor issues only")
        else:
            print("ğŸŸ¢ Excellent quality - no significant issues")
    
    def run_cli_mode(self, args):
        """Ğ ĞµĞ¶Ğ¸Ğ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸"""
        try:
            if args.prompt:
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ· Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
                request = GenerationRequest(
                    prompt=args.prompt,
                    genre=getattr(args, 'genre', None),
                    bpm=getattr(args, 'bpm', None),
                    duration=getattr(args, 'duration', None),
                    mastering_purpose=getattr(args, 'mastering_purpose', 'personal'),
                    output_dir=args.output_dir or 'cli_output',
                    export_stems=getattr(args, 'export_stems', True),
                    energy_level=getattr(args, 'energy_level', 0.5),
                    creativity_factor=getattr(args, 'creativity_factor', 0.7)
                )
                
                print(f"ğŸš€ CLI Generation: '{args.prompt}'")
                result = self.generate_track_sync(request)
                
                if result.success:
                    print(f"âœ… Success: {result.final_path}")
                    return 0
                else:
                    print(f"âŒ Failed: {result.error_message}")
                    return 1
                    
            elif getattr(args, 'batch', None):
                return self._run_cli_batch(args.batch)
                
            elif getattr(args, 'analyze', None):
                return self._run_cli_analyze(args.analyze)
                
            else:
                print("âŒ No valid CLI command provided")
                return 1
                
        except Exception as e:
            self.logger.error(f"CLI mode error: {e}")
            print(f"âŒ CLI error: {e}")
            return 1
    
    def _run_cli_batch(self, batch_file: str) -> int:
        """CLI Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"""
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                batch_data = json.load(f)
            
            tasks = batch_data.get("tasks", [])
            print(f"ğŸ“¦ Processing {len(tasks)} tasks from {batch_file}")
            
            successful = 0
            failed = 0
            
            for i, task_data in enumerate(tasks, 1):
                print(f"\n[{i}/{len(tasks)}] {task_data.get('name', f'Task {i}')}")
                
                try:
                    request = self._create_request_from_task(task_data, i)
                    result = self.generate_track_sync(request)
                    
                    if result.success:
                        print(f"âœ… {result.final_path}")
                        successful += 1
                    else:
                        print(f"âŒ {result.error_message}")
                        failed += 1
                        
                except Exception as e:
                    print(f"âŒ {e}")
                    failed += 1
            
            print(f"\nğŸ“Š Batch complete: {successful} successful, {failed} failed")
            return 0 if failed == 0 else 1
            
        except Exception as e:
            print(f"âŒ Batch processing error: {e}")
            return 1
    
    def _run_cli_analyze(self, file_path: str) -> int:
        """CLI Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°"""
        try:
            if not os.path.exists(file_path):
                print(f"âŒ File not found: {file_path}")
                return 1
            
            from pydub import AudioSegment
            audio = AudioSegment.from_file(file_path)
            
            target_config = {"target_lufs": -14, "peak_ceiling": -1}
            report = asyncio.run(self.verifier.analyze_track(audio, target_config))
            
            print(f"ğŸ“Š Quality Analysis: {file_path}")
            print(f"Score: {report.get('overall_score', 0):.2f}/1.0")
            print(f"Status: {report.get('status', 'unknown')}")
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚
            report_path = f"{Path(file_path).stem}_quality_report.md"
            if self.verifier.generate_markdown_report(report, report_path):
                print(f"ğŸ“‹ Report: {report_path}")
            
            return 0
            
        except Exception as e:
            print(f"âŒ Analysis error: {e}")
            return 1


def create_sample_batch_file():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸"""
    sample_batch = {
        "name": "WaveDream Enhanced Pro - Sample Batch",
        "version": "2.0",
        "default_settings": {
            "mastering_purpose": "personal",
            "export_stems": True,
            "export_formats": ["wav", "mp3"]
        },
        "tasks": [
            {
                "name": "Dark Trap Beat",
                "prompt": "dark aggressive trap 160bpm with vocal chops and 808s",
                "mastering_purpose": "freelance",
                "duration": 90,
                "energy_level": 0.8
            },
            {
                "name": "Lofi Study Music",
                "prompt": "melodic lofi study beats with vintage textures and vinyl crackle",
                "mastering_purpose": "personal",
                "duration": 120,
                "energy_level": 0.3
            },
            {
                "name": "Cinematic Epic",
                "prompt": "cinematic epic orchestral trailer music heroic and inspiring",
                "mastering_purpose": "professional",
                "duration": 180,
                "energy_level": 0.9
            },
            {
                "name": "House Groove",
                "prompt": "deep house groove with plucked bass and disco elements 124bpm",
                "mastering_purpose": "streaming",
                "duration": 240,
                "energy_level": 0.7
            }
        ]
    }
    
    with open("sample_batch_tasks.json", 'w', encoding='utf-8') as f:
        json.dump(sample_batch, f, indent=2, ensure_ascii=False)
    
    print("ğŸ“ Sample batch file created: sample_batch_tasks.json")


def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ½Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸"""
    parser = argparse.ArgumentParser(
        description="ğŸµ WaveDream Enhanced Pro v2.0 - Full AI Music Generation Suite",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸŒŸ Examples:

Interactive mode:
  python wavedream_enhanced_main.py

Quick generation:
  python wavedream_enhanced_main.py --prompt "dark trap 160bpm aggressive" --purpose freelance

Batch processing:
  python wavedream_enhanced_main.py --batch sample_batch_tasks.json

Quality analysis:
  python wavedream_enhanced_main.py --analyze track.wav

Create sample batch:
  python wavedream_enhanced_main.py --create-batch

Advanced generation:
  python wavedream_enhanced_main.py --prompt "melodic lofi study beats" --genre lofi --bpm 75 --duration 120 --purpose personal --stems

System diagnostics:
  python wavedream_enhanced_main.py --diagnostics

ğŸ¯ Mastering purposes: freelance, professional, personal, family, streaming, vinyl
ğŸ­ Genres: trap, lofi, dnb, ambient, techno, house, cinematic, hyperpop
        """
    )
    
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
    parser.add_argument("--prompt", type=str, help="Track description prompt")
    parser.add_argument("--genre", type=str, choices=[g.value for g in GenreType], help="Force specific genre")
    parser.add_argument("--bpm", type=int, help="Target BPM")
    parser.add_argument("--duration", type=int, help="Duration in seconds")
    parser.add_argument("--purpose", dest="mastering_purpose", choices=[p.value for p in MasteringPurpose], 
                        default="personal", help="Mastering purpose")
    parser.add_argument("--output-dir", type=str, help="Output directory")
    parser.add_argument("--stems", dest="export_stems", action="store_true", help="Export stem versions")
    parser.add_argument("--energy", dest="energy_level", type=float, default=0.5, help="Energy level (0-1)")
    parser.add_argument("--creativity", dest="creativity_factor", type=float, default=0.7, help="Creativity factor (0-1)")
    
    # ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
    parser.add_argument("--batch", type=str, help="Batch processing from JSON file")
    parser.add_argument("--create-batch", action="store_true", help="Create sample batch file")
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°
    parser.add_argument("--analyze", type=str, help="Analyze audio file quality")
    parser.add_argument("--diagnostics", action="store_true", help="Run system diagnostics")
    parser.add_argument("--stats", action="store_true", help="Show performance statistics")
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
    parser.add_argument("--rebuild-index", action="store_true", help="Rebuild sample index")
    parser.add_argument("--clear-cache", action="store_true", help="Clear cache files")
    parser.add_argument("--debug", action="store_true", help="Enable debug logging")
    parser.add_argument("--quiet", action="store_true", help="Minimal output")
    
    args = parser.parse_args()
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ»Ğ°ÑƒĞ½Ñ‡ĞµÑ€Ğ°
    try:
        launcher = WaveDreamEnhancedLauncher()
    except Exception as e:
        print(f"âŒ Failed to initialize WaveDream: {e}")
        return 1
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´
    if args.create_batch:
        create_sample_batch_file()
        return 0
    
    if args.diagnostics:
        launcher._run_system_diagnostics()
        return 0
    
    if args.stats:
        launcher._display_statistics()
        return 0
    
    if args.rebuild_index:
        print("ğŸ”„ Rebuilding sample index...")
        launcher.sample_engine.build_semantic_index()
        print("âœ… Index rebuilt")
        return 0
    
    if args.clear_cache:
        cache_dir = Path(config.CACHE_DIR)
        if cache_dir.exists():
            import shutil
            shutil.rmtree(cache_dir)
            print("âœ… Cache cleared")
        return 0
    
    # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    elif args.quiet:
        logging.getLogger().setLevel(logging.WARNING)
    
    # Ğ ĞµĞ¶Ğ¸Ğ¼Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
    if any([args.prompt, args.batch, args.analyze]):
        # CLI Ñ€ĞµĞ¶Ğ¸Ğ¼
        return launcher.run_cli_mode(args)
    else:
        # Ğ˜Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
        try:
            launcher.run_interactive_mode()
            return 0
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            return 0
        except Exception as e:
            launcher.logger.error(f"Interactive mode error: {e}")
            print(f"âŒ Unexpected error: {e}")
            return 1


def quick_start_wizard():
    """ĞœĞ°ÑÑ‚ĞµÑ€ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹"""
    print("""
ğŸŒŸ Welcome to WaveDream Enhanced Pro v2.0!
This wizard will help you create your first AI-generated track.
    """)
    
    # ĞŸÑ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹
    prompts = [
        "What style of music do you want? (e.g., 'dark trap', 'chill lofi', 'epic cinematic'): ",
        "Any specific tempo in BPM? (Enter for auto-detection): ",
        "How long should it be in seconds? (Enter for auto, typical: 60-120): ",
        "What will you use it for? (personal/freelance/professional/family): "
    ]
    
    answers = {}
    
    for i, prompt_text in enumerate(prompts):
        answer = input(prompt_text).strip()
        answers[i] = answer if answer else None
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ
    music_prompt = answers[0] or "electronic music"
    
    try:
        bpm = int(answers[1]) if answers[1] else None
    except ValueError:
        bpm = None
    
    try:
        duration = int(answers[2]) if answers[2] else None
    except ValueError:
        duration = None
    
    purpose = answers[3] if answers[3] in ["personal", "freelance", "professional", "family"] else "personal"
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ
    launcher = WaveDreamEnhancedLauncher()
    
    request = GenerationRequest(
        prompt=music_prompt,
        bpm=bpm,
        duration=duration,
        mastering_purpose=purpose,
        output_dir="quick_start_output",
        export_stems=True
    )
    
    print(f"\nğŸš€ Generating: '{music_prompt}' for {purpose} use")
    print("This may take a few minutes...")
    
    result = launcher.generate_track_sync(request)
    
    if result.success:
        print(f"\nğŸ‰ Your track is ready!")
        print(f"ğŸ“ Location: {result.final_path}")
        print(f"ğŸ¯ Quality: {result.quality_score:.2f}/1.0")
        print(f"\nğŸ’¡ Tip: Use the interactive mode (just run the script) for more options!")
    else:
        print(f"\nâŒ Generation failed: {result.error_message}")


if __name__ == "__main__":
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ¾Ğ²
    if len(sys.argv) == 2 and sys.argv[1] == "--quick-start":
        quick_start_wizard()
    else:
        sys.exit(main())
