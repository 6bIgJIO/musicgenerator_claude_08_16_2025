import logging
import numpy as np
import asyncio
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass
import json
from pathlib import Path
import io

# –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
from pydub import AudioSegment, effects
import librosa
import soundfile as sf

from config import config, MasteringPurpose
from sample_engine import EffectsChain


@dataclass
class MasteringTarget:
    """–¶–µ–ª–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞"""
    lufs: float                    # –¶–µ–ª–µ–≤–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å
    peak_ceiling: float           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–∏–∫
    dynamic_range: float          # –ñ–µ–ª–∞–µ–º—ã–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
    stereo_width: float          # –°—Ç–µ—Ä–µ–æ —à–∏—Ä–∏–Ω–∞ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
    frequency_balance: Dict      # –ë–∞–ª–∞–Ω—Å —á–∞—Å—Ç–æ—Ç
    harmonic_content: float      # –ñ–µ–ª–∞–µ–º–æ–µ –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    transient_preservation: float # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤


class SmartMasteringEngine:
    """
    –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —É–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ WaveDream 2.0
    
    –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    1. ‚úÖ –£–±—Ä–∞–Ω—ã –í–°–ï –∑–∞–≥–ª—É—à–∫–∏ —Å —Ç–∏—à–∏–Ω–æ–π
    2. ‚úÖ –°—Ç—Ä–æ–≥–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
    3. ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∑–≤—É–∫–∞
    4. ‚úÖ –†–µ–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ LUFS –∏ –¥–∏–Ω–∞–º–∏–∫–∏
    5. ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ fallback'—ã –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∏—à–∏–Ω—ã
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.effects_chain = EffectsChain()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        self._init_analyzers()
        
        # –ö—ç—à –∞–Ω–∞–ª–∏–∑–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
        self.analysis_cache = {}
        
        self.logger.info("üéõÔ∏è SmartMasteringEngine 2.0 initialized")
    
    def _init_analyzers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –∞—É–¥–∏–æ"""
        self.logger.info("üéõÔ∏è Initializing mastering analyzers...")
    
    def _load_audio_from_bytes(self, audio_bytes: bytes) -> AudioSegment:
        """
        –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –∑–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ - NO MORE SILENCE FALLBACKS!
        """
        if not audio_bytes or len(audio_bytes) == 0:
            raise ValueError("‚ùå CRITICAL: Empty audio bytes provided to mastering!")
        
        try:
            audio_io = io.BytesIO(audio_bytes)
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏
            formats_to_try = ['wav', 'mp3', 'flac', 'ogg', 'm4a', 'aiff']
            
            for fmt in formats_to_try:
                try:
                    audio_io.seek(0)
                    audio = AudioSegment.from_file(audio_io, format=fmt)
                    
                    # –°–¢–†–û–ì–ò–ï –ü–†–û–í–ï–†–ö–ò - –ù–ï –ü–†–ò–ù–ò–ú–ê–ï–ú –ü–£–°–¢–û–ï/–¢–ò–•–û–ï –ê–£–î–ò–û
                    if len(audio) == 0:
                        self.logger.debug(f"Format {fmt} loaded empty audio, trying next...")
                        continue
                    
                    if audio.max_dBFS == float('-inf'):
                        self.logger.debug(f"Format {fmt} loaded silent audio, trying next...")
                        continue
                    
                    # –í–°–ï –û–ö - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–∞–ª–∏–¥–Ω–æ–µ –∞—É–¥–∏–æ
                    self.logger.info(f"‚úÖ Audio loaded as {fmt}: "
                                   f"{len(audio)/1000:.1f}s, {audio.channels}ch, "
                                   f"{audio.frame_rate}Hz, peak: {audio.max_dBFS:.1f}dB")
                    return audio
                    
                except Exception as e:
                    self.logger.debug(f"Format {fmt} failed: {e}")
                    continue
            
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
            try:
                audio_io.seek(0)
                audio = AudioSegment.from_file(audio_io)
                
                if len(audio) == 0 or audio.max_dBFS == float('-inf'):
                    raise ValueError("Auto-detected audio is empty or silent")
                
                self.logger.info(f"‚úÖ Audio loaded (auto-detect): "
                               f"{len(audio)/1000:.1f}s, {audio.channels}ch, {audio.frame_rate}Hz")
                return audio
                
            except Exception as e:
                self.logger.error(f"‚ùå Even auto-detect failed: {e}")
            
            # –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ö–ê–ó - –ù–ï –í–û–ó–í–†–ê–©–ê–ï–ú –¢–ò–®–ò–ù–£!
            raise ValueError("‚ùå CRITICAL: Cannot load any valid audio from bytes!")
            
        except Exception as e:
            self.logger.error(f"‚ùå CRITICAL: Audio loading completely failed: {e}")
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∑–∞–≥–ª—É—à–∫–∏
    
    async def master_track(
        self,
        audio: Union[bytes, AudioSegment], 
        target_config: Dict,
        genre_info: Dict,
        purpose: str
    ) -> Tuple[AudioSegment, Dict]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ WaveDream 2.0
        """
        self.logger.info(f"üéõÔ∏è Starting WaveDream 2.0 mastering: {purpose}")

        try:
            # === –≠–¢–ê–ü 1: –í–ê–õ–ò–î–ê–¶–ò–Ø –ò –ó–ê–ì–†–£–ó–ö–ê –ò–°–•–û–î–ù–û–ì–û –ê–£–î–ò–û ===
            source_audio = None
            
            if isinstance(audio, (bytes, bytearray)):
                if len(audio) == 0:
                    raise ValueError("‚ùå CRITICAL: Empty bytes provided to master_track!")
                source_audio = self._load_audio_from_bytes(bytes(audio))
                
            elif isinstance(audio, AudioSegment):
                source_audio = audio
                
            elif hasattr(audio, 'export'):  # AudioSegment-like object
                source_audio = audio
                
            else:
                raise TypeError(f"‚ùå CRITICAL: Unsupported audio type: {type(audio)}")

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê –ó–ê–ì–†–£–ñ–ï–ù–ù–û–ì–û –ê–£–î–ò–û
            if source_audio is None:
                raise ValueError("‚ùå CRITICAL: source_audio is None after loading!")
            
            if len(source_audio) < 100:  # –ú–∏–Ω–∏–º—É–º 100–º—Å
                raise ValueError(f"‚ùå CRITICAL: Audio too short for mastering: {len(source_audio)}ms")
            
            if source_audio.max_dBFS == float('-inf'):
                raise ValueError("‚ùå CRITICAL: Source audio is completely silent!")

            # === –≠–¢–ê–ü 2: –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ò–°–•–û–î–ù–û–ì–û –ú–ê–¢–ï–†–ò–ê–õ–ê ===
            self.logger.info("  üìä Analyzing source material...")
            try:
                source_analysis = await self._analyze_source_material(source_audio)
                self.logger.info(
                    f"  üìä Analysis: LUFS {source_analysis['lufs']:.1f}, "
                    f"peak {source_analysis['peak']:.1f}dB, "
                    f"DR {source_analysis['dynamic_range']:.1f}LU, "
                    f"duration {source_analysis['duration']:.1f}s"
                )
            except Exception as e:
                self.logger.error(f"‚ùå Source analysis failed: {e}")
                # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–æ –ù–ï –û–¢–ö–ê–ó–´–í–ê–ï–ú–°–Ø –û–¢ –ú–ê–°–¢–ï–†–ò–ù–ì–ê
                source_analysis = {
                    'lufs': -23.0,
                    'peak': source_audio.max_dBFS,
                    'dynamic_range': 10.0,
                    'duration': len(source_audio) / 1000.0,
                    'frequency_balance': {'low': 0.33, 'mid': 0.33, 'high': 0.34}
                }
                self.logger.warning("‚ö†Ô∏è Using fallback analysis values")

            # === –≠–¢–ê–ü 3: –°–û–ó–î–ê–ù–ò–ï –¶–ï–õ–ï–ô –ú–ê–°–¢–ï–†–ò–ù–ì–ê ===
            mastering_target = self._create_mastering_target(target_config, genre_info, source_analysis)
            self.logger.info(f"  üéØ Target: {mastering_target.lufs} LUFS, {mastering_target.peak_ceiling} dB ceiling")
            
            # === –≠–¢–ê–ü 4: –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò ===
            processing_plan = await self._plan_mastering_chain(source_analysis, mastering_target, genre_info)
            self.logger.info(f"  üìã Processing plan: {len(processing_plan['stages'])} stages")
            
            # === –≠–¢–ê–ü 5: –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –û–ë–†–ê–ë–û–¢–ö–ò ===
            mastered_audio = await self._apply_mastering_chain(source_audio, processing_plan)
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê –ú–ê–°–¢–ï–†–ò–ù–ì–ê
            if mastered_audio is None:
                raise ValueError("‚ùå CRITICAL: Mastering chain returned None!")
            
            if mastered_audio.max_dBFS == float('-inf'):
                self.logger.error("‚ùå WARNING: Mastering resulted in silence!")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ –≤–º–µ—Å—Ç–æ —Ç–∏—à–∏–Ω—ã
                mastered_audio = effects.normalize(source_audio)
                self.logger.warning("üö® Using normalized original as fallback")
            
            if len(mastered_audio) == 0:
                raise ValueError("‚ùå CRITICAL: Mastered audio has zero duration!")
            
            # === –≠–¢–ê–ü 6: –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø ===
            mastered_audio = await self._final_verification_pass(mastered_audio, mastering_target)
            
            # === –≠–¢–ê–ü 7: –°–û–ó–î–ê–ù–ò–ï –û–¢–ß–ï–¢–ê ===
            applied_config = self._create_mastering_report(processing_plan, source_analysis, mastering_target)

            # === –§–ò–ù–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–ê ===
            try:
                result_analysis = await self._analyze_source_material(mastered_audio)
                self.logger.info(
                    f"  ‚úÖ Mastered result: LUFS {result_analysis['lufs']:.1f}, "
                    f"peak {result_analysis['peak']:.1f}dB, "
                    f"DR {result_analysis['dynamic_range']:.1f}LU"
                )
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Result analysis failed: {e}")

            return mastered_audio, applied_config

        except Exception as e:
            self.logger.error(f"‚ùå CRITICAL Mastering error: {e}")
            
            # === –£–õ–£–ß–®–ï–ù–ù–´–ô FALLBACK –ë–ï–ó –ü–û–¢–ï–†–ò –ò–°–•–û–î–ù–û–ì–û –ê–£–î–ò–û ===
            try:
                self.logger.info("üö® Attempting intelligent fallback recovery...")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                fallback_audio = None
                
                if isinstance(audio, (bytes, bytearray)) and len(audio) > 0:
                    fallback_audio = self._load_audio_from_bytes(bytes(audio))
                elif isinstance(audio, AudioSegment):
                    fallback_audio = audio
                
                if fallback_audio is not None and fallback_audio.max_dBFS != float('-inf'):
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –±–∞–∑–æ–≤—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∫–∞–∫ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                    normalized_audio = effects.normalize(fallback_audio)
                    
                    # –ü—Ä–æ—Å—Ç–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –ø–æ–¥ —Ü–µ–ª–µ–≤–æ–π LUFS
                    target_lufs = target_config.get("target_lufs", -16)
                    current_rms_db = 20 * np.log10(normalized_audio.rms / normalized_audio.max_possible_amplitude)
                    adjustment = target_lufs - (current_rms_db - 23)  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ LUFS
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
                    adjustment = max(-12, min(12, adjustment))
                    
                    if adjustment != 0:
                        fallback_audio = normalized_audio + adjustment
                    else:
                        fallback_audio = normalized_audio
                    
                    self.logger.warning(f"üö® Fallback successful: normalized + {adjustment:.1f}dB adjustment")
                    return fallback_audio, target_config
                
                # –ï—Å–ª–∏ –¥–∞–∂–µ fallback –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                raise ValueError("‚ùå FATAL: Cannot recover any valid audio!")
                
            except Exception as fallback_error:
                self.logger.error(f"‚ùå FATAL: Fallback also failed: {fallback_error}")
                raise ValueError(f"‚ùå FATAL: Complete mastering failure: {e}, fallback: {fallback_error}")
  
    async def _analyze_source_material(self, audio: AudioSegment) -> Dict:
        """
        –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
        """
        try:
            # –í–•–û–î–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø
            if audio is None:
                raise ValueError("‚ùå Audio is None in analysis")
            
            if len(audio) == 0:
                raise ValueError("‚ùå Audio has zero duration in analysis")
            
            if audio.max_dBFS == float('-inf'):
                raise ValueError("‚ùå Audio is completely silent in analysis")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
            if audio.channels == 2:
                samples = samples.reshape((-1, 2))
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–º–ø–ª–∏—Ç—É–¥—ã
            max_val = 2**(audio.sample_width * 8 - 1)
            samples = samples / max_val
            sample_rate = audio.frame_rate
            
            analysis = {}
            
            # === –ë–ê–ó–û–í–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò ===
            analysis['peak'] = audio.max_dBFS
            analysis['rms'] = audio.rms
            analysis['duration'] = len(audio) / 1000.0
            
            # === –£–õ–£–ß–®–ï–ù–ù–´–ô LUFS –ê–ù–ê–õ–ò–ó ===
            if audio.rms > 0:
                # –ë–æ–ª–µ–µ —Ç–æ—á–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ LUFS —á–µ—Ä–µ–∑ RMS
                rms_db = 20 * np.log10(audio.rms / audio.max_possible_amplitude)
                # LUFS ‚âà RMS - 23 (—É–ø—Ä–æ—â–µ–Ω–∏–µ, –Ω–æ –ª—É—á—à–µ —á–µ–º –Ω–∏—á–µ–≥–æ)
                analysis['lufs'] = max(-70, rms_db - 23)
            else:
                analysis['lufs'] = -70
            
            # === –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –î–ò–ê–ü–ê–ó–û–ù ===
            if audio.rms > 0:
                rms_db = 20 * np.log10(audio.rms / audio.max_possible_amplitude)
                analysis['dynamic_range'] = abs(analysis['peak'] - rms_db)
            else:
                analysis['dynamic_range'] = 0
            
            # === –°–ü–ï–ö–¢–†–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó (–ë–ï–ó–û–ü–ê–°–ù–´–ô) ===
            mono_samples = samples.mean(axis=1) if audio.channels == 2 else samples
            
            if len(mono_samples) > 0:
                try:
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    max_samples = sample_rate * 30  # –ú–∞–∫—Å–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥
                    if len(mono_samples) > max_samples:
                        mono_samples = mono_samples[:max_samples]
                    
                    # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å librosa
                    spectral_centroid = librosa.feature.spectral_centroid(y=mono_samples, sr=sample_rate)
                    analysis['spectral_centroid'] = float(np.mean(spectral_centroid))
                    
                    spectral_rolloff = librosa.feature.spectral_rolloff(y=mono_samples, sr=sample_rate)
                    analysis['spectral_rolloff'] = float(np.mean(spectral_rolloff))
                    
                except Exception as e:
                    self.logger.debug(f"Advanced spectral analysis failed, using fallback: {e}")
                    analysis['spectral_centroid'] = 2000.0
                    analysis['spectral_rolloff'] = 8000.0
                
                # === –°–¢–ï–†–ï–û –ê–ù–ê–õ–ò–ó ===
                if audio.channels == 2 and len(samples) > 0:
                    try:
                        left = samples[:, 0]
                        right = samples[:, 1]
                        
                        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å—Ç–µ—Ä–µ–æ –∫–∞–Ω–∞–ª–æ–≤
                        correlation = np.corrcoef(left, right)[0, 1]
                        if np.isnan(correlation) or np.isinf(correlation):
                            correlation = 1.0
                            
                        analysis['stereo_correlation'] = float(correlation)
                        analysis['stereo_width'] = max(0.0, min(2.0, 1.0 - abs(correlation)))
                        
                    except Exception as e:
                        self.logger.debug(f"Stereo analysis failed: {e}")
                        analysis['stereo_correlation'] = 1.0
                        analysis['stereo_width'] = 0.0
                else:
                    analysis['stereo_correlation'] = 1.0
                    analysis['stereo_width'] = 0.0
                
                # === –ß–ê–°–¢–û–¢–ù–û–ï –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï ===
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Å—ç–º–ø–ª –¥–ª—è FFT
                    fft_length = min(len(mono_samples), sample_rate * 10)  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–µ–∫
                    fft_samples = mono_samples[:fft_length]
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–∫–Ω–æ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π
                    windowed = fft_samples * np.hanning(len(fft_samples))
                    fft = np.fft.rfft(windowed)
                    freqs = np.fft.rfftfreq(len(fft_samples), 1/sample_rate)
                    magnitude = np.abs(fft)
                    
                    # –ß–∞—Å—Ç–æ—Ç–Ω—ã–µ –ø–æ–ª–æ—Å—ã
                    low_mask = freqs < 250      # –ë–∞—Å—ã
                    mid_mask = (freqs >= 250) & (freqs < 4000)  # –°–µ—Ä–µ–¥–∏–Ω–∞  
                    high_mask = freqs >= 4000   # –í–µ—Ä—Ö–∞
                    
                    total_energy = np.sum(magnitude**2) + 1e-10
                    
                    analysis['frequency_balance'] = {
                        'low': float(np.sum(magnitude[low_mask]**2) / total_energy),
                        'mid': float(np.sum(magnitude[mid_mask]**2) / total_energy), 
                        'high': float(np.sum(magnitude[high_mask]**2) / total_energy)
                    }
                    
                except Exception as e:
                    self.logger.debug(f"Frequency analysis failed: {e}")
                    analysis['frequency_balance'] = {'low': 0.33, 'mid': 0.34, 'high': 0.33}
                
                # === –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò ===
                try:
                    # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
                    diff = np.abs(np.diff(mono_samples))
                    transient_density = np.mean(diff) * 1000  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
                    analysis['transient_density'] = float(min(10.0, max(0.0, transient_density)))
                    
                    # –ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–∏–µ/–ø–µ—Ä–∫—É—Å—Å–∏–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ)
                    analysis['harmonic_ratio'] = 0.6  # –ó–∞–≥–ª—É—à–∫–∞, —Ç—Ä–µ–±—É–µ—Ç —Å–ª–æ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                    analysis['percussive_ratio'] = 0.4
                    
                except Exception as e:
                    self.logger.debug(f"Transient analysis failed: {e}")
                    analysis['transient_density'] = 5.0
                    analysis['harmonic_ratio'] = 0.5
                    analysis['percussive_ratio'] = 0.5
            else:
                # Fallback –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω
                analysis.update({
                    'spectral_centroid': 2000.0,
                    'spectral_rolloff': 8000.0,
                    'stereo_correlation': 1.0,
                    'stereo_width': 0.0,
                    'frequency_balance': {'low': 0.33, 'mid': 0.34, 'high': 0.33},
                    'transient_density': 5.0,
                    'harmonic_ratio': 0.5,
                    'percussive_ratio': 0.5
                })
            
            # === –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø –ê–ù–ê–õ–ò–ó–ê ===
            if analysis['peak'] == float('-inf') or analysis['rms'] == 0:
                raise ValueError("‚ùå Analysis detected completely silent audio")
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã–µ
            for key, value in analysis.items():
                if isinstance(value, (int, float)) and (np.isnan(value) or np.isinf(value)):
                    self.logger.warning(f"‚ö†Ô∏è Invalid analysis value for {key}, using fallback")
                    fallback_values = {
                        'lufs': -23.0, 'peak': -6.0, 'dynamic_range': 8.0,
                        'spectral_centroid': 2000.0, 'spectral_rolloff': 8000.0,
                        'stereo_correlation': 1.0, 'stereo_width': 0.5,
                        'transient_density': 5.0, 'harmonic_ratio': 0.5, 'percussive_ratio': 0.5
                    }
                    analysis[key] = fallback_values.get(key, 0.0)
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå CRITICAL: Source analysis completely failed: {e}")
            raise ValueError(f"Source analysis failed - audio may be corrupted: {e}")
    
    def _create_mastering_target(self, target_config: Dict, genre_info: Dict, source_analysis: Dict) -> MasteringTarget:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∏ –∂–∞–Ω—Ä–∞"""
        
        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        target = MasteringTarget(
            lufs=target_config.get("target_lufs", -16),
            peak_ceiling=target_config.get("peak_ceiling", -1),
            dynamic_range=target_config.get("dynamic_range", 8),
            stereo_width=target_config.get("stereo_enhancement", 1.0),
            frequency_balance={},
            harmonic_content=target_config.get("harmonic_saturation", 0.2),
            transient_preservation=0.8
        )
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∂–∞–Ω—Ä
        genre = genre_info.get("name", "").lower()
        
        # –ñ–∞–Ω—Ä–æ–≤—ã–µ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –¥–ª—è WaveDream 2.0
        genre_adaptations = {
            "trap": {
                "frequency_balance": {"low": 0.4, "mid": 0.35, "high": 0.25},
                "stereo_width": 1.2,
                "transient_preservation": 0.9,
                "lufs_adjustment": -2  # –ß—É—Ç—å —Ç–∏—à–µ –¥–ª—è —Ç—Ä–∞–ø–∞
            },
            "lofi": {
                "frequency_balance": {"low": 0.35, "mid": 0.45, "high": 0.2},
                "stereo_width": 0.8,
                "transient_preservation": 0.6,
                "lufs_adjustment": -1
            },
            "drum and bass": {
                "frequency_balance": {"low": 0.35, "mid": 0.35, "high": 0.3},
                "stereo_width": 1.1,
                "transient_preservation": 0.95,
                "lufs_adjustment": -1
            },
            "dnb": {
                "frequency_balance": {"low": 0.35, "mid": 0.35, "high": 0.3},
                "stereo_width": 1.1,
                "transient_preservation": 0.95,
                "lufs_adjustment": -1
            },
            "ambient": {
                "frequency_balance": {"low": 0.25, "mid": 0.45, "high": 0.3},
                "stereo_width": 1.5,
                "transient_preservation": 0.5,
                "lufs_adjustment": -3  # –¢–∏—à–µ –¥–ª—è —ç–º–±–∏–µ–Ω—Ç–∞
            },
            "techno": {
                "frequency_balance": {"low": 0.4, "mid": 0.35, "high": 0.25},
                "stereo_width": 1.0,
                "transient_preservation": 0.85,
                "lufs_adjustment": 0
            },
            "house": {
                "frequency_balance": {"low": 0.35, "mid": 0.4, "high": 0.25},
                "stereo_width": 1.1,
                "transient_preservation": 0.8,
                "lufs_adjustment": 0
            },
            "cinematic": {
                "frequency_balance": {"low": 0.3, "mid": 0.4, "high": 0.3},
                "stereo_width": 1.3,
                "transient_preservation": 0.7,
                "lufs_adjustment": -4  # –¢–∏—à–µ –¥–ª—è –∫–∏–Ω–æ
            }
        }
        
        if genre in genre_adaptations:
            adaptations = genre_adaptations[genre]
            target.frequency_balance = adaptations["frequency_balance"]
            target.stereo_width = adaptations["stereo_width"]
            target.transient_preservation = adaptations["transient_preservation"]
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º LUFS –ø–æ–¥ –∂–∞–Ω—Ä
            lufs_adj = adaptations.get("lufs_adjustment", 0)
            target.lufs += lufs_adj
        else:
            # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –±–∞–ª–∞–Ω—Å –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤
            target.frequency_balance = {"low": 0.33, "mid": 0.34, "high": 0.33}
        
        return target
    
    async def _plan_mastering_chain(
        self, source_analysis: Dict, target: MasteringTarget, genre_info: Dict
    ) -> Dict:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        plan = {
            "stages": [],
            "parameters": {},
            "genre_specific": {}
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        lufs_diff = target.lufs - source_analysis["lufs"]
        peak_diff = target.peak_ceiling - source_analysis["peak"]
        
        self.logger.debug(f"  üìä Planning: LUFS diff {lufs_diff:.1f}, peak diff {peak_diff:.1f}")
        
        # === 1. EQ –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï ===
        source_balance = source_analysis.get("frequency_balance", {"low": 0.33, "mid": 0.33, "high": 0.34})
        target_balance = target.frequency_balance
        
        eq_corrections = {}
        for band in ["low", "mid", "high"]:
            source_level = source_balance.get(band, 0.33)
            target_level = target_balance.get(band, 0.33)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dB –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
            if target_level > source_level:
                correction = min(4, (target_level - source_level) * 15)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
            else:
                correction = max(-4, (target_level - source_level) * 15)
            
            eq_corrections[band] = correction
        
        # –î–æ–±–∞–≤–ª—è–µ–º EQ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        if any(abs(c) > 0.3 for c in eq_corrections.values()):
            plan["stages"].append("eq")
            plan["parameters"]["eq"] = eq_corrections
            self.logger.debug(f"  üéõÔ∏è EQ corrections: {eq_corrections}")
        
        # === 2. –ö–û–ú–ü–†–ï–°–°–ò–Ø –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï ===
        source_dr = source_analysis.get("dynamic_range", 10)
        target_dr = target.dynamic_range
        
        if source_dr > target_dr + 1:  # –ù—É–∂–Ω–∞ –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
            compression_ratio = min(6.0, 1 + (source_dr - target_dr) / 4)
            threshold = source_analysis["peak"] - (source_dr * 0.6)
            
            plan["stages"].append("compressor")
            plan["parameters"]["compressor"] = {
                "ratio": compression_ratio,
                "threshold": max(-30, threshold),  # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
                "attack": 15,  # ms
                "release": 120,  # ms
                "knee": 2.0
            }
            self.logger.debug(f"  üóúÔ∏è Compression: ratio {compression_ratio:.1f}, threshold {threshold:.1f}dB")
        
        # === 3. –ù–ê–°–´–©–ï–ù–ò–ï –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï ===
        if target.harmonic_content > 0.05:
            genre = genre_info.get("name", "").lower()
            saturation_types = {
                "lofi": "tape",
                "trap": "tube", 
                "techno": "digital",
                "ambient": "tube",
                "house": "tube",
                "drum and bass": "transistor",
                "dnb": "transistor"
            }
            
            plan["stages"].append("saturation")
            plan["parameters"]["saturation"] = {
                "amount": min(0.5, target.harmonic_content),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
                "type": saturation_types.get(genre, "tube"),
                "warmth": target.harmonic_content * 1.2
            }
            self.logger.debug(f"  üî• Saturation: {target.harmonic_content:.2f} amount")
        
        # === 4. –°–¢–ï–†–ï–û –û–ë–†–ê–ë–û–¢–ö–ê ===
        source_width = source_analysis.get("stereo_width", 0.5)
        width_diff = abs(target.stereo_width - source_width)
        
        if width_diff > 0.1:
            plan["stages"].append("stereo")
            plan["parameters"]["stereo"] = {
                "width": min(2.0, max(0.0, target.stereo_width)),  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
                "imaging": "enhanced" if target.stereo_width > 1.2 else "natural"
            }
            self.logger.debug(f"  üéß Stereo width: {source_width:.2f} -> {target.stereo_width:.2f}")
        
        # === 5. –†–ï–í–ï–†–ë (–∂–∞–Ω—Ä–æ–≤–æ-–∑–∞–≤–∏—Å–∏–º—ã–π) ===
        genre = genre_info.get("name", "").lower()
        if genre in ["ambient", "cinematic", "ethereal"]:
            plan["stages"].append("reverb")
            reverb_settings = {
                "ambient": {"room_size": 0.8, "wet_level": 0.3, "type": "hall"},
                "cinematic": {"room_size": 0.7, "wet_level": 0.25, "type": "cinematic_hall"},
                "ethereal": {"room_size": 0.6, "wet_level": 0.2, "type": "shimmer"}
            }
            plan["parameters"]["reverb"] = reverb_settings.get(genre, {"room_size": 0.5, "wet_level": 0.15})
        
        # === 6. –õ–ò–ú–ò–¢–ï–† (–≤—Å–µ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç—Ç–∞–ø) ===
        plan["stages"].append("limiter")
        plan["parameters"]["limiter"] = {
            "threshold": target.peak_ceiling + 0.5,  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
            "ceiling": target.peak_ceiling,
            "release": 100,  # ms
            "lookahead": 5   # ms
        }
        
        # === 7. –ñ–ê–ù–†–û–í–û-–°–ü–ï–¶–ò–§–ò–ß–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò ===
        plan["genre_specific"] = {
            "preserve_transients": target.transient_preservation,
            "target_loudness": target.lufs,
            "processing_intensity": min(1.0, abs(lufs_diff) / 12),  # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å
            "genre": genre_info.get("name", "unknown")
        }
        
        self.logger.info(f"  üìã Processing plan: {len(plan['stages'])} stages - {', '.join(plan['stages'])}")
        
        return plan
    
    async def _apply_mastering_chain(self, audio: AudioSegment, plan: Dict) -> AudioSegment:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
        """
        
        processed = audio
        
        # –í–•–û–î–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø
        if processed.max_dBFS == float('-inf'):
            raise ValueError("‚ùå CRITICAL: Input audio to mastering chain is silent!")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        original_audio = audio
        
        for i, stage in enumerate(plan["stages"]):
            if stage in plan["parameters"]:
                params = plan["parameters"][stage]
                
                # –°–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                pre_peak = processed.max_dBFS
                pre_duration = len(processed)
                
                self.logger.debug(f"  üîß Stage {i+1}: {stage} with {params}")
                
                try:
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç
                    processed = await self._apply_mastering_effect(processed, stage, params)
                    
                    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
                    if processed is None:
                        raise ValueError(f"Effect {stage} returned None!")
                    
                    if processed.max_dBFS == float('-inf'):
                        raise ValueError(f"Effect {stage} made audio silent!")
                    
                    if len(processed) == 0:
                        raise ValueError(f"Effect {stage} made audio empty!")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π
                    post_peak = processed.max_dBFS
                    post_duration = len(processed)
                    
                    if abs(post_duration - pre_duration) > 100:  # –î–æ–ø—É—Å–∫–∞–µ–º 100–º—Å —Ä–∞–∑–Ω–∏—Ü—ã
                        self.logger.warning(f"‚ö†Ô∏è {stage} changed duration: {pre_duration} -> {post_duration}")
                    
                    peak_change = post_peak - pre_peak
                    if abs(peak_change) > 20:  # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∏–∫–∞
                        self.logger.warning(f"‚ö†Ô∏è {stage} large peak change: {peak_change:.1f}dB")
                    
                    self.logger.debug(f"    ‚úÖ {stage} OK: peak {pre_peak:.1f} -> {post_peak:.1f} dB")
                        
                except Exception as e:
                    self.logger.error(f"‚ùå Effect {stage} failed: {e}")
                    
                    # –†–µ—à–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∏–ª–∏ –ø—Ä–µ—Ä–≤–∞—Ç—å
                    if stage == "limiter":
                        # –õ–∏–º–∏—Ç–µ—Ä –∫—Ä–∏—Ç–∏—á–µ–Ω, –Ω–æ –º–æ–∂–µ–º –∑–∞–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
                        try:
                            ceiling = params.get("ceiling", -1)
                            if processed.max_dBFS > ceiling:
                                reduction = processed.max_dBFS - ceiling
                                processed = processed - reduction
                                self.logger.warning(f"‚ö†Ô∏è Applied simple limiting: -{reduction:.1f}dB")
                        except Exception as e2:
                            self.logger.error(f"‚ùå Even simple limiting failed: {e2}")
                            # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    
                    # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    self.logger.warning(f"‚ö†Ô∏è Skipping {stage}, continuing with previous state")
        
        # –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –í–°–ï–ô –¶–ï–ü–û–ß–ö–ò
        if processed.max_dBFS == float('-inf') or len(processed) == 0:
            self.logger.error("‚ùå CRITICAL: Entire mastering chain failed!")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –æ—Ä–∏–≥–∏–Ω–∞–ª
            processed = effects.normalize(original_audio)
            self.logger.warning("üö® Using normalized original as mastering fallback")
        
        return processed
    
    async def _apply_mastering_effect(self, audio: AudioSegment, effect: str, params: Dict) -> AudioSegment:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –±–∞–∑–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º fallback
        """
        try:
            # –í—Ö–æ–¥–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if audio.max_dBFS == float('-inf'):
                self.logger.warning(f"‚ö†Ô∏è Skipping {effect} - input audio is silent")
                return audio
            
            if effect == "limiter":
                # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ª–∏–º–∏—Ç–µ—Ä
                ceiling = params.get("ceiling", -1)
                threshold = params.get("threshold", -2)
                
                if audio.max_dBFS > ceiling:
                    # –ú—è–≥–∫–æ–µ –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∫–æ–º–ø—Ä–µ—Å—Å–∏–µ–π
                    over_threshold = audio.max_dBFS - threshold
                    
                    if over_threshold > 0:
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–º–ø—Ä–µ—Å—Å–∏—é –∫ —á–∞—Å—Ç–∏ –Ω–∞–¥ –ø–æ—Ä–æ–≥–æ–º
                        compressed = effects.compress_dynamic_range(
                            audio, 
                            threshold=threshold,
                            ratio=4.0,
                            attack=1.0,
                            release=50.0
                        )
                        
                        # –ó–∞—Ç–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
                        if compressed.max_dBFS > ceiling:
                            final_reduction = compressed.max_dBFS - ceiling
                            result = compressed - final_reduction
                        else:
                            result = compressed
                    else:
                        # –ü—Ä–æ—Å—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∏–∫
                        reduction = audio.max_dBFS - ceiling
                        result = audio - reduction
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if result.max_dBFS == float('-inf'):
                        self.logger.warning(f"‚ö†Ô∏è Limiter result is silent, using original")
                        return audio
                    
                    return result
                
                return audio
            
            elif effect == "compressor":
                # –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                try:
                    threshold = max(-40, min(-6, params.get("threshold", -20)))
                    ratio = max(1.1, min(10.0, params.get("ratio", 3.0)))
                    
                    if audio.max_dBFS > threshold:
                        result = effects.compress_dynamic_range(
                            audio,
                            threshold=threshold,
                            ratio=ratio,
                            attack=params.get("attack", 10),
                            release=params.get("release", 100)
                        )
                        
                        if result.max_dBFS == float('-inf'):
                            self.logger.warning("‚ö†Ô∏è Compressor made audio silent, using original")
                            return audio
                        
                        return result
                    
                    return audio
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Compressor failed: {e}, using original")
                    return audio
            
            elif effect == "eq":
                # –ü—Ä–æ—Å—Ç–æ–π 3-–ø–æ–ª–æ—Å–Ω—ã–π EQ —á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                try:
                    result = audio
                    corrections = params
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –µ—Å–ª–∏ –æ–Ω–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ
                    for band, correction in corrections.items():
                        if abs(correction) > 0.5:  # –ü–æ—Ä–æ–≥ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è
                            if band == "low" and correction != 0:
                                # –ë–∞—Å–æ–≤–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —á–µ—Ä–µ–∑ gain
                                result = result + (correction * 0.5)  # –°–º—è–≥—á–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
                            elif band == "high" and correction != 0:
                                # –í—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
                                result = result + (correction * 0.3)  # –ï—â–µ –º—è–≥—á–µ –¥–ª—è –≤–µ—Ä—Ö–æ–≤
                            # –î–ª—è mid –ø–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (—Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å
                    if result.max_dBFS > -0.1:
                        result = effects.normalize(result, headroom=1.0)
                    
                    return result
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è EQ failed: {e}, using original")
                    return audio
            
            elif effect == "saturation":
                # –ü—Ä–æ—Å—Ç–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ overdrive
                try:
                    amount = min(0.3, max(0.0, params.get("amount", 0.1)))
                    
                    if amount > 0.05:
                        # –ú—è–≥–∫–∏–π overdrive
                        boosted = audio + (amount * 20)  # –ù–µ–±–æ–ª—å—à–æ–π –±—É—Å—Ç
                        
                        # Soft clipping simulation
                        if boosted.max_dBFS > -1:
                            result = effects.normalize(boosted, headroom=1.0)
                        else:
                            result = boosted
                        
                        return result
                    
                    return audio
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Saturation failed: {e}, using original")
                    return audio
            
            elif effect == "stereo":
                # –°—Ç–µ—Ä–µ–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ/—Å—É–∂–µ–Ω–∏–µ
                try:
                    if audio.channels == 2:
                        width = params.get("width", 1.0)
                        
                        if abs(width - 1.0) > 0.1:
                            # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ç–µ—Ä–µ–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ/—Å—É–∂–µ–Ω–∏–µ
                            # –≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, –ø–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                            self.logger.debug(f"Stereo width adjustment: {width} (not implemented)")
                    
                    return audio
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Stereo processing failed: {e}, using original")
                    return audio
            
            else:
                # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç
                self.logger.warning(f"‚ö†Ô∏è Unknown effect: {effect}, skipping")
                return audio
                
        except Exception as e:
            self.logger.error(f"‚ùå Critical error in effect {effect}: {e}")
            return audio
    
    async def _final_verification_pass(self, audio: AudioSegment, target: MasteringTarget) -> AudioSegment:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞
        """
        
        # –í–•–û–î–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø
        if audio is None:
            raise ValueError("‚ùå CRITICAL: Audio is None in final verification!")
        
        if audio.max_dBFS == float('-inf'):
            raise ValueError("‚ùå CRITICAL: Audio is silent in final verification!")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        try:
            final_analysis = await self._analyze_source_material(audio)
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Final analysis failed: {e}, skipping verification")
            return audio  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è
        
        corrections_needed = []
        corrected = audio
        
        # === –ü–†–û–í–ï–†–ö–ê –ò –ö–û–†–†–ï–ö–¶–ò–Ø LUFS ===
        lufs_error = abs(final_analysis["lufs"] - target.lufs)
        if lufs_error > 2.0:  # –ü–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –±–æ–ª—å—à–µ 2 LU
            lufs_correction = target.lufs - final_analysis["lufs"]
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
            lufs_correction = max(-8, min(8, lufs_correction))
            
            try:
                test_corrected = corrected + lufs_correction
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏–ª–∞ –∑–≤—É–∫
                if test_corrected.max_dBFS != float('-inf'):
                    corrected = test_corrected
                    self.logger.info(f"  üìä LUFS correction: {lufs_correction:+.1f}dB")
                else:
                    self.logger.warning("‚ö†Ô∏è LUFS correction would make audio silent, skipping")
                    
            except Exception as e:
                self.logger.error(f"‚ùå LUFS correction failed: {e}")
        
        # === –ü–†–û–í–ï–†–ö–ê –ò –ö–û–†–†–ï–ö–¶–ò–Ø –ü–ò–ö–û–í ===
        if final_analysis["peak"] > target.peak_ceiling:
            over_ceiling = final_analysis["peak"] - target.peak_ceiling
            
            try:
                # –ú—è–≥–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∏–∫–æ–≤
                reduction = over_ceiling + 0.2  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
                test_corrected = corrected - reduction
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if test_corrected.max_dBFS != float('-inf'):
                    corrected = test_corrected
                    self.logger.info(f"  üöß Peak correction: -{reduction:.1f}dB")
                else:
                    self.logger.warning("‚ö†Ô∏è Peak correction would make audio silent, skipping")
                    
            except Exception as e:
                self.logger.error(f"‚ùå Peak correction failed: {e}")
        
        # === –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê ===
        if corrected.max_dBFS == float('-inf'):
            self.logger.warning("‚ö†Ô∏è Final verification resulted in silence, returning original")
            return audio
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –Ω–µ —Å–æ–∑–¥–∞–ª–∏ –∫–ª–∏–ø–ø–∏–Ω–≥
        if corrected.max_dBFS > 0:
            self.logger.warning("‚ö†Ô∏è Final result has clipping, applying soft limiting")
            try:
                corrected = effects.normalize(corrected, headroom=1.0)
            except Exception as e:
                self.logger.error(f"‚ùå Final normalization failed: {e}")
                return audio
        
        return corrected
    
    def _create_mastering_report(
        self, plan: Dict, source_analysis: Dict, target: MasteringTarget
    ) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞ –æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        
        report = {
            "wavedream_version": "2.0.0",
            "mastering_timestamp": time.time(),
            "applied_stages": plan["stages"],
            "parameters": plan["parameters"],
            "source_characteristics": {
                "lufs": source_analysis["lufs"],
                "peak": source_analysis["peak"],
                "dynamic_range": source_analysis["dynamic_range"],
                "stereo_width": source_analysis.get("stereo_width", 0.5),
                "duration": source_analysis["duration"],
                "frequency_balance": source_analysis.get("frequency_balance", {})
            },
            "target_characteristics": {
                "lufs": target.lufs,
                "peak_ceiling": target.peak_ceiling,
                "dynamic_range": target.dynamic_range,
                "stereo_width": target.stereo_width,
                "frequency_balance": target.frequency_balance
            },
            "processing_stats": {
                "intensity": plan["genre_specific"]["processing_intensity"],
                "genre": plan["genre_specific"]["genre"],
                "transient_preservation": plan["genre_specific"]["preserve_transients"]
            },
            "quality_metrics": {
                "mastering_success": True,  # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
                "processing_stages": len(plan["stages"]),
                "character": f"WaveDream 2.0 mastered for {target.lufs} LUFS with {target.dynamic_range} LU dynamics"
            }
        }
        
        return report
