import logging
import numpy as np
import asyncio
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import json
from pathlib import Path
import io

# –ê—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
from pydub import AudioSegment, effects
import librosa
import soundfile as sf

from config import config, MasteringPurpose
from sample_engine import EffectsChain


@dataclass
class MasteringTarget:
    """–¶–µ–ª–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞"""
    lufs: float                    # –¶–µ–ª–µ–≤–∞—è –≥—Ä–æ–º–∫–æ—Å—Ç—å
    peak_ceiling: float           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–∏–∫
    dynamic_range: float          # –ñ–µ–ª–∞–µ–º—ã–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
    stereo_width: float          # –°—Ç–µ—Ä–µ–æ —à–∏—Ä–∏–Ω–∞ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
    frequency_balance: Dict      # –ë–∞–ª–∞–Ω—Å —á–∞—Å—Ç–æ—Ç
    harmonic_content: float      # –ñ–µ–ª–∞–µ–º–æ–µ –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
    transient_preservation: float # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤


class SmartMasteringEngine:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —É–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π –ø–æ–¥ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ –∂–∞–Ω—Ä
    
    –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - –£–±—Ä–∞–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ —Å —Ç–∏—à–∏–Ω–æ–π –≤ _load_audio_from_bytes
    - –£–ª—É—á—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∞—É–¥–∏–æ
    - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ fallback'–æ–≤
    - –î–æ–±–∞–≤–ª–µ–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.effects_chain = EffectsChain()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
        self._init_analyzers()
        
        # –ö—ç—à –∞–Ω–∞–ª–∏–∑–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
        self.analysis_cache = {}
    
    def _init_analyzers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤ –∞—É–¥–∏–æ"""
        self.logger.info("üéõÔ∏è Initializing mastering analyzers...")
    
    def _load_audio_from_bytes(self, audio_bytes: bytes) -> AudioSegment:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –∑–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ –∏–∑ bytes - –ë–ï–ó –ó–ê–ì–õ–£–®–ï–ö –° –¢–ò–®–ò–ù–û–ô!
        
        Args:
            audio_bytes: –ê—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ bytes
            
        Returns:
            AudioSegment –æ–±—ä–µ–∫—Ç –∏–ª–∏ –≤—ã–∑—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
        """
        if not audio_bytes or len(audio_bytes) == 0:
            raise ValueError("‚ùå CRITICAL: Empty audio bytes provided!")
        
        try:
            # –°–æ–∑–¥–∞—ë–º BytesIO –æ–±—ä–µ–∫—Ç –∏–∑ bytes
            audio_io = io.BytesIO(audio_bytes)
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            formats_to_try = ['wav', 'mp3', 'flac', 'ogg', 'm4a', 'aiff']
            
            last_error = None
            
            for fmt in formats_to_try:
                try:
                    audio_io.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –Ω–∞—á–∞–ª—É
                    audio = AudioSegment.from_file(audio_io, format=fmt)
                    
                    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∞—É–¥–∏–æ –Ω–µ –ø—É—Å—Ç–æ–µ
                    if len(audio) == 0:
                        self.logger.warning(f"‚ö†Ô∏è Audio loaded as {fmt} but is empty (0 duration)")
                        continue
                    
                    if audio.max_dBFS == float('-inf'):
                        self.logger.warning(f"‚ö†Ô∏è Audio loaded as {fmt} but is silent (max_dBFS = -inf)")
                        continue
                    
                    self.logger.info(f"‚úÖ Successfully loaded audio as {fmt}: "
                                   f"{len(audio)/1000:.1f}s, {audio.channels}ch, {audio.frame_rate}Hz, "
                                   f"peak: {audio.max_dBFS:.1f}dB")
                    return audio
                    
                except Exception as e:
                    last_error = e
                    self.logger.debug(f"Failed to load as {fmt}: {e}")
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω —Ñ–æ—Ä–º–∞—Ç –Ω–µ –ø–æ–¥–æ—à—ë–ª, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
            try:
                audio_io.seek(0)
                audio = AudioSegment.from_file(audio_io)
                
                # –û–ø—è—Ç—å –∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞—É–¥–∏–æ –Ω–µ –ø—É—Å—Ç–æ–µ
                if len(audio) == 0 or audio.max_dBFS == float('-inf'):
                    raise ValueError("Loaded audio is empty or silent")
                
                self.logger.info(f"‚úÖ Successfully loaded audio (auto-detect): "
                               f"{len(audio)/1000:.1f}s, {audio.channels}ch, {audio.frame_rate}Hz")
                return audio
                
            except Exception as e:
                last_error = e
                self.logger.error(f"‚ùå Auto-detect also failed: {e}")
            
            # –£–ë–†–ê–ù–û: –í–æ–∑–≤—Ä–∞—Ç —Ç–∏—à–∏–Ω—ã –∫–∞–∫ fallback
            # –¢–µ–ø–µ—Ä—å –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ —Ç–∏—à–∏–Ω—ã
            raise ValueError(f"‚ùå CRITICAL: Cannot load audio from bytes! Last error: {last_error}")
            
        except Exception as e:
            self.logger.error(f"‚ùå CRITICAL: Failed to load audio from bytes: {e}")
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –≤–º–µ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∑–∞–≥–ª—É—à–∫–∏
    
    async def master_track(
        self,
        audio: bytes,
        target_config: Dict,
        genre_info: Dict,
        purpose: str
    ) -> Tuple[AudioSegment, Dict]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ —Ç—Ä–µ–∫–∞
        """
        self.logger.info(f"üéõÔ∏è Starting smart mastering: {purpose}")

        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            source_audio = None
            
            if isinstance(audio, bytes):
                if len(audio) == 0:
                    raise ValueError("‚ùå CRITICAL: Empty bytes provided to master_track!")
                source_audio = self._load_audio_from_bytes(audio)
                
            elif hasattr(audio, 'export'):  # AudioSegment
                source_audio = audio
                
            elif hasattr(audio, 'read'):  # file-like object
                buffer = io.BytesIO()
                audio.export(buffer, format="wav")
                buffer.seek(0)
                source_audio = self._load_audio_from_bytes(buffer.getvalue())
                
            else:
                raise TypeError(f"‚ùå CRITICAL: Unsupported audio type: {type(audio)}")

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ source_audio –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–≤—É–∫
            if source_audio is None:
                raise ValueError("‚ùå CRITICAL: source_audio is None after conversion!")
            
            if len(source_audio) < 100:  # –ú–∏–Ω–∏–º—É–º 100–º—Å
                raise ValueError(f"‚ùå CRITICAL: Audio too short: {len(source_audio)}ms")
            
            if source_audio.max_dBFS == float('-inf'):
                raise ValueError("‚ùå CRITICAL: Source audio is completely silent!")

            # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
            source_analysis = await self._analyze_source_material(source_audio)
            self.logger.info(
                f"  üìä Source analysis: LUFS {source_analysis['lufs']:.1f}, "
                f"peak {source_analysis['peak']:.1f}dB, "
                f"duration {source_analysis['duration']:.1f}s"
            )

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–π –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞
            mastering_target = self._create_mastering_target(target_config, genre_info, source_analysis)
            
            # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            processing_plan = await self._plan_mastering_chain(source_analysis, mastering_target, genre_info)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            mastered_audio = await self._apply_mastering_chain(source_audio, processing_plan)
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ mastered_audio –Ω–µ —Å—Ç–∞–ª —Ç–∏—à–∏–Ω–æ–π
            if mastered_audio.max_dBFS == float('-inf'):
                self.logger.warning("‚ö†Ô∏è Mastering resulted in silence, using original audio!")
                mastered_audio = source_audio
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
            mastered_audio = await self._final_verification_pass(mastered_audio, mastering_target)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞
            applied_config = self._create_mastering_report(processing_plan, source_analysis, mastering_target)

            # –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            result_analysis = await self._analyze_source_material(mastered_audio)
            self.logger.info(
                f"  ‚úÖ Mastered: LUFS {result_analysis['lufs']:.1f}, "
                f"peak {result_analysis['peak']:.1f}dB, "
                f"dynamics {result_analysis['dynamic_range']:.1f}LU, "
                f"duration {result_analysis['duration']:.1f}s"
            )

            return mastered_audio, applied_config

        except Exception as e:
            self.logger.error(f"‚ùå CRITICAL Mastering error: {e}")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–ª—É—á—à–µ–Ω–Ω—ã–π fallback –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –≤–µ—Ä–Ω—É—Ç—å —Ö–æ—Ç—è –±—ã –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ, –∞ –Ω–µ —Ç–∏—à–∏–Ω—É
                if isinstance(audio, (bytes, bytearray)) and len(audio) > 0:
                    fallback_audio = self._load_audio_from_bytes(bytes(audio))
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ fallback –Ω–µ —Ç–∏—à–∏–Ω–∞
                    if fallback_audio.max_dBFS != float('-inf'):
                        self.logger.warning("üö® Returning normalized original audio as fallback")
                        return effects.normalize(fallback_audio), target_config
                    
                elif isinstance(audio, AudioSegment):
                    if audio.max_dBFS != float('-inf'):
                        self.logger.warning("üö® Returning normalized original AudioSegment as fallback")
                        return effects.normalize(audio), target_config
                
                # –ï—Å–ª–∏ –¥–∞–∂–µ –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ –ø—Ä–æ–±–ª–µ–º–Ω–æ–µ - –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                raise ValueError("‚ùå FATAL: Cannot recover any audio, original is also corrupted!")
                
            except Exception as inner_err:
                self.logger.error(f"‚ùå FATAL: Fallback also failed: {inner_err}")
                # –¢–û–õ–¨–ö–û –í –ö–†–ê–ô–ù–ï–ú –°–õ–£–ß–ê–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É, –∞ –Ω–µ —Ç–∏—à–∏–Ω—É
                raise ValueError(f"‚ùå FATAL: Complete mastering failure: {e}, fallback: {inner_err}")
  
    async def _analyze_source_material(self, audio: AudioSegment) -> Dict:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞"""
        try:
            # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ
            if audio is None:
                raise ValueError("Audio is None in analysis")
            
            if len(audio) == 0:
                raise ValueError("Audio has zero duration in analysis")
            
            if audio.max_dBFS == float('-inf'):
                raise ValueError("Audio is completely silent in analysis")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
            if audio.channels == 2:
                samples = samples.reshape((-1, 2))
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            max_val = 2**(audio.sample_width * 8 - 1)
            samples = samples / max_val
            
            sample_rate = audio.frame_rate
            
            analysis = {}
            
            # –ë–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            analysis['peak'] = audio.max_dBFS
            analysis['rms'] = audio.rms
            analysis['duration'] = len(audio) / 1000.0
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π LUFS –∞–Ω–∞–ª–∏–∑
            if audio.rms > 0:
                # –ü—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—ã–π LUFS —á–µ—Ä–µ–∑ RMS
                rms_db = 20 * np.log10(audio.rms / audio.max_possible_amplitude)
                analysis['lufs'] = max(-70, rms_db - 23)  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ LUFS
            else:
                analysis['lufs'] = -70
            
            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω
            if audio.rms > 0:
                rms_db = 20 * np.log10(audio.rms / audio.max_possible_amplitude)
                analysis['dynamic_range'] = abs(analysis['peak'] - rms_db)
            else:
                analysis['dynamic_range'] = 0
            
            # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
            mono_samples = samples.mean(axis=1) if audio.channels == 2 else samples
            
            if len(mono_samples) > 0:
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                try:
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    if len(mono_samples) > sample_rate * 30:  # –ú–∞–∫—Å–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                        mono_samples = mono_samples[:sample_rate * 30]
                    
                    spectral_centroid = librosa.feature.spectral_centroid(y=mono_samples, sr=sample_rate)
                    analysis['spectral_centroid'] = float(np.mean(spectral_centroid))
                    
                    spectral_rolloff = librosa.feature.spectral_rolloff(y=mono_samples, sr=sample_rate)
                    analysis['spectral_rolloff'] = float(np.mean(spectral_rolloff))
                except Exception as e:
                    self.logger.debug(f"Spectral analysis failed: {e}")
                    analysis['spectral_centroid'] = 2000.0
                    analysis['spectral_rolloff'] = 8000.0
                
                # –°—Ç–µ—Ä–µ–æ –∞–Ω–∞–ª–∏–∑
                if audio.channels == 2 and len(samples) > 0:
                    try:
                        correlation = np.corrcoef(samples[:, 0], samples[:, 1])[0, 1]
                        if np.isnan(correlation) or np.isinf(correlation):
                            correlation = 1.0
                        analysis['stereo_correlation'] = float(correlation)
                        analysis['stereo_width'] = max(0.0, 1.0 - abs(correlation))
                    except Exception as e:
                        self.logger.debug(f"Stereo analysis failed: {e}")
                        analysis['stereo_correlation'] = 1.0
                        analysis['stereo_width'] = 0.0
                else:
                    analysis['stereo_correlation'] = 1.0
                    analysis['stereo_width'] = 0.0
                
                # –ß–∞—Å—Ç–æ—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (—É–ø—Ä–æ—â—ë–Ω–Ω–æ–µ)
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Å—ç–º–ø–ª –¥–ª—è FFT
                    fft_samples = mono_samples[:min(len(mono_samples), sample_rate * 10)]  # –ú–∞–∫—Å–∏–º—É–º 10 —Å–µ–∫
                    fft = np.fft.rfft(fft_samples)
                    freqs = np.fft.rfftfreq(len(fft_samples), 1/sample_rate)
                    magnitude = np.abs(fft)
                    
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–æ–ª–æ—Å—ã
                    low_mask = freqs < 300
                    mid_mask = (freqs >= 300) & (freqs < 3000) 
                    high_mask = freqs >= 3000
                    
                    total_energy = np.sum(magnitude**2) + 1e-10  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
                    
                    analysis['frequency_balance'] = {
                        'low': float(np.sum(magnitude[low_mask]**2) / total_energy),
                        'mid': float(np.sum(magnitude[mid_mask]**2) / total_energy), 
                        'high': float(np.sum(magnitude[high_mask]**2) / total_energy)
                    }
                except Exception as e:
                    self.logger.debug(f"Frequency analysis failed: {e}")
                    analysis['frequency_balance'] = {'low': 0.33, 'mid': 0.33, 'high': 0.34}
                
                # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã —Å fallback –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                analysis.update({
                    'transient_density': 5.0,
                    'harmonic_ratio': 0.5,
                    'percussive_ratio': 0.5
                })
            else:
                # Fallback –∑–Ω–∞—á–µ–Ω–∏—è –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
                analysis.update({
                    'spectral_centroid': 2000.0,
                    'spectral_rolloff': 8000.0,
                    'stereo_correlation': 1.0,
                    'stereo_width': 0.0,
                    'frequency_balance': {'low': 0.33, 'mid': 0.33, 'high': 0.34},
                    'transient_density': 5.0,
                    'harmonic_ratio': 0.5,
                    'percussive_ratio': 0.5
                })
            
            # –î–û–ë–ê–í–õ–ï–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞
            if analysis['peak'] == float('-inf') or analysis['rms'] == 0:
                raise ValueError("Analysis detected completely silent audio")
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå CRITICAL: Source analysis error: {e}")
            # –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º fallback –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∏—à–∏–Ω—ã!
            raise ValueError(f"Source analysis failed - audio may be corrupted: {e}")
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def _create_mastering_target(self, target_config: Dict, genre_info: Dict, source_analysis: Dict) -> MasteringTarget:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞"""
        
        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        target = MasteringTarget(
            lufs=target_config.get("target_lufs", -14),
            peak_ceiling=target_config.get("peak_ceiling", -1),
            dynamic_range=target_config.get("dynamic_range", 8),
            stereo_width=target_config.get("stereo_enhancement", 1.0),
            frequency_balance={},
            harmonic_content=target_config.get("harmonic_saturation", 0.2),
            transient_preservation=0.8  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤
        )
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∂–∞–Ω—Ä
        genre = genre_info.get("name", "").lower()
        genre_adaptations = {
            "trap": {
                "frequency_balance": {"low": 0.4, "mid": 0.35, "high": 0.25},
                "stereo_width": 1.2,
                "transient_preservation": 0.9  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–∞—Ä—ã
            },
            "lofi": {
                "frequency_balance": {"low": 0.35, "mid": 0.45, "high": 0.2},
                "stereo_width": 0.8,  # –ë–æ–ª–µ–µ —É–∑–∫–∏–π —Å—Ç–µ—Ä–µ–æ
                "transient_preservation": 0.6  # –ë–æ–ª–µ–µ –º—è–≥–∫–æ
            },
            "dnb": {
                "frequency_balance": {"low": 0.3, "mid": 0.4, "high": 0.3},
                "stereo_width": 1.1,
                "transient_preservation": 0.95  # –ú–∞–∫—Å–∏–º—É–º —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤
            },
            "drum and bass": {
                "frequency_balance": {"low": 0.3, "mid": 0.4, "high": 0.3},
                "stereo_width": 1.1,
                "transient_preservation": 0.95
            },
            "ambient": {
                "frequency_balance": {"low": 0.25, "mid": 0.45, "high": 0.3},
                "stereo_width": 1.5,  # –®–∏—Ä–æ–∫–∏–π —Å—Ç–µ—Ä–µ–æ
                "transient_preservation": 0.5  # –ú—è–≥–∫–æ—Å—Ç—å
            },
            "techno": {
                "frequency_balance": {"low": 0.35, "mid": 0.4, "high": 0.25},
                "stereo_width": 1.0,
                "transient_preservation": 0.85
            },
            "house": {
                "frequency_balance": {"low": 0.35, "mid": 0.4, "high": 0.25},
                "stereo_width": 1.1,
                "transient_preservation": 0.8
            }
        }
        
        if genre in genre_adaptations:
            adaptations = genre_adaptations[genre]
            target.frequency_balance = adaptations["frequency_balance"]
            target.stereo_width = adaptations["stereo_width"]
            target.transient_preservation = adaptations["transient_preservation"]
        else:
            # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –±–∞–ª–∞–Ω—Å
            target.frequency_balance = {"low": 0.33, "mid": 0.34, "high": 0.33}
        
        return target
    
    async def _plan_mastering_chain(
        self, source_analysis: Dict, target: MasteringTarget, genre_info: Dict
    ) -> Dict:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        
        plan = {
            "stages": [],
            "parameters": {},
            "genre_specific": {}
        }
        
        # 1. –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ—Ä—Ä–µ–∫—Ü–∏–π
        lufs_diff = target.lufs - source_analysis["lufs"]
        peak_diff = target.peak_ceiling - source_analysis["peak"]
        
        # 2. EQ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        source_balance = source_analysis.get("frequency_balance", {"low": 0.33, "mid": 0.33, "high": 0.34})
        target_balance = target.frequency_balance
        
        eq_corrections = {}
        for band in ["low", "mid", "high"]:
            source_level = source_balance.get(band, 0.33)
            target_level = target_balance.get(band, 0.33)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dB –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ)
            if target_level > source_level:
                correction = min(6, (target_level - source_level) * 20)
            else:
                correction = max(-6, (target_level - source_level) * 20)
            
            eq_corrections[band] = correction
        
        if any(abs(c) > 0.5 for c in eq_corrections.values()):
            plan["stages"].append("eq")
            plan["parameters"]["eq"] = eq_corrections
        
        # 3. –ö–æ–º–ø—Ä–µ—Å—Å–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        source_dr = source_analysis.get("dynamic_range", 10)
        target_dr = target.dynamic_range
        
        if source_dr > target_dr + 2:  # –ù—É–∂–Ω–∞ –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
            compression_ratio = min(8.0, 1 + (source_dr - target_dr) / 5)
            threshold = source_analysis["peak"] - (source_dr * 0.7)
            
            plan["stages"].append("compressor")
            plan["parameters"]["compressor"] = {
                "ratio": compression_ratio,
                "threshold": threshold,
                "attack": 10,  # ms
                "release": 100  # ms
            }
        
        # 4. –ù–∞—Å—ã—â–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        if target.harmonic_content > 0.1:
            genre = genre_info.get("name", "").lower()
            saturation_types = {
                "lofi": "tape",
                "trap": "tube", 
                "techno": "transistor",
                "ambient": "tube",
                "house": "tube"
            }
            
            plan["stages"].append("saturation")
            plan["parameters"]["saturation"] = {
                "amount": target.harmonic_content,
                "type": saturation_types.get(genre, "tube"),
                "warmth": target.harmonic_content * 1.5
            }
        
        # 5. –°—Ç–µ—Ä–µ–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        source_width = source_analysis.get("stereo_width", 0.5)
        if abs(target.stereo_width - source_width) > 0.1:
            plan["stages"].append("stereo")
            plan["parameters"]["stereo"] = {
                "width": target.stereo_width,
                "imaging": "enhanced" if target.stereo_width > 1.0 else "natural"
            }
        
        # 6. –†–µ–≤–µ—Ä–± (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –∂–∞–Ω—Ä–∞)
        genre = genre_info.get("name", "").lower()
        if genre in ["ambient", "cinematic"]:
            plan["stages"].append("reverb")
            reverb_settings = {
                "ambient": {"room_size": 0.7, "wet_level": 0.25, "type": "hall"},
                "cinematic": {"room_size": 0.6, "wet_level": 0.2, "type": "cinematic_hall"}
            }
            plan["parameters"]["reverb"] = reverb_settings.get(genre, {"room_size": 0.3, "wet_level": 0.15})
        
        # 7. –õ–∏–º–∏—Ç–µ—Ä (–≤—Å–µ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π)
        plan["stages"].append("limiter")
        plan["parameters"]["limiter"] = {
            "threshold": target.peak_ceiling + 1,  # –ù–µ–º–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞
            "ceiling": target.peak_ceiling,
            "release": 50  # ms
        }
        
        # 8. –ñ–∞–Ω—Ä–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        plan["genre_specific"] = {
            "preserve_transients": target.transient_preservation,
            "target_loudness": target.lufs,
            "processing_intensity": min(1.0, abs(lufs_diff) / 10)  # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
        }
        
        self.logger.info(f"  üìã Processing plan: {len(plan['stages'])} stages - {', '.join(plan['stages'])}")
        
        return plan
    
    async def _apply_mastering_chain(self, audio: AudioSegment, plan: Dict) -> AudioSegment:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        processed = audio
        
        # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ
        if processed.max_dBFS == float('-inf'):
            self.logger.error("‚ùå CRITICAL: Input audio to mastering chain is silent!")
            return processed
        
        for stage in plan["stages"]:
            if stage in plan["parameters"]:
                params = plan["parameters"][stage]
                
                self.logger.debug(f"  üîß Applying {stage}: {params}")
                
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                    pre_peak = processed.max_dBFS
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —ç—Ç–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞
                    if hasattr(self.effects_chain, 'processors') and stage in self.effects_chain.processors:
                        processed = await self.effects_chain.processors[stage].process(processed, params)
                    else:
                        # Fallback –¥–ª—è –±–∞–∑–æ–≤—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
                        processed = await self._apply_basic_effect(processed, stage, params)
                    
                    # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ñ—Ñ–µ–∫—Ç –Ω–µ —É–±–∏–ª –∑–≤—É–∫
                    post_peak = processed.max_dBFS
                    if post_peak == float('-inf') and pre_peak != float('-inf'):
                        self.logger.error(f"‚ùå Effect {stage} made audio silent! Reverting...")
                        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
                        processed = audio if stage == plan["stages"][0] else processed  # –≠—Ç–æ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å
                        
                except Exception as e:
                    self.logger.error(f"‚ùå Error in {stage}: {e}")
                    # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–µ–ø–æ—á–∫—É, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º
        
        return processed
    
    async def _apply_basic_effect(self, audio: AudioSegment, effect: str, params: Dict) -> AudioSegment:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –±–∞–∑–æ–≤—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã –∫–∞–∫ fallback"""
        try:
            # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ
            if audio.max_dBFS == float('-inf'):
                self.logger.warning(f"‚ö†Ô∏è Skipping {effect} - audio is silent")
                return audio
            
            if effect == "limiter":
                # –ü—Ä–æ—Å—Ç–æ–π –ª–∏–º–∏—Ç–µ—Ä —á–µ—Ä–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
                ceiling = params.get("ceiling", -1)
                if audio.max_dBFS > ceiling:
                    reduction = audio.max_dBFS - ceiling
                    result = audio - reduction
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if result.max_dBFS == float('-inf'):
                        self.logger.warning(f"‚ö†Ô∏è Limiter made audio silent, using original")
                        return audio
                    
                    return result
                return audio
            
            elif effect == "compressor":
                # –ë–∞–∑–æ–≤–æ–µ —Å–∂–∞—Ç–∏–µ —á–µ—Ä–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –¥–∏–Ω–∞–º–∏–∫–∏
                try:
                    result = effects.compress_dynamic_range(audio, threshold=params.get("threshold", -20))
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if result.max_dBFS == float('-inf'):
                        self.logger.warning(f"‚ö†Ô∏è Compressor made audio silent, using original")
                        return audio
                    
                    return result
                except Exception:
                    return audio
            
            elif effect == "eq":
                # –ë–∞–∑–æ–≤—ã–π EQ —á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä—ã (–ø–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å)
                return audio
            
            else:
                return audio
                
        except Exception as e:
            self.logger.error(f"Error in basic {effect}: {e}")
            return audio
    
    async def _final_verification_pass(self, audio: AudioSegment, target: MasteringTarget) -> AudioSegment:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è"""
        
        # –î–û–ë–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ audio –Ω–µ None –∏ –Ω–µ —Ç–∏—à–∏–Ω–∞
        if audio is None:
            raise ValueError("‚ùå CRITICAL: Audio is None in final verification!")
        
        if audio.max_dBFS == float('-inf'):
            raise ValueError("‚ùå CRITICAL: Audio is silent in final verification!")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        try:
            final_analysis = await self._analyze_source_material(audio)
        except Exception as e:
            self.logger.error(f"‚ùå Final analysis failed: {e}")
            # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—É–¥–∏–æ –∫–∞–∫ –µ—Å—Ç—å
            return audio
        
        corrections_needed = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º LUFS
        lufs_error = abs(final_analysis["lufs"] - target.lufs)
        if lufs_error > 1.0:  # –ë–æ–ª—å—à–µ 1 LU –æ—à–∏–±–∫–∏
            corrections_needed.append("loudness")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∏–∫–∏
        if final_analysis["peak"] > target.peak_ceiling:
            corrections_needed.append("peaks")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        corrected = audio
        
        if "peaks" in corrections_needed:
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            try:
                over_ceiling = final_analysis["peak"] - target.peak_ceiling
                test_corrected = corrected - (over_ceiling + 0.1)  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–µ —É–±–∏–ª–∞ –∑–≤—É–∫
                if test_corrected.max_dBFS != float('-inf'):
                    corrected = test_corrected
                    self.logger.info(f"  üöß Final peak correction: -{over_ceiling + 0.1:.1f}dB")
                else:
                    self.logger.warning("‚ö†Ô∏è Peak correction would make audio silent, skipping")
                    
            except Exception as e:
                self.logger.error(f"‚ùå Peak correction failed: {e}")
        
        if "loudness" in corrections_needed:
            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            try:
                lufs_correction = target.lufs - final_analysis["lufs"]
                if abs(lufs_correction) < 6:  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç
                    test_corrected = corrected + lufs_correction
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
                    if test_corrected.max_dBFS != float('-inf'):
                        corrected = test_corrected
                        self.logger.info(f"  üìä Final loudness correction: {lufs_correction:+.1f}dB")
                    else:
                        self.logger.warning("‚ö†Ô∏è Loudness correction would make audio silent, skipping")
                        
            except Exception as e:
                self.logger.error(f"‚ùå Loudness correction failed: {e}")
        
        # –î–û–ë–ê–í–õ–ï–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if corrected.max_dBFS == float('-inf'):
            self.logger.warning("‚ö†Ô∏è Final verification resulted in silence, returning original")
            return audio
        
        return corrected
    
    def _create_mastering_report(
        self, plan: Dict, source_analysis: Dict, target: MasteringTarget
    ) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ –æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        
        report = {
            "applied_stages": plan["stages"],
            "parameters": plan["parameters"],
            "source_characteristics": {
                "lufs": source_analysis["lufs"],
                "peak": source_analysis["peak"],
                "dynamic_range": source_analysis["dynamic_range"],
                "stereo_width": source_analysis.get("stereo_width", 0.5),
                "duration": source_analysis["duration"]
            },
            "target_characteristics": {
                "lufs": target.lufs,
                "peak_ceiling": target.peak_ceiling,
                "dynamic_range": target.dynamic_range,
                "stereo_width": target.stereo_width
            },
            "processing_intensity": plan["genre_specific"]["processing_intensity"],
            "character": f"mastered for {target.lufs} LUFS with {target.dynamic_range} LU dynamics"
        }
        
        return report