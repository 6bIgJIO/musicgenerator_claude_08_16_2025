# metadata.py - –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–º–ø—Ç–æ–≤

import re
import logging
from typing import Dict, List, Optional, Tuple, Any
import json

from config import config, GenreType


class MetadataProcessor:
    """
    –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–º–ø—Ç–æ–≤
    
    –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:
    - –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤
    - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (BPM, —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ)
    - –î–µ—Ç–µ–∫—Ü–∏—è –∂–∞–Ω—Ä–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    - –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –ø–æ–¥—Å–∫–∞–∑–æ–∫
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.regex_patterns = {
            'bpm': re.compile(r'(\d{2,3})\s*(?:bpm|beats?|tempo)', re.IGNORECASE),
            'key': re.compile(r'\b([A-G][#b]?)\s*(?:maj|min|major|minor)?\b', re.IGNORECASE),
            'duration': re.compile(r'(\d+)\s*(?:min|minutes?|sec|seconds?)', re.IGNORECASE),
            'energy': re.compile(r'\b(high|low|medium|intense|calm|aggressive|peaceful)\s*energy\b', re.IGNORECASE)
        }
        
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.mood_keywords = {
            'dark': ['dark', 'evil', 'sinister', 'goth', 'horror', 'mysterious', 'shadow'],
            'bright': ['bright', 'happy', 'joyful', 'uplifting', 'cheerful', 'sunny', 'positive'],
            'aggressive': ['aggressive', 'hard', 'intense', 'brutal', 'heavy', 'powerful', 'strong'],
            'calm': ['calm', 'peaceful', 'soft', 'gentle', 'relaxing', 'chill', 'smooth'],
            'energetic': ['energetic', 'driving', 'pumping', 'dynamic', 'active', 'bouncy'],
            'melancholic': ['sad', 'melancholic', 'emotional', 'nostalgic', 'wistful', 'longing'],
            'ethereal': ['ethereal', 'ambient', 'spacious', 'floating', 'dreamy', 'atmospheric'],
            'vintage': ['vintage', 'retro', 'old-school', 'classic', 'nostalgic', 'analog']
        }
        
        self.instrument_aliases = {
            'drums': ['drums', 'percussion', 'kit', 'beats'],
            'bass': ['bass', 'sub', '808', 'low-end', 'bottom'],
            'synth': ['synth', 'synthesizer', 'keys', 'keyboard', 'lead'],
            'guitar': ['guitar', 'gtr', 'strings', 'riff'],
            'vocal': ['vocal', 'voice', 'singing', 'rap', 'lyrics'],
            'piano': ['piano', 'keys', 'ivories'],
            'strings': ['strings', 'orchestra', 'violin', 'cello'],
            'brass': ['brass', 'trumpet', 'horn', 'trombone']
        }
        
        # –ñ–∞–Ω—Ä–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–∑ config
        self.genre_keywords = {}
        for genre_enum in GenreType:
            genre = genre_enum.value
            if genre in config.GENRE_CONFIGS:
                genre_config = config.GENRE_CONFIGS[genre] 
                self.genre_keywords[genre] = getattr(genre_config, 'default_tags', [])
    
    def analyze_prompt(self, prompt: str) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        
        Args:
            prompt: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        self.logger.info(f"üìù Analyzing prompt: '{prompt[:50]}...'")
        
        analysis = {
            'original_prompt': prompt,
            'cleaned_prompt': self._clean_prompt(prompt),
            'language': self._detect_language(prompt),
            'length': len(prompt),
            'word_count': len(prompt.split())
        }
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        analysis.update(self.extract_parameters(prompt))
        analysis.update(self._extract_mood_descriptors(prompt))
        analysis.update(self._extract_structure_hints(prompt))
        analysis.update(self._extract_production_hints(prompt))
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–º–ø—Ç–∞
        analysis['complexity_score'] = self._calculate_prompt_complexity(analysis)
        
        self.logger.info(f"  üìä Extracted: {len(analysis)} metadata fields")
        
        return analysis
    
    def extract_parameters(self, prompt: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        prompt_lower = prompt.lower()
        extracted = {}
        
        # BPM –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
        bpm_match = self.regex_patterns['bpm'].search(prompt)
        if bpm_match:
            bpm = int(bpm_match.group(1))
            if 60 <= bpm <= 200:  # –í–∞–ª–∏–¥–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                extracted['bpm'] = bpm
        
        # –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        key_match = self.regex_patterns['key'].search(prompt)
        if key_match:
            key = key_match.group(1).upper()
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–∞–∂–æ—Ä/–º–∏–Ω–æ—Ä –µ—Å–ª–∏ –µ—Å—Ç—å
            full_match = key_match.group(0).lower()
            if 'min' in full_match:
                key += 'm'
            elif 'maj' in full_match:
                key += 'M'
            extracted['key'] = key
        
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration_match = self.regex_patterns['duration'].search(prompt)
        if duration_match:
            duration_value = int(duration_match.group(1))
            duration_unit = duration_match.group(0).lower()
            
            if 'min' in duration_unit:
                extracted['duration'] = duration_value * 60
            else:
                extracted['duration'] = duration_value
        
        # –£—Ä–æ–≤–µ–Ω—å —ç–Ω–µ—Ä–≥–∏–∏
        energy_match = self.regex_patterns['energy'].search(prompt)
        if energy_match:
            energy_word = energy_match.group(1).lower()
            energy_mapping = {
                'low': 0.3, 'calm': 0.3, 'peaceful': 0.2,
                'medium': 0.5,
                'high': 0.8, 'intense': 0.9, 'aggressive': 0.9
            }
            extracted['energy_level'] = energy_mapping.get(energy_word, 0.5)
        
        # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        detected_instruments = []
        for instrument, aliases in self.instrument_aliases.items():
            for alias in aliases:
                if alias in prompt_lower:
                    detected_instruments.append(instrument)
                    break
        
        if detected_instruments:
            extracted['instruments'] = list(set(detected_instruments))
        
        # –¢–µ–≥–∏ –∏–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –∫–∞—Ä—Ç—ã
        detected_tags = []
        for tag, data in config.SEMANTIC_MAP.items():
            if isinstance(data, dict):
                synonyms = data.get('synonyms', [])
            else:
                synonyms = data if isinstance(data, list) else [data]
            
            for synonym in synonyms:
                if synonym.lower() in prompt_lower:
                    detected_tags.append(tag)
                    break
        
        if detected_tags:
            extracted['tags'] = list(set(detected_tags))
        
        return extracted
    
    def detect_genre(self, prompt: str, existing_tags: Optional[List[str]] = None) -> str:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –∂–∞–Ω—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞ –∏ —Ç–µ–≥–æ–≤
        
        Args:
            prompt: –¢–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞
            existing_tags: –£–∂–µ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —Ç–µ–≥–∏
            
        Returns:
            –ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∂–∞–Ω—Ä–∞
        """
        prompt_lower = prompt.lower()
        genre_scores = {}
        
        # 1. –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –∂–∞–Ω—Ä–æ–≤
        for genre in self.genre_keywords:
            if genre in prompt_lower:
                genre_scores[genre] = genre_scores.get(genre, 0) + 10
        
        # 2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for genre, keywords in self.genre_keywords.items():
            for keyword in keywords:
                if keyword.lower() in prompt_lower:
                    genre_scores[genre] = genre_scores.get(genre, 0) + 3
        
        # 3. –ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ–≥–æ–≤
        if existing_tags:
            for tag in existing_tags:
                tag_lower = tag.lower()
                for genre, keywords in self.genre_keywords.items():
                    if tag_lower in [k.lower() for k in keywords]:
                        genre_scores[genre] = genre_scores.get(genre, 0) + 5
        
        # 4. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        context_indicators = {
            'trap': ['urban', 'street', 'hip-hop', 'drill', 'memphis'],
            'lofi': ['study', 'chill', 'vintage', 'vinyl', 'cozy'],
            'dnb': ['jungle', 'breakbeat', 'neurofunk', 'liquid'],
            'ambient': ['meditation', 'space', 'atmospheric', 'zen'],
            'techno': ['warehouse', 'industrial', 'minimal', 'berlin'],
            'house': ['disco', 'dance', 'club', 'groove', 'funk']
        }
        
        for genre, indicators in context_indicators.items():
            for indicator in indicators:
                if indicator in prompt_lower:
                    genre_scores[genre] = genre_scores.get(genre, 0) + 2
        
        # –í—ã–±–∏—Ä–∞–µ–º –∂–∞–Ω—Ä —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —Å–∫–æ—Ä–æ–º
        if genre_scores:
            best_genre = max(genre_scores, key=genre_scores.get)
            confidence = genre_scores[best_genre]
            
            self.logger.info(f"  üé≠ Genre detected: {best_genre} (confidence: {confidence})")
            return best_genre
        
        # –§–æ–ª–±–µ–∫ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º trap –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
        self.logger.info("  üé≠ Genre detection fallback: trap")
        return "trap"
    
    def _clean_prompt(self, prompt: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–∞"""
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–∏–º–≤–æ–ª—ã
        cleaned = re.sub(r'\s+', ' ', prompt.strip())
        
        # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã, –ø—Ä–æ–±–µ–ª—ã –∏ –æ—Å–Ω–æ–≤–Ω—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
        cleaned = re.sub(r'[^\w\s\-.,!?#]', '', cleaned)
        
        return cleaned
    
    def _detect_language(self, prompt: str) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        if re.search(r'[–∞-—è—ë]', prompt.lower()):
            return 'ru'
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞
        elif re.search(r'\b(and|the|with|for|of|in|to|a|an)\b', prompt.lower()):
            return 'en'
        else:
            return 'unknown'
    
    def _extract_mood_descriptors(self, prompt: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è"""
        prompt_lower = prompt.lower()
        detected_moods = []
        mood_confidence = {}
        
        for mood, keywords in self.mood_keywords.items():
            matches = 0
            for keyword in keywords:
                if keyword in prompt_lower:
                    matches += 1
            
            if matches > 0:
                detected_moods.append(mood)
                mood_confidence[mood] = matches / len(keywords)
        
        result = {'mood': detected_moods}
        
        if mood_confidence:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
            dominant_mood = max(mood_confidence, key=mood_confidence.get)
            result['dominant_mood'] = dominant_mood
            result['mood_confidence'] = mood_confidence
        
        return result
    
    def _extract_structure_hints(self, prompt: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥—Å–∫–∞–∑–æ–∫ –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
        prompt_lower = prompt.lower()
        structure_hints = {}
        
        # –ü–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        structure_elements = {
            'intro': ['intro', 'introduction', 'start', 'beginning'],
            'verse': ['verse', 'vocal', 'rap'],
            'chorus': ['chorus', 'hook', 'refrain'],
            'bridge': ['bridge', 'breakdown', 'middle'],
            'outro': ['outro', 'end', 'ending', 'fade'],
            'drop': ['drop', 'climax', 'peak'],
            'build': ['build', 'tension', 'rising']
        }
        
        found_elements = []
        for element, keywords in structure_elements.items():
            for keyword in keywords:
                if keyword in prompt_lower:
                    found_elements.append(element)
                    break
        
        if found_elements:
            structure_hints['mentioned_sections'] = list(set(found_elements))
        
        # –ü–æ–∏—Å–∫ —É–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–∫—Ü–∏–π
        section_durations = re.findall(r'(\w+)\s+(?:for\s+)?(\d+)\s*(?:sec|bar|beat)', prompt_lower)
        if section_durations:
            structure_hints['section_durations'] = dict(section_durations)
        
        return structure_hints
    
    def _extract_production_hints(self, prompt: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ–¥—Å–∫–∞–∑–æ–∫ –æ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ"""
        prompt_lower = prompt.lower()
        production_hints = {}
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç—ã
        effects_keywords = {
            'reverb': ['reverb', 'echo', 'hall', 'space'],
            'delay': ['delay', 'echo', 'repeat'],
            'distortion': ['distortion', 'overdrive', 'saturated', 'dirty'],
            'compression': ['compressed', 'punchy', 'tight'],
            'filtering': ['filtered', 'muffled', 'bright', 'dark']
        }
        
        mentioned_effects = []
        for effect, keywords in effects_keywords.items():
            for keyword in keywords:
                if keyword in prompt_lower:
                    mentioned_effects.append(effect)
                    break
        
        if mentioned_effects:
            production_hints['suggested_effects'] = mentioned_effects
        
        # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        quality_keywords = {
            'professional': ['professional', 'studio', 'mastered', 'polished'],
            'lofi': ['lofi', 'vintage', 'analog', 'warm', 'tape'],
            'clean': ['clean', 'crisp', 'clear', 'pristine'],
            'raw': ['raw', 'unprocessed', 'live', 'organic']
        }
        
        quality_indicators = []
        for quality, keywords in quality_keywords.items():
            for keyword in keywords:
                if keyword in prompt_lower:
                    quality_indicators.append(quality)
                    break
        
        if quality_indicators:
            production_hints['quality_style'] = quality_indicators
        
        return production_hints
    
    def _calculate_prompt_complexity(self, analysis: Dict) -> float:
        """–†–∞—Å—á—ë—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤"""
        complexity_score = 0.0
        
        # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤
        word_count = analysis.get('word_count', 0)
        complexity_score += min(1.0, word_count / 20)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if 'bpm' in analysis:
            complexity_score += 0.2
        if 'key' in analysis:
            complexity_score += 0.2
        if 'duration' in analysis:
            complexity_score += 0.1
        
        # –ë–æ–Ω—É—Å –∑–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ —É–∫–∞–∑–∞–Ω–∏—è
        instruments_count = len(analysis.get('instruments', []))
        complexity_score += min(0.3, instruments_count * 0.1)
        
        # –ë–æ–Ω—É—Å –∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
        moods_count = len(analysis.get('mood', []))
        complexity_score += min(0.2, moods_count * 0.05)
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
        if 'mentioned_sections' in analysis:
            complexity_score += 0.2
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø—Ä–æ–¥–∞–∫—à–µ–Ω –ø–æ–¥—Å–∫–∞–∑–∫–∏
        if 'suggested_effects' in analysis:
            complexity_score += 0.1
        
        return min(1.0, complexity_score)
    
    def create_generation_context(self, analysis: Dict) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        context = {
            'prompt_analysis': analysis,
            'generation_hints': {},
            'quality_targets': {},
            'creative_constraints': {}
        }
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
        if analysis.get('complexity_score', 0) > 0.7:
            context['generation_hints']['approach'] = 'detailed'
            context['generation_hints']['creativity'] = 0.8
        else:
            context['generation_hints']['approach'] = 'standard'
            context['generation_hints']['creativity'] = 0.6
        
        # –¶–µ–ª–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if 'professional' in analysis.get('quality_style', []):
            context['quality_targets']['mastering_intensity'] = 0.8
            context['quality_targets']['dynamics_preservation'] = 0.7
        elif 'lofi' in analysis.get('quality_style', []):
            context['quality_targets']['vintage_processing'] = 0.8
            context['quality_targets']['dynamics_preservation'] = 0.4
        
        # –ö—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        mentioned_sections = analysis.get('mentioned_sections', [])
        if mentioned_sections:
            context['creative_constraints']['required_sections'] = mentioned_sections
        
        if 'bpm' in analysis:
            context['creative_constraints']['tempo_range'] = (
                analysis['bpm'] - 5, analysis['bpm'] + 5
            )
        
        return context
                
def write_report(self, f, samples, mastering, exported_files):
    # === –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã ===
    if samples:
        f.write(f"## üéõÔ∏è Used Samples ({len(samples)})\n\n")
        by_instrument = {}
        for sample in samples:
            instrument = sample.get("instrument_role", "unknown")
            by_instrument.setdefault(instrument, []).append(sample)
        
        for instrument, instrument_samples in by_instrument.items():
            f.write(f"### {instrument.title()}\n")
            for sample in instrument_samples:
                filename = sample.get("filename", "unknown")
                section = sample.get("section", "unknown")
                f.write(f"- **{filename}** (in {section})\n")
            f.write("\n")

    # === –ú–∞—Å—Ç–µ—Ä–∏–Ω–≥–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
    f.write("## üéöÔ∏è Mastering Configuration\n\n")
    if mastering:
        f.write(f"**Target LUFS**: {mastering.get('target_lufs', 'N/A')}\n\n")
        f.write(f"**Peak Ceiling**: {mastering.get('peak_ceiling', 'N/A')} dB\n\n")
        f.write(f"**Character**: {mastering.get('character', 'N/A')}\n\n")
        if "applied_stages" in mastering:
            f.write("**Applied Processing**:\n")
            for stage in mastering["applied_stages"]:
                f.write(f"- {stage.replace('_', ' ').title()}\n")
            f.write("\n")
    
    # === –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã ===
    f.write("## üìÅ Exported Files\n\n")
    for file_type, file_path in exported_files.items():
        relative_path = Path(file_path).name
        f.write(f"- **{file_type.replace('_', ' ').title()}**: `{relative_path}`\n")
    f.write("\n")

def analyze_audio(self, audio, sample_rate):
    try:
        samples = np.array(audio.get_array_of_samples()).astype(np.float32)
        mono_samples = samples.mean(axis=1) if audio.channels == 2 else samples

        analysis = {
            'peak': audio.max_dBFS,
            'rms': audio.rms,
            'duration': len(audio) / 1000.0
        }

        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        spectral_centroid = librosa.feature.spectral_centroid(y=mono_samples, sr=sample_rate)
        analysis['spectral_centroid'] = float(spectral_centroid.mean())

        spectral_rolloff = librosa.feature.spectral_rolloff(y=mono_samples, sr=sample_rate)
        analysis['spectral_rolloff'] = float(spectral_rolloff.mean())

        # –°—Ç–µ—Ä–µ–æ –∞–Ω–∞–ª–∏–∑
        if audio.channels == 2:
            correlation = np.corrcoef(samples[:, 0], samples[:, 1])[0, 1]
            analysis['stereo_correlation'] = float(correlation)
            analysis['stereo_width'] = 1.0 - abs(correlation)
        else:
            analysis['stereo_correlation'] = 1.0
            analysis['stereo_width'] = 0.0

        # –ß–∞—Å—Ç–æ—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        fft = np.fft.rfft(mono_samples)
        freqs = np.fft.rfftfreq(len(mono_samples), 1/sample_rate)
        magnitude = np.abs(fft)

        total_energy = np.sum(magnitude**2)
        analysis['frequency_balance'] = {
            'low': float(np.sum(magnitude[freqs < 300]**2) / total_energy),
            'mid': float(np.sum(magnitude[(freqs >= 300) & (freqs < 3000)]**2) / total_energy),
            'high': float(np.sum(magnitude[freqs >= 3000]**2) / total_energy)
        }

        # –¢—Ä–∞–Ω–∑–∏–µ–Ω—Ç—ã
        onset_frames = librosa.onset.onset_detect(y=mono_samples, sr=sample_rate)
        analysis['transient_density'] = len(onset_frames) / analysis['duration']

        # –ì–∞—Ä–º–æ–Ω–∏—á–Ω–æ—Å—Ç—å
        harmonic, percussive = librosa.effects.hpss(mono_samples)
        harmonic_energy = np.sum(harmonic**2)
        percussive_energy = np.sum(percussive**2)
        total = harmonic_energy + percussive_energy

        analysis['harmonic_ratio'] = float(harmonic_energy / total) if total > 0 else 0.5
        analysis['percussive_ratio'] = float(percussive_energy / total) if total > 0 else 0.5

        return analysis

    except Exception as e:
        self.logger.error(f"Source analysis error: {e}")
        return {
            'peak': audio.max_dBFS,
            'rms': audio.rms,
            'lufs': -20,
            'dynamic_range': 10,
            'duration': len(audio) / 1000.0,
            'frequency_balance': {'low': 0.33, 'mid': 0.33, 'high': 0.34},
            'stereo_width': 0.5,
            'harmonic_ratio': 0.5
        }

    def _create_mastering_target(self, target_config: Dict, genre_info: Dict, source_analysis: Dict) -> MasteringTarget:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞"""
        
        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        target = MasteringTarget(
            lufs=target_config.get("target_lufs", -14),
            peak_ceiling=target_config.get("peak_ceiling", -1),
            dynamic_range=target_config.get("dynamic_range", 8),
            stereo_width=target_config.get("stereo_enhancement", 1.0),
            frequency_balance={},
            harmonic_content=target_config.get("harmonic_saturation", 0.2),
            transient_preservation=0.8  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤
        )
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –∂–∞–Ω—Ä
        genre = genre_info.get("name", "")
        genre_adaptations = {
            "trap": {
                "frequency_balance": {"low": 0.4, "mid": 0.35, "high": 0.25},
                "stereo_width": 1.2,
                "transient_preservation": 0.9  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–∞—Ä—ã
            },
            "lofi": {
                "frequency_balance": {"low": 0.35, "mid": 0.45, "high": 0.2},
                "stereo_width": 0.8,  # –ë–æ–ª–µ–µ —É–∑–∫–∏–π —Å—Ç–µ—Ä–µ–æ
                "transient_preservation": 0.6  # –ë–æ–ª–µ–µ –º—è–≥–∫–æ
            },
            "dnb": {
                "frequency_balance": {"low": 0.3, "mid": 0.4, "high": 0.3},
                "stereo_width": 1.1,
                "transient_preservation": 0.95  # –ú–∞–∫—Å–∏–º—É–º —Ç—Ä–∞–Ω–∑–∏–µ–Ω—Ç–æ–≤
            },
            "ambient": {
                "frequency_balance": {"low": 0.25, "mid": 0.45, "high": 0.3},
                "stereo_width": 1.5,  # –®–∏—Ä–æ–∫–∏–π —Å—Ç–µ—Ä–µ–æ
                "transient_preservation": 0.5  # –ú—è–≥–∫–æ—Å—Ç—å
            },
            "techno": {
                "frequency_balance": {"low": 0.35, "mid": 0.4, "high": 0.25},
                "stereo_width": 1.0,
                "transient_preservation": 0.85
            }
        }
        
        if genre in genre_adaptations:
            adaptations = genre_adaptations[genre]
            target.frequency_balance = adaptations["frequency_balance"]
            target.stereo_width = adaptations["stereo_width"]
            target.transient_preservation = adaptations["transient_preservation"]
        else:
            # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –±–∞–ª–∞–Ω—Å
            target.frequency_balance = {"low": 0.33, "mid": 0.34, "high": 0.33}
        
        return target
    
    async def _plan_mastering_chain(
        self, source_analysis: Dict, target: MasteringTarget, genre_info: Dict
    ) -> Dict:
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        
        plan = {
            "stages": [],
            "parameters": {},
            "genre_specific": {}
        }
        
        # 1. –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ—Ä—Ä–µ–∫—Ü–∏–π
        lufs_diff = target.lufs - source_analysis["lufs"]
        peak_diff = target.peak_ceiling - source_analysis["peak"]
        
        # 2. EQ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        source_balance = source_analysis.get("frequency_balance", {"low": 0.33, "mid": 0.33, "high": 0.34})
        target_balance = target.frequency_balance
        
        eq_corrections = {}
        for band in ["low", "mid", "high"]:
            source_level = source_balance.get(band, 0.33)
            target_level = target_balance.get(band, 0.33)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dB –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω–æ)
            if target_level > source_level:
                correction = min(6, (target_level - source_level) * 20)
            else:
                correction = max(-6, (target_level - source_level) * 20)
            
            eq_corrections[band] = correction
        
        if any(abs(c) > 0.5 for c in eq_corrections.values()):
            plan["stages"].append("eq")
            plan["parameters"]["eq"] = eq_corrections
        
        # 3. –ö–æ–º–ø—Ä–µ—Å—Å–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        source_dr = source_analysis.get("dynamic_range", 10)
        target_dr = target.dynamic_range
        
        if source_dr > target_dr + 2:  # –ù—É–∂–Ω–∞ –∫–æ–º–ø—Ä–µ—Å—Å–∏—è
            compression_ratio = min(8.0, 1 + (source_dr - target_dr) / 5)
            threshold = source_analysis["peak"] - (source_dr * 0.7)
            
            plan["stages"].append("compressor")
            plan["parameters"]["compressor"] = {
                "ratio": compression_ratio,
                "threshold": threshold,
                "attack": 10,  # ms
                "release": 100  # ms
            }
        
        # 4. –ù–∞—Å—ã—â–µ–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        if target.harmonic_content > 0.1:
            genre = genre_info.get("name", "")
            saturation_types = {
                "lofi": "tape",
                "trap": "tube", 
                "techno": "transistor",
                "ambient": "tube"
            }
            
            plan["stages"].append("saturation")
            plan["parameters"]["saturation"] = {
                "amount": target.harmonic_content,
                "type": saturation_types.get(genre, "tube"),
                "warmth": target.harmonic_content * 1.5
            }
        
        # 5. –°—Ç–µ—Ä–µ–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        source_width = source_analysis.get("stereo_width", 0.5)
        if abs(target.stereo_width - source_width) > 0.1:
            plan["stages"].append("stereo")
            plan["parameters"]["stereo"] = {
                "width": target.stereo_width,
                "imaging": "enhanced" if target.stereo_width > 1.0 else "natural"
            }
        
        # 6. –†–µ–≤–µ—Ä–± (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –∂–∞–Ω—Ä–∞)
        genre = genre_info.get("name", "")
        if genre in ["ambient", "cinematic"]:
            plan["stages"].append("reverb")
            reverb_settings = {
                "ambient": {"room_size": 0.7, "wet_level": 0.25, "type": "hall"},
                "cinematic": {"room_size": 0.6, "wet_level": 0.2, "type": "cinematic_hall"}
            }
            plan["parameters"]["reverb"] = reverb_settings.get(genre, {"room_size": 0.3, "wet_level": 0.15})
        
        # 7. –õ–∏–º–∏—Ç–µ—Ä (–≤—Å–µ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π)
        plan["stages"].append("limiter")
        plan["parameters"]["limiter"] = {
            "threshold": target.peak_ceiling + 1,  # –ù–µ–º–Ω–æ–≥–æ –∑–∞–ø–∞—Å–∞
            "ceiling": target.peak_ceiling,
            "release": 50  # ms
        }
        
        # 8. –ñ–∞–Ω—Ä–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        plan["genre_specific"] = {
            "preserve_transients": target.transient_preservation,
            "target_loudness": target.lufs,
            "processing_intensity": min(1.0, abs(lufs_diff) / 10)  # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
        }
        
        self.logger.info(f"  üìã Processing plan: {len(plan['stages'])} stages - {', '.join(plan['stages'])}")
        
        return plan
    
    async def _apply_mastering_chain(self, audio: AudioSegment, plan: Dict) -> AudioSegment:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        processed = audio
        
        for stage in plan["stages"]:
            if stage in plan["parameters"]:
                params = plan["parameters"][stage]
                
                self.logger.debug(f"  üîß Applying {stage}: {params}")
                
                try:
                    processed = await self.effects_chain.processors[stage].process(processed, params)
                except Exception as e:
                    self.logger.error(f"‚ùå Error in {stage}: {e}")
        
        return processed
    
    async def _final_verification_pass(self, audio: AudioSegment, target: MasteringTarget) -> AudioSegment:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è"""
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_analysis = await self._analyze_source_material(audio)
        
        corrections_needed = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º LUFS
        lufs_error = abs(final_analysis["lufs"] - target.lufs)
        if lufs_error > 1.0:  # –ë–æ–ª—å—à–µ 1 LU –æ—à–∏–±–∫–∏
            corrections_needed.append("loudness")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∏–∫–∏
        if final_analysis["peak"] > target.peak_ceiling:
            corrections_needed.append("peaks")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        corrected = audio
        
        if "peaks" in corrections_needed:
            # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            over_ceiling = final_analysis["peak"] - target.peak_ceiling
            corrected = corrected - (over_ceiling + 0.1)  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
            self.logger.info(f"  üöß Final peak correction: -{over_ceiling + 0.1:.1f}dB")
        
        if "loudness" in corrections_needed:
            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            lufs_correction = target.lufs - final_analysis["lufs"]
            if abs(lufs_correction) < 6:  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç
                corrected = corrected + lufs_correction
                self.logger.info(f"  üìä Final loudness correction: {lufs_correction:+.1f}dB")
        
        return corrected
    
    def _create_mastering_report(
        self, plan: Dict, source_analysis: Dict, target: MasteringTarget
    ) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ –æ –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ"""
        
        report = {
            "applied_stages": plan["stages"],
            "parameters": plan["parameters"],
            "source_characteristics": {
                "lufs": source_analysis["lufs"],
                "peak": source_analysis["peak"],
                "dynamic_range": source_analysis["dynamic_range"],
                "stereo_width": source_analysis.get("stereo_width", 0.5)
            },
            "target_characteristics": {
                "lufs": target.lufs,
                "peak_ceiling": target.peak_ceiling,
                "dynamic_range": target.dynamic_range,
                "stereo_width": target.stereo_width
            },
            "processing_intensity": plan["genre_specific"]["processing_intensity"],
            "character": f"mastered for {target.lufs} LUFS with {target.dynamic_range} LU dynamics"
        }
        
        return report