# mistral_client.py - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø VERSION
import requests
import json
import subprocess
import logging
import re

def query_structured_music(prompt: str) -> dict:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∑–∞–ø—Ä–æ—Å –∫ LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º—É–∑—ã–∫–∏
    """
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ HTTP API (–±—ã—Å—Ç—Ä–µ–µ –∏ –Ω–∞–¥–µ–∂–Ω–µ–µ)
    result = _query_ollama_api(prompt)
    if result:
        logging.info(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–ª—É—á–µ–Ω–∞ —á–µ—Ä–µ–∑ API: {len(result.get('structure', []))} —Å–µ–∫—Ü–∏–π")
        return result
    
    # Fallback –Ω–∞ subprocess —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π
    result = _query_ollama_subprocess(prompt)
    if result:
        logging.info(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ–ª—É—á–µ–Ω–∞ —á–µ—Ä–µ–∑ subprocess: {len(result.get('structure', []))} —Å–µ–∫—Ü–∏–π")
        return result
    
    logging.error("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
    return None


def _query_ollama_api(prompt: str) -> dict:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Ollama HTTP API
    """
    # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ø—Ä–æ–º–ø—Ç –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ JSON
    llama_prompt = f"""Generate a music track structure in JSON format for: {prompt}

Return only valid JSON with this exact structure:

{{
  "BPM": 120,
  "structure": [
    {{"type": "intro", "duration": 8}},
    {{"type": "buildup", "duration": 16}},
    {{"type": "drop", "duration": 16}},
    {{"type": "outro", "duration": 8}}
  ]
}}

Rules:
- Only JSON, no explanations
- Use double quotes only
- Match the genre and mood from description
- Total duration should be 60-120 seconds
- Section types: intro, verse, chorus, buildup, drop, breakdown, bridge, outro"""

    # –ò–°–ü–†–ê–í–õ–ï–ù: –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama API
    try:
        ping_response = requests.get("http://localhost:11434/api/version", timeout=5)
        if ping_response.status_code != 200:
            logging.warning("‚ö†Ô∏è Ollama API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            return None
    except:
        logging.warning("‚ö†Ô∏è Ollama API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return None
    
    # –í–ê–®–ò –†–ï–ê–õ–¨–ù–´–ï –ú–û–î–ï–õ–ò –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    models_to_try = [
        "llama3-music:latest",    # –í–∞—à–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        "llama3.1:latest",        # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
        "llama3:latest",          # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
        "llama3.2:latest",        # –ë–æ–ª–µ–µ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è
        "mistral:7b",             # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
        "mistral:latest"          # Fallback
    ]
    
    for model in models_to_try:
        try:
            logging.info(f"üöÄ –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª—å {model} —á–µ—Ä–µ–∑ Ollama API")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π endpoint /api/tags
            response = requests.post(
                "http://localhost:11434/api/generate",  # –ò–°–ü–†–ê–í–õ–ï–ù–û!
                json={
                    "model": model,
                    "prompt": llama_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –¥–ª—è JSON
                        "top_p": 0.5,
                        "num_predict": 500,   # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
                        "stop": ["```", "---", "Explanation:", "Note:", "\n\n\n", "Human:", "Assistant:"]
                    }
                },
                timeout=90  # –†–∞–∑—É–º–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
            )
            
            if response.status_code == 200:
                result_data = response.json()
                raw_output = result_data.get("response", "")
                
                if raw_output.strip():
                    logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç {model}: {len(raw_output)} —Å–∏–º–≤–æ–ª–æ–≤")
                    parsed_result = _parse_json_from_response(raw_output)
                    if parsed_result:
                        return parsed_result
                        
        except requests.exceptions.ConnectionError:
            logging.warning(f"‚ö†Ô∏è Ollama API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            break  # –ù–µ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
        except requests.exceptions.Timeout:
            logging.warning(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ {model}")
            continue
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model}: {e}")
            continue
    
    return None


def _query_ollama_subprocess(prompt: str) -> dict:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô fallback —á–µ—Ä–µ–∑ subprocess
    """
    llama_prompt = f"""Generate a music track structure in JSON format for: {prompt}

Return only valid JSON with this exact structure:

{{
  "BPM": 120,
  "structure": [
    {{"type": "intro", "duration": 8}},
    {{"type": "buildup", "duration": 16}},
    {{"type": "drop", "duration": 16}},
    {{"type": "outro", "duration": 8}}
  ]
}}

Rules:
- Only JSON, no explanations
- Use double quotes only
- Match the genre and mood from description
- Total duration should be 60-120 seconds
- Section types: intro, verse, chorus, buildup, drop, breakdown, bridge, outro"""

    models_to_try = [
        "llama3-music:latest",    # –í–∞—à–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        "llama3.1:latest",        # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
        "llama3:latest",          # –û—Å–Ω–æ–≤–Ω–∞—è 
        "llama3.2:latest",        # –ë–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è
        "mistral:7b",             # –ë—ã—Å—Ç—Ä–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
        "mistral:latest"          # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback
    ]
    
    for model in models_to_try:
        try:
            logging.info(f"üöÄ –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫ {model} —á–µ—Ä–µ–∑ ollama run")

            result = subprocess.run(
                ['ollama', 'run', model],
                input=llama_prompt,
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=90  # –†–∞–∑—É–º–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
            )

            if result.returncode != 0:
                stderr_output = result.stderr.strip()
                if "model" in stderr_output.lower() and "not found" in stderr_output.lower():
                    logging.info(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                else:
                    logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ ollama –¥–ª—è {model}: {stderr_output}")
                continue

            raw_output = result.stdout.strip()
            
            if raw_output:
                logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç {model}: {len(raw_output)} —Å–∏–º–≤–æ–ª–æ–≤")
                parsed_result = _parse_json_from_response(raw_output)
                if parsed_result:
                    return parsed_result

        except subprocess.TimeoutExpired:
            logging.warning(f"‚ö†Ô∏è –ó–∞–ø—Ä–æ—Å –∫ {model} –ø—Ä–µ–≤—ã—Å–∏–ª –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏")
            continue
        except FileNotFoundError:
            logging.error("‚ùå ollama –∫–æ–º–∞–Ω–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama!")
            break
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ —Å {model}: {e}")
            continue

    logging.error("‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM —á–µ—Ä–µ–∑ subprocess –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å")
    return None


def _parse_json_from_response(raw_output: str) -> dict:
    """
    –£–õ–£–ß–®–ï–ù–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM
    """
    logging.debug(f"–ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç: {raw_output[:200]}...")
    
    # –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ JSON
    json_candidates = []
    
    # –ú–µ—Ç–æ–¥ 1: –ü–æ–∏—Å–∫ –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º ```json
    if "```json" in raw_output.lower():
        start = raw_output.lower().find("```json") + 7
        end = raw_output.find("```", start)
        if end != -1:
            json_candidates.append(raw_output[start:end].strip())
    
    # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–≥–æ { –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ }
    first_brace = raw_output.find('{')
    last_brace = raw_output.rfind('}')
    if first_brace != -1 and last_brace > first_brace:
        json_candidates.append(raw_output[first_brace:last_brace+1])
    
    # –ú–µ—Ç–æ–¥ 3: –ü–æ—Å—Ç—Ä–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –ø–æ–¥—Å—á–µ—Ç–æ–º —Å–∫–æ–±–æ–∫
    lines = raw_output.split('\n')
    current_json = ""
    brace_count = 0
    in_json = False
    
    for line in lines:
        stripped_line = line.strip()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        if stripped_line.startswith(('//:', '#', '/*', '*/', 'Note:', 'Explanation:', 'Human:', 'Assistant:')):
            continue
            
        if '{' in stripped_line and not in_json:
            in_json = True
            current_json = ""
        
        if in_json:
            current_json += line + '\n'
            brace_count += line.count('{') - line.count('}')
            
            if brace_count == 0 and '}' in line:
                json_candidates.append(current_json.strip())
                in_json = False
                current_json = ""
                break
    
    # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    for i, candidate in enumerate(json_candidates):
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–µ–≥–æ
            cleaned = _clean_json_text(candidate)
            if not cleaned:
                continue
                
            parsed = json.loads(cleaned)
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if _validate_llama_response(parsed):
                logging.info(f"‚úÖ JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω (–º–µ—Ç–æ–¥ {i+1})")
                return _normalize_llama_response(parsed)
        
        except json.JSONDecodeError as e:
            logging.debug(f"‚ö†Ô∏è JSON –∫–∞–Ω–¥–∏–¥–∞—Ç {i+1} –Ω–µ –≤–∞–ª–∏–¥–µ–Ω: {e}")
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π JSON –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logging.debug(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π JSON: {candidate[:200]}")
            continue
        except Exception as e:
            logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ {i+1}: {e}")
            continue
    
    logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞–ª–∏–¥–Ω—ã–π JSON –≤ –æ—Ç–≤–µ—Ç–µ LLM")
    logging.debug(f"–ò—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç: {raw_output}")
    return None


def _clean_json_text(text: str) -> str:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ JSON —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞
    """
    if not text:
        return ""
    
    # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–º–µ—Ç–∫—É
    text = text.replace('```json', '').replace('```', '')
    
    # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ —Å—Ç–∏–ª–µ // –∏ #
    lines = []
    for line in text.split('\n'):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º
        stripped = line.strip()
        if not stripped.startswith(('//:', '//', '#', '/*', '*/', 'Note:', 'Explanation:')):
            # –£–±–∏—Ä–∞–µ–º inline –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø–æ—Å–ª–µ //
            if '//' in line:
                line = line.split('//')[0]
            lines.append(line)
    
    text = '\n'.join(lines)
    
    # –£–±–∏—Ä–∞–µ–º trailing commas (—á–∞—Å—Ç–∞—è –ø—Ä–æ–±–ª–µ–º–∞ LLM)
    text = re.sub(r',(\s*[}\]])', r'\1', text)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\s*{\s*', '{', text)
    text = re.sub(r'\s*}\s*', '}', text)
    text = re.sub(r'\s*\[\s*', '[', text)
    text = re.sub(r'\s*\]\s*', ']', text)
    
    return text.strip()


def _validate_llama_response(data: dict) -> bool:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLaMA
    """
    if not isinstance(data, dict):
        logging.debug("‚ùå –û—Ç–≤–µ—Ç –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º")
        return False
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º BPM –≤–º–µ—Å—Ç–æ tempo
    if 'BPM' not in data:
        logging.debug("‚ùå –ù–µ—Ç –ø–æ–ª—è BPM")
        return False
    
    if not isinstance(data['BPM'], (int, float)):
        logging.debug("‚ùå BPM –Ω–µ —á–∏—Å–ª–æ")
        return False
    
    if 'structure' not in data or not isinstance(data['structure'], list):
        logging.debug("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω–æ–≥–æ –ø–æ–ª—è structure")
        return False
    
    if not data['structure']:
        logging.debug("‚ùå –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—É—Å—Ç–∞")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–µ–∫—Ü–∏–π
    for i, section in enumerate(data['structure']):
        if not isinstance(section, dict):
            logging.debug(f"‚ùå –°–µ–∫—Ü–∏—è {i} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º")
            return False
        if 'type' not in section:
            logging.debug(f"‚ùå –°–µ–∫—Ü–∏—è {i} –±–µ–∑ —Ç–∏–ø–∞")
            return False
        if 'duration' not in section:
            logging.debug(f"‚ùå –°–µ–∫—Ü–∏—è {i} –±–µ–∑ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            return False
        if not isinstance(section['duration'], (int, float)):
            logging.debug(f"‚ùå –°–µ–∫—Ü–∏—è {i} —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é")
            return False
    
    logging.debug("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")
    return True


def _normalize_llama_response(data: dict) -> dict:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLaMA –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É pipeline
    """
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç pipeline
    normalized = {
        'structure': [],
        'BPM': int(data.get('BPM', 120)),
        'tracks': data.get('tracks', [])  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    }
    
    total_duration = 0
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    for section in data.get('structure', []):
        duration = int(section.get('duration', 16))
        normalized_section = {
            'type': section.get('type', 'section').lower(),
            'duration': duration,
            'energy': _estimate_energy_from_type(section.get('type', 'section')),
            'start_time': total_duration  # –î–æ–±–∞–≤–ª—è–µ–º start_time –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        }
        normalized['structure'].append(normalized_section)
        total_duration += duration
    
    # –ï—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—É—Å—Ç–∞—è, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é
    if not normalized['structure']:
        logging.warning("‚ö†Ô∏è –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É, —Ç–∞–∫ –∫–∞–∫ LLM –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç—É—é")
        normalized['structure'] = [
            {'type': 'intro', 'duration': 8, 'energy': 0.3, 'start_time': 0},
            {'type': 'verse', 'duration': 16, 'energy': 0.6, 'start_time': 8},
            {'type': 'chorus', 'duration': 16, 'energy': 0.8, 'start_time': 24},
            {'type': 'verse', 'duration': 16, 'energy': 0.6, 'start_time': 40},
            {'type': 'chorus', 'duration': 16, 'energy': 0.9, 'start_time': 56},
            {'type': 'outro', 'duration': 8, 'energy': 0.4, 'start_time': 72}
        ]
        total_duration = 80
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    normalized['total_duration'] = total_duration
    
    logging.info(f"‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞: {len(normalized['structure'])} —Å–µ–∫—Ü–∏–π, {total_duration}—Å")
    return normalized


def _estimate_energy_from_type(section_type: str) -> float:
    """
    –û—Ü–µ–Ω–∫–∞ —ç–Ω–µ—Ä–≥–∏–∏ —Å–µ–∫—Ü–∏–∏ –ø–æ –µ—ë —Ç–∏–ø—É
    """
    energy_map = {
        'intro': 0.3,
        'verse': 0.6,
        'prechorus': 0.7,
        'chorus': 0.8,
        'hook': 0.9,
        'drop': 0.9,
        'buildup': 0.7,
        'breakdown': 0.4,
        'bridge': 0.5,
        'outro': 0.3,
        'interlude': 0.4,
        'solo': 0.8
    }
    
    return energy_map.get(section_type.lower(), 0.5)


def test_mistral_client():
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    """
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ mistral_client...")
    
    test_prompts = [
        "dark trap beat 160bpm aggressive",
        "melodic lofi study music with vinyl textures",
        "energetic drum and bass 174bpm"
    ]
    
    for prompt in test_prompts:
        print(f"\nüéµ –¢–µ—Å—Ç–∏—Ä—É–µ–º: '{prompt}'")
        result = query_structured_music(prompt)
        
        if result:
            print(f"‚úÖ –£—Å–ø–µ—Ö: {len(result['structure'])} —Å–µ–∫—Ü–∏–π, BPM: {result.get('BPM')}")
            for i, section in enumerate(result['structure']):
                print(f"  {i+1}. {section['type']} - {section['duration']}—Å")
        else:
            print("‚ùå –ù–µ—É–¥–∞—á–∞")
    
    return True


if __name__ == "__main__":
    # –í–∫–ª—é—á–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    logging.basicConfig(level=logging.DEBUG)
    test_mistral_client()
