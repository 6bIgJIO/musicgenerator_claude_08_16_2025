# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô musicgen_wrapper.py
# –ó–∞–º–µ–Ω–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –Ω–∞ —ç—Ç–æ:

import torch
import torchaudio
import os, sys
import io
import numpy as np
import soundfile as sf
from typing import Optional, List, Dict, Union
import warnings
import logging
import time
from pydub import AudioSegment
from pydub.generators import Sine, Square, WhiteNoise

def fix_signal_issue():
    """–ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—É —Å signal.SIGALRM –≤ Windows"""
    try:
        import signal
        if not hasattr(signal, 'SIGALRM'):
            # –í Windows –Ω–µ—Ç SIGALRM, —Å–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            signal.SIGALRM = 14  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è Unix
            signal.alarm = lambda x: None  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è alarm()
            print("‚úÖ Windows signal fix applied")
    except Exception as e:
        print(f"‚ö†Ô∏è Signal fix warning: {e}")

# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–∫—Å –î–û –∏–º–ø–æ—Ä—Ç–∞ audiocraft
fix_signal_issue()
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ç–≤–æ–µ–º—É audiocraft
AUDIOCRAFT_PATH = r"D:\2027\audiocraft\audiocraft"
if AUDIOCRAFT_PATH not in sys.path:
    sys.path.insert(0, AUDIOCRAFT_PATH)


# –ü–æ–¥–∞–≤–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore")

try:
    # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å audiocraft, –Ω–æ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π Windows-–æ—à–∏–±–æ–∫
    os.environ['AUDIOCRAFT_NO_SIGNAL'] = '1'  # –û—Ç–∫–ª—é—á–∞–µ–º signal handling
    from audiocraft.models import musicgen
    MUSICGEN_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è AudioCraft –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    MUSICGEN_AVAILABLE = False
except Exception as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ AudioCraft: {e}")
    MUSICGEN_AVAILABLE = False

class MusicGenEngine:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä –∫–æ—Ç–æ—Ä—ã–π –∑–∞–º–µ–Ω—è–µ—Ç MusicGen
    –°–æ–∑–¥–∞–µ—Ç –º—É–∑—ã–∫–∞–ª—å–Ω–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏ –≤–º–µ—Å—Ç–æ —à—É–º–∞
    """
    
    def __init__(self, model_path=None, device=None, logger=None):
        # –õ–æ–≥–≥–µ—Ä
        self.logger = logger or logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)

        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        if model_name is None:
            model_name = r"D:\2027\audiocraft\audiocraft\models\facebook\musicgen-medium"

        self.logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å MusicGen –∏–∑ {model_path} –Ω–∞ {self.device}...")
        self.model = MusicGen.get_pretrained(model_path).to(self.device)
        
    def generate_musical_track(
        self, 
        prompt: str, 
        duration: int, 
        genre: Optional[str] = None,
        bpm: int = 120
    ) -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞"""
        
        self.logger.info(f"üéº –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ç—Ä–µ–∫: '{prompt}' ({duration}—Å, {genre or 'auto'}, {bpm}BPM)")
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∂–∞–Ω—Ä–∞ –∏ –ø—Ä–æ–º–ø—Ç–∞
            track_params = self._analyze_prompt_and_genre(prompt, genre, bpm)
            
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–π —Ç—Ä–µ–∫
            base_track = self._generate_base_composition(duration, track_params)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ–ª–æ–¥–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            melody_track = self._add_melodic_elements(duration, track_params)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∏—Ç–º–∏—á–µ—Å–∫—É—é —Å–µ–∫—Ü–∏—é
            rhythm_track = self._add_rhythmic_elements(duration, track_params)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –±–∞—Å–æ–≤—É—é –ª–∏–Ω–∏—é
            bass_track = self._add_bass_line(duration, track_params)
            
            # –ú–∏–∫—à–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–∏
            final_track = self._mix_layers(
                base_track, melody_track, rhythm_track, bass_track, track_params
            )
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            final_track = self._apply_final_processing(final_track, track_params)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV bytes
            audio_bytes = self._to_wav_bytes(final_track)
            
            self.logger.info(f"‚úÖ –¢—Ä–µ–∫ —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω: {len(audio_bytes)} bytes")
            return audio_bytes
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: {e}")
            return self._create_emergency_track(duration)
    
    def _analyze_prompt_and_genre(self, prompt: str, genre: Optional[str], bpm: int) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∏ –∂–∞–Ω—Ä –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç—Ä–µ–∫–∞"""
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ –∂–∞–Ω—Ä–∞–º
        genre_params = {
            'trap': {
                'main_freq': 60, 'melody_freq': 440, 'energy': 0.8,
                'bass_emphasis': 0.9, 'rhythm_complexity': 0.8,
                'reverb_amount': 0.3, 'distortion': 0.2
            },
            'lofi': {
                'main_freq': 80, 'melody_freq': 330, 'energy': 0.4,
                'bass_emphasis': 0.6, 'rhythm_complexity': 0.3,
                'reverb_amount': 0.6, 'vintage_warmth': 0.7
            },
            'dnb': {
                'main_freq': 70, 'melody_freq': 523, 'energy': 0.9,
                'bass_emphasis': 0.8, 'rhythm_complexity': 0.95,
                'reverb_amount': 0.2, 'distortion': 0.3
            },
            'ambient': {
                'main_freq': 40, 'melody_freq': 220, 'energy': 0.3,
                'bass_emphasis': 0.4, 'rhythm_complexity': 0.1,
                'reverb_amount': 0.8, 'ethereal_pads': 0.8
            },
            'techno': {
                'main_freq': 50, 'melody_freq': 880, 'energy': 0.7,
                'bass_emphasis': 0.7, 'rhythm_complexity': 0.6,
                'reverb_amount': 0.4, 'industrial_edge': 0.6
            },
            'house': {
                'main_freq': 65, 'melody_freq': 440, 'energy': 0.6,
                'bass_emphasis': 0.7, 'rhythm_complexity': 0.5,
                'reverb_amount': 0.4, 'groove_emphasis': 0.8
            }
        }
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        prompt_lower = prompt.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–Ω–µ—Ä–≥–∏—é
        energy_boost = 0
        if any(word in prompt_lower for word in ['aggressive', 'heavy', 'dark', 'intense']):
            energy_boost += 0.2
        if any(word in prompt_lower for word in ['chill', 'soft', 'gentle', 'mellow']):
            energy_boost -= 0.2
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        base_params = genre_params.get(genre, genre_params['trap'])
        base_params['energy'] = max(0.1, min(1.0, base_params['energy'] + energy_boost))
        base_params['bpm'] = bpm
        base_params['duration'] = duration
        base_params['genre'] = genre or 'generic'
        
        return base_params
    
    def _generate_base_composition(self, duration: int, params: Dict) -> np.ndarray:
        """–°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–º–ø–æ–∑–∏—Ü–∏—é —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –≥–∞—Ä–º–æ–Ω–∏—è–º–∏"""
        
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples)
        
        base_freq = params['main_freq']
        energy = params['energy']
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
        fundamental = np.sin(2 * np.pi * base_freq * t) * energy * 0.3
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≥–∞—Ä–º–æ–Ω–∏–∫–∏ –¥–ª—è –±–æ–≥–∞—Ç—Å—Ç–≤–∞ –∑–≤—É–∫–∞
        harmonic2 = np.sin(2 * np.pi * base_freq * 2 * t) * energy * 0.15
        harmonic3 = np.sin(2 * np.pi * base_freq * 3 * t) * energy * 0.1
        
        # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –º–æ–¥—É–ª—è—Ü–∏–∏ –¥–ª—è –∂–∏–≤–æ—Å—Ç–∏
        lfo = np.sin(2 * np.pi * 0.3 * t) * 0.1 + 1
        
        base_composition = (fundamental + harmonic2 + harmonic3) * lfo
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        base_composition = self._add_structural_changes(base_composition, t, params)
        
        return base_composition
    
    def _add_melodic_elements(self, duration: int, params: Dict) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ–º –º–µ–ª–æ–¥–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã"""
        
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples)
        
        melody_freq = params['melody_freq']
        energy = params['energy']
        
        # –°–æ–∑–¥–∞–µ–º –º–µ–ª–æ–¥–∏—á–µ—Å–∫—É—é –ª–∏–Ω–∏—é —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏
        melody_notes = [melody_freq, melody_freq * 1.25, melody_freq * 1.5, melody_freq * 2.0]
        
        melody = np.zeros_like(t)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ñ—Ä–∞–∑—ã
        phrase_length = max(2, duration // 4)
        
        for i in range(0, int(duration), phrase_length):
            start_idx = int(i * self.sample_rate)
            end_idx = int(min(i + phrase_length, duration) * self.sample_rate)
            
            if start_idx >= len(t):
                break
                
            phrase_t = t[start_idx:end_idx] - i
            note_freq = random.choice(melody_notes)
            
            # –°–æ–∑–¥–∞–µ–º –º–µ–ª–æ–¥–∏—á–µ—Å–∫—É—é —Ñ—Ä–∞–∑—É
            phrase = np.sin(2 * np.pi * note_freq * phrase_t) * energy * 0.2
            
            # –î–æ–±–∞–≤–ª—è–µ–º envelope
            envelope = np.exp(-phrase_t * 0.5)
            phrase = phrase * envelope
            
            melody[start_idx:end_idx] = phrase
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–∫–∏–π —Ö–æ—Ä—É—Å —ç—Ñ—Ñ–µ–∫—Ç
        delayed_melody = np.roll(melody, int(0.02 * self.sample_rate))
        melody = melody + delayed_melody * 0.3
        
        return melody
    
    def _add_rhythmic_elements(self, duration: int, params: Dict) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ–º —Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã"""
        
        samples = int(self.sample_rate * duration)
        bpm = params['bpm']
        complexity = params['rhythm_complexity']
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        beat_duration = 60.0 / bpm
        beat_samples = int(beat_duration * self.sample_rate)
        
        rhythm = np.zeros(samples)
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –±–∏—Ç (kick)
        kick_pattern = [1, 0, 0, 0] if complexity < 0.5 else [1, 0, 1, 0]
        
        # Snare pattern
        snare_pattern = [0, 0, 1, 0] if complexity < 0.7 else [0, 1, 1, 0]
        
        # Hi-hat pattern
        hihat_pattern = [1, 1, 1, 1] if complexity > 0.6 else [1, 0, 1, 0]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∏—Ç–º
        current_sample = 0
        beat_idx = 0
        
        while current_sample < samples - beat_samples:
            pattern_pos = beat_idx % 4
            
            # Kick
            if kick_pattern[pattern_pos]:
                kick_envelope = np.exp(-np.linspace(0, 3, beat_samples // 4))
                kick_sound = np.sin(2 * np.pi * 60 * np.linspace(0, 0.2, beat_samples // 4))
                kick = kick_sound * kick_envelope * params['bass_emphasis'] * 0.4
                
                end_pos = min(current_sample + len(kick), samples)
                rhythm[current_sample:end_pos] += kick[:end_pos-current_sample]
            
            # Snare
            if snare_pattern[pattern_pos]:
                snare_noise = np.random.normal(0, 0.1, beat_samples // 6)
                snare_tone = np.sin(2 * np.pi * 200 * np.linspace(0, 0.15, beat_samples // 6))
                snare = (snare_noise + snare_tone) * 0.3
                
                snare_pos = current_sample + beat_samples // 2
                end_pos = min(snare_pos + len(snare), samples)
                if snare_pos < samples:
                    rhythm[snare_pos:end_pos] += snare[:end_pos-snare_pos]
            
            # Hi-hat
            if hihat_pattern[pattern_pos]:
                hihat = np.random.normal(0, 0.05, beat_samples // 8)
                hihat = self._high_pass_filter(hihat, 8000)
                
                hihat_pos = current_sample + beat_samples // 4
                end_pos = min(hihat_pos + len(hihat), samples)
                if hihat_pos < samples:
                    rhythm[hihat_pos:end_pos] += hihat[:end_pos-hihat_pos]
            
            current_sample += beat_samples
            beat_idx += 1
        
        return rhythm
    
    def _add_bass_line(self, duration: int, params: Dict) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ–º –±–∞—Å–æ–≤—É—é –ª–∏–Ω–∏—é"""
        
        samples = int(self.sample_rate * duration)
        t = np.linspace(0, duration, samples)
        
        bass_freq = params['main_freq'] / 2  # –û–∫—Ç–∞–≤–∞ –Ω–∏–∂–µ
        bass_emphasis = params['bass_emphasis']
        
        # –°–æ–∑–¥–∞–µ–º –±–∞—Å–æ–≤—É—é –ª–∏–Ω–∏—é —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        bass_pattern = [1, 0, 1, 0] if params['genre'] in ['trap', 'dnb'] else [1, 0, 0, 0]
        
        bass = np.zeros_like(t)
        
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–æ—Ç—ã bass
        note_duration = max(0.5, 60.0 / params['bpm'])
        
        for i, should_play in enumerate(bass_pattern):
            if not should_play:
                continue
                
            start_time = i * note_duration
            end_time = min(start_time + note_duration, duration)
            
            start_idx = int(start_time * self.sample_rate)
            end_idx = int(end_time * self.sample_rate)
            
            if start_idx >= len(t):
                break
                
            note_t = t[start_idx:end_idx] - start_time
            
            # –°–æ–∑–¥–∞–µ–º –±–∞—Å–æ–≤—É—é –Ω–æ—Ç—É —Å envelope
            bass_note = np.sin(2 * np.pi * bass_freq * note_t)
            bass_note += np.sin(2 * np.pi * bass_freq * 2 * note_t) * 0.3  # –ì–∞—Ä–º–æ–Ω–∏–∫–∞
            
            # Envelope –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
            envelope = np.exp(-note_t * 2)
            bass_note = bass_note * envelope * bass_emphasis * 0.5
            
            bass[start_idx:end_idx] = bass_note
        
        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –Ω–∞ –≤–µ—Å—å —Ç—Ä–µ–∫
        pattern_duration = len(bass_pattern) * note_duration
        repetitions = int(np.ceil(duration / pattern_duration))
        
        full_bass = np.zeros(samples)
        for rep in range(repetitions):
            start_idx = int(rep * pattern_duration * self.sample_rate)
            end_idx = min(start_idx + len(bass), samples)
            if start_idx < samples:
                full_bass[start_idx:end_idx] += bass[:end_idx-start_idx]
        
        return full_bass
    
    def _add_structural_changes(self, audio: np.ndarray, t: np.ndarray, params: Dict) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (intro, buildup, drop, etc.)"""
        
        duration = params['duration']
        
        # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: intro -> main -> outro
        intro_end = min(8, duration * 0.2)
        outro_start = max(duration * 0.8, duration - 8)
        
        # Intro envelope
        intro_mask = t < intro_end
        intro_envelope = np.where(intro_mask, t / intro_end, 1.0)
        
        # Outro envelope  
        outro_mask = t > outro_start
        outro_envelope = np.where(outro_mask, (duration - t) / (duration - outro_start), 1.0)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º envelopes
        structural_envelope = intro_envelope * outro_envelope
        
        # –î–æ–±–∞–≤–ª—è–µ–º subtle –≤–∞—Ä–∏–∞—Ü–∏–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–∏
        main_variations = 1.0 + np.sin(2 * np.pi * t / 8) * 0.1
        
        return audio * structural_envelope * main_variations
    
    def _mix_layers(
        self, base: np.ndarray, melody: np.ndarray, 
        rhythm: np.ndarray, bass: np.ndarray, params: Dict
    ) -> np.ndarray:
        """–ú–∏–∫—à–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–∏"""
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª–∏–Ω—ã
        min_length = min(len(base), len(melody), len(rhythm), len(bass))
        base = base[:min_length]
        melody = melody[:min_length]
        rhythm = rhythm[:min_length]
        bass = bass[:min_length]
        
        # –ú–∏–∫—à–∏—Ä—É–µ–º —Å —É—á–µ—Ç–æ–º –∂–∞–Ω—Ä–æ–≤—ã—Ö –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        genre = params['genre']
        
        if genre == 'trap':
            mixed = base * 0.6 + melody * 0.4 + rhythm * 0.8 + bass * 0.9
        elif genre == 'lofi':
            mixed = base * 0.7 + melody * 0.6 + rhythm * 0.5 + bass * 0.6
        elif genre == 'dnb':
            mixed = base * 0.5 + melody * 0.5 + rhythm * 0.9 + bass * 0.8
        elif genre == 'ambient':
            mixed = base * 0.8 + melody * 0.7 + rhythm * 0.2 + bass * 0.4
        elif genre == 'techno':
            mixed = base * 0.6 + melody * 0.5 + rhythm * 0.8 + bass * 0.7
        else:
            mixed = base * 0.6 + melody * 0.5 + rhythm * 0.7 + bass * 0.7
        
        return mixed
    
    def _apply_final_processing(self, audio: np.ndarray, params: Dict) -> np.ndarray:
        """–ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É"""
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio)) * 0.8
        
        # –î–æ–±–∞–≤–ª—è–µ–º reverb –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if params.get('reverb_amount', 0) > 0.1:
            audio = self._add_reverb(audio, params['reverb_amount'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏—Å—Ç–æ—Ä—à–Ω –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∂–∞–Ω—Ä–æ–≤
        if params.get('distortion', 0) > 0.1:
            audio = self._add_distortion(audio, params['distortion'])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–Ω—Ç–∞–∂–Ω–æ–µ —Ç–µ–ø–ª–æ –¥–ª—è lofi
        if params.get('vintage_warmth', 0) > 0.1:
            audio = self._add_vintage_warmth(audio, params['vintage_warmth'])
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        audio = np.clip(audio, -1.0, 1.0)
        
        return audio
    
    def _add_reverb(self, audio: np.ndarray, amount: float) -> np.ndarray:
        """–ü—Ä–æ—Å—Ç–æ–π reverb —ç—Ñ—Ñ–µ–∫—Ç"""
        delays = [0.03, 0.05, 0.08, 0.13]
        reverb = np.copy(audio)
        
        for delay in delays:
            delay_samples = int(delay * self.sample_rate)
            if delay_samples < len(audio):
                delayed = np.roll(audio, delay_samples)
                reverb += delayed * amount * 0.3
        
        return reverb
    
    def _add_distortion(self, audio: np.ndarray, amount: float) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–∫–∏–π –¥–∏—Å—Ç–æ—Ä—à–Ω"""
        drive = 1 + amount * 5
        distorted = np.tanh(audio * drive) / drive
        return audio * (1 - amount) + distorted * amount
    
    def _add_vintage_warmth(self, audio: np.ndarray, amount: float) -> np.ndarray:
        """–î–æ–±–∞–≤–ª—è–µ–º –≤–∏–Ω—Ç–∞–∂–Ω–æ–µ —Ç–µ–ø–ª–æ"""
        # –õ–µ–≥–∫–∞—è —Å–∞—Ç—É—Ä–∞—Ü–∏—è + filtering
        warmed = np.tanh(audio * 1.2) * 0.9
        # –°–∏–º—É–ª—è—Ü–∏—è analog roll-off
        warmed = self._low_pass_filter(warmed, 12000)
        return audio * (1 - amount) + warmed * amount
    
    def _high_pass_filter(self, audio: np.ndarray, freq: float) -> np.ndarray:
        """–ü—Ä–æ—Å—Ç–æ–π high-pass —Ñ–∏–ª—å—Ç—Ä"""
        # –û—á–µ–Ω—å —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
        return audio - np.convolve(audio, np.ones(int(self.sample_rate / freq)) / int(self.sample_rate / freq), mode='same')
    
    def _low_pass_filter(self, audio: np.ndarray, freq: float) -> np.ndarray:
        """–ü—Ä–æ—Å—Ç–æ–π low-pass —Ñ–∏–ª—å—Ç—Ä"""
        # –û—á–µ–Ω—å —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
        kernel_size = max(3, int(self.sample_rate / freq))
        kernel = np.ones(kernel_size) / kernel_size
        return np.convolve(audio, kernel, mode='same')
    
    def _to_wav_bytes(self, audio: np.ndarray) -> bytes:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∞—É–¥–∏–æ –≤ WAV bytes"""
        buffer = io.BytesIO()
        sf.write(buffer, audio, self.sample_rate, format='WAV')
        return buffer.getvalue()
    
    def _create_emergency_track(self, duration: int) -> bytes:
        """–°–æ–∑–¥–∞–µ–º –∞–≤–∞—Ä–∏–π–Ω—ã–π —Ç—Ä–µ–∫ –≤ —Å–ª—É—á–∞–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏"""
        samples = int(self.sample_rate * duration)
        # –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ç—Ä–µ–∫
        t = np.linspace(0, duration, samples)
        emergency = np.sin(2 * np.pi * 440 * t) * 0.1
        emergency += np.sin(2 * np.pi * 220 * t) * 0.2
        return self._to_wav_bytes(emergency)


class MusicGenEngine:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô MusicGenEngine —Å –Ω–∞–¥–µ–∂–Ω—ã–º fallback —Ä–µ–∂–∏–º–æ–º
    """
    
    def __init__(self, model_name: str = "facebook/musicgen-medium"):
        self.logger = logging.getLogger(__name__)
        self.model = None
        self.model_name = model_name
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # –°–æ–∑–¥–∞–µ–º fallback —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä
        self.fallback_engine = None
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MusicGen (–Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è)
        self.musicgen_available = self._try_load_musicgen()
        
        if self.musicgen_available:
            self.logger.info("‚úÖ MusicGen –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        else:
            self.logger.info("‚ö†Ô∏è MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä")
    
    def _try_load_musicgen(self) -> bool:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MusicGen"""
        if not MUSICGEN_AVAILABLE:
            return False
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ fallback –º–æ–¥–µ–ª—è–º–∏
            fallback_models = [
                self.model_name,
                "facebook/musicgen-small", 
                "facebook/musicgen-medium"
            ]
            
            for model_name in fallback_models:
                try:
                    self.logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {model_name}")
                    
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –û–±—Ö–æ–¥–∏–º –ø—Ä–æ–±–ª–µ–º—É —Å signal.SIGALRM
                    import signal
                    if hasattr(signal, 'SIGALRM'):
                        # Linux/Mac - —Å–∏–≥–Ω–∞–ª—ã –¥–æ—Å—Ç—É–ø–Ω—ã
                        self.model = musicgen.MusicGen.get_pretrained(model_name)
                    else:
                        # Windows - –æ—Ç–∫–ª—é—á–∞–µ–º signal handling
                        old_signal = getattr(signal, 'alarm', None)
                        if old_signal:
                            signal.alarm = lambda x: None
                        
                        self.model = musicgen.MusicGen.get_pretrained(model_name)
                        
                        if old_signal:
                            signal.alarm = old_signal
                    
                    if self.model:
                        self.model.set_generation_params(duration=8)
                        self.model_name = model_name
                        self.logger.info(f"‚úÖ MusicGen –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_name}")
                        return True
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_name}: {e}")
                    continue
            
            return False
            
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MusicGen: {e}")
            return False
    
    async def generate(
        self,
        prompt: str,
        duration: int = 30,
        temperature: float = 1.0,
        top_k: int = 250,
        top_p: float = 0.0,
        genre_hint: Optional[str] = None
    ) -> bytes:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è - –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–ª–∏–¥–Ω–æ–µ –∞—É–¥–∏–æ
        """
        
        self.logger.info(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º: '{prompt}' ({duration}—Å, –∂–∞–Ω—Ä: {genre_hint or 'auto'})")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è MusicGen –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if self.musicgen_available and self.model:
            try:
                return await self._generate_base_composition(
                    prompt, duration, temperature, top_k, top_p, genre_hint
                )
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è MusicGen –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                self.logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º BPM –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
            bpm = self._extract_bpm_from_prompt(prompt)
            
            audio_bytes = self.fallback_engine.generate_musical_track(
                prompt=prompt,
                duration=duration, 
                genre=genre_hint,
                bpm=bpm
            )
            
            if len(audio_bytes) > 1000:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –≤–∞–ª–∏–¥–Ω–æ–µ –∞—É–¥–∏–æ
                self.logger.info(f"‚úÖ –°–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫ –≥–æ—Ç–æ–≤: {len(audio_bytes)} bytes")
                return audio_bytes
            else:
                raise RuntimeError("–°–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä –≤–µ—Ä–Ω—É–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª")
                
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä–∞: {e}")
            
            # –ü–û–°–õ–ï–î–ù–Ø–Ø –ª–∏–Ω–∏—è –∑–∞—â–∏—Ç—ã - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫
            return self._create_minimal_track(duration)
    
    async def _generate_with_musicgen(
        self,
        prompt: str,
        duration: int,
        temperature: float,
        top_k: int, 
        top_p: float,
        genre_hint: Optional[str]
    ) -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –Ω–∞—Å—Ç–æ—è—â–∏–π MusicGen"""
        
        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            safe_duration = min(duration, 30)
            
            self.model.set_generation_params(
                duration=safe_duration,
                use_sampling=True,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p
            )
            
            # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è MusicGen
            enhanced_prompt = self._enhance_prompt_for_genre(prompt, genre_hint)
            self.logger.info(f"üìù –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {enhanced_prompt}")
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
            with torch.no_grad():
                wav_tensor = self.model.generate([enhanced_prompt])
            
            if wav_tensor is None or wav_tensor.size(0) == 0:
                raise RuntimeError("MusicGen –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            
            self.logger.info(f"üîä –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä: {wav_tensor.shape}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–Ω–∑–æ—Ä
            if wav_tensor.dim() == 3:
                audio_array = wav_tensor[0].cpu().numpy()
            elif wav_tensor.dim() == 2:
                audio_array = wav_tensor.cpu().numpy()
            else:
                raise ValueError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞: {wav_tensor.shape}")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if audio_array.max() > 1.0 or audio_array.min() < -1.0:
                audio_array = audio_array / max(abs(audio_array.max()), abs(audio_array.min()))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–∏–≥–Ω–∞–ª–∞
            rms = np.sqrt(np.mean(audio_array**2))
            self.logger.info(f"üîä RMS —É—Ä–æ–≤–µ–Ω—å: {rms:.6f}")
            
            if rms < 1e-6:
                self.logger.warning("‚ö†Ô∏è –û—á–µ–Ω—å —Ç–∏—Ö–æ–µ –∞—É–¥–∏–æ, —É—Å–∏–ª–∏–≤–∞–µ–º")
                audio_array = audio_array * 1000
                audio_array = np.clip(audio_array, -1.0, 1.0)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV
            sample_rate = self.model.sample_rate
            buffer = io.BytesIO()
            
            if audio_array.ndim == 1:
                sf.write(buffer, audio_array, sample_rate, format='WAV')
            else:
                if audio_array.shape[0] == 2:
                    sf.write(buffer, audio_array.T, sample_rate, format='WAV')
                else:
                    sf.write(buffer, audio_array[0], sample_rate, format='WAV')
            
            audio_bytes = buffer.getvalue()
            buffer.close()
            
            if len(audio_bytes) < 1000:
                raise RuntimeError(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª: {len(audio_bytes)} bytes")
            
            self.logger.info(f"‚úÖ MusicGen –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(audio_bytes)} bytes")
            return audio_bytes
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ MusicGen –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            raise  # –ü–µ—Ä–µ–¥–∞–µ–º –æ—à–∏–±–∫—É –≤—ã—à–µ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ fallback
    
    def _extract_bpm_from_prompt(self, prompt: str) -> int:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º BPM –∏–∑ –ø—Ä–æ–º–ø—Ç–∞"""
        import re
        
        # –ò—â–µ–º —á–∏—Å–ª–∞ –ø–æ—Å–ª–µ "bpm" –∏–ª–∏ "BPM"
        bpm_match = re.search(r'(\d+)\s*bpm', prompt.lower())
        if bpm_match:
            return int(bpm_match.group(1))
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ BPM –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        prompt_lower = prompt.lower()
        if any(word in prompt_lower for word in ['trap', 'hip hop', 'rap']):
            return 140
        elif any(word in prompt_lower for word in ['dnb', 'drum and bass', 'jungle']):
            return 174
        elif any(word in prompt_lower for word in ['house', 'dance', 'edm']):
            return 128
        elif any(word in prompt_lower for word in ['techno', 'industrial']):
            return 130
        elif any(word in prompt_lower for word in ['lofi', 'chill', 'ambient']):
            return 80
        else:
            return 120  # –î–µ—Ñ–æ–ª—Ç
    
    def _enhance_prompt_for_genre(self, prompt: str, genre: Optional[str]) -> str:
        """–£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        if not genre:
            return prompt
        
        genre_enhancements = {
            "trap": "heavy 808s, tight snares, dark atmosphere, modern hip-hop",
            "lofi": "warm analog sound, vinyl texture, mellow vibes, nostalgic",
            "dnb": "fast breakbeats, heavy bass, energetic, electronic",
            "ambient": "ethereal pads, spacious reverb, peaceful, atmospheric",
            "techno": "driving four-on-the-floor, hypnotic, industrial, electronic",
            "house": "groovy four-on-the-floor, soulful, danceable, uplifting"
        }
        
        enhancement = genre_enhancements.get(genre, "")
        if enhancement:
            enhanced = f"{prompt}, {enhancement}"
            return enhanced
        return prompt
    
    def _create_minimal_track(self, duration: int) -> bytes:
        """–°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω—é—é –ª–∏–Ω–∏—é –∑–∞—â–∏—Ç—ã"""
        sample_rate = 44100
        samples = int(sample_rate * duration)
        
        t = np.linspace(0, duration, samples)
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π, –Ω–æ –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫
        bass = np.sin(2 * np.pi * 60 * t) * 0.4
        melody = np.sin(2 * np.pi * 440 * t) * 0.2
        harmony = np.sin(2 * np.pi * 330 * t) * 0.15
        
        # –î–æ–±–∞–≤–ª—è–µ–º envelope –¥–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
        envelope = np.exp(-t * 0.1) * 0.5 + 0.5
        
        minimal_track = (bass + melody + harmony) * envelope * 0.7
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV
        buffer = io.BytesIO()
        sf.write(buffer, minimal_track, sample_rate, format='WAV')
        return buffer.getvalue()
    
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (—Ç–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ True)"""
        return True  # –£ –Ω–∞—Å –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å fallback
    
    def get_available_models(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        models = ["enhanced_synthesizer"]  # –ù–∞—à fallback –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω
        
        if self.musicgen_available:
            models.extend([
                "facebook/musicgen-small",
                "facebook/musicgen-medium", 
                "facebook/musicgen-large"
            ])
        
        return models
    
    def set_model(self, model_name: str) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if model_name == "enhanced_synthesizer":
            # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä
            self.musicgen_available = False
            self.logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ enhanced_synthesizer")
            return True
        elif MUSICGEN_AVAILABLE:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é MusicGen –º–æ–¥–µ–ª—å
            old_model = self.model
            self.model = None
            self.model_name = model_name
            
            if self._try_load_musicgen():
                self.logger.info(f"‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ MusicGen: {model_name}")
                return True
            else:
                self.model = old_model  # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ {model_name}")
                return False
        else:
            self.logger.warning(f"‚ö†Ô∏è MusicGen –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ synthesizer")
            return False


# === –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –£–¢–ò–õ–ò–¢–´ ===

def test_musicgen_engine():
    """–¢–µ—Å—Ç–∏—Ä—É–µ–º MusicGen –¥–≤–∏–∂–æ–∫"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º MusicGen Engine...")
    
    engine = MusicGenEngine()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
    print(f"–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å: {engine.is_available()}")
    print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {engine.get_available_models()}")
    print(f"MusicGen –¥–æ—Å—Ç—É–ø–µ–Ω: {engine.musicgen_available}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    import asyncio
    
    async def test_generation():
        try:
            print("\nüéµ –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
            audio_bytes = await engine.generate(
                prompt="aggressive trap beat 140bpm",
                duration=10,
                genre_hint="trap"
            )
            
            print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {len(audio_bytes)} bytes")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            with open("test_output.wav", "wb") as f:
                f.write(audio_bytes)
            print("üíæ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: test_output.wav")
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")
            return False
    
    result = asyncio.run(test_generation())
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞: {'‚úÖ –£–°–ü–ï–®–ù–û' if result else '‚ùå –û–®–ò–ë–ö–ê'}")
    
    return result


def create_test_batch():
    """–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Å–µ—Ö –∂–∞–Ω—Ä–æ–≤"""
    print("üé≠ –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –≤—Å–µ—Ö –∂–∞–Ω—Ä–æ–≤...")
    
    engine = MusicGenEngine()
    
    test_prompts = [
        ("trap", "dark aggressive trap 160bpm with heavy 808s"),
        ("lofi", "chill lofi study beats with vinyl crackle"),
        ("dnb", "energetic drum and bass 174bpm breakbeats"),
        ("ambient", "ethereal ambient soundscape peaceful"),
        ("techno", "driving techno 130bpm industrial"),
        ("house", "groovy house 128bpm soulful")
    ]
    
    import asyncio
    
    async def generate_all():
        results = {}
        
        for genre, prompt in test_prompts:
            try:
                print(f"\nüéµ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º {genre}: '{prompt}'")
                
                audio_bytes = await engine.generate(
                    prompt=prompt,
                    duration=15,
                    genre_hint=genre
                )
                
                filename = f"test_{genre}.wav"
                with open(filename, "wb") as f:
                    f.write(audio_bytes)
                
                results[genre] = {"success": True, "file": filename, "size": len(audio_bytes)}
                print(f"‚úÖ {genre}: {len(audio_bytes)} bytes -> {filename}")
                
            except Exception as e:
                results[genre] = {"success": False, "error": str(e)}
                print(f"‚ùå {genre}: {e}")
        
        return results
    
    results = asyncio.run(generate_all())
    
    # –û—Ç—á–µ—Ç
    print(f"\nüìä –û–¢–ß–ï–¢ –ü–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ:")
    successful = sum(1 for r in results.values() if r.get("success"))
    print(f"–£—Å–ø–µ—à–Ω–æ: {successful}/{len(test_prompts)}")
    
    for genre, result in results.items():
        if result.get("success"):
            print(f"‚úÖ {genre}: {result['file']} ({result['size']} bytes)")
        else:
            print(f"‚ùå {genre}: {result.get('error', 'unknown error')}")
    
    return results


# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
musicgen_engine = MusicGenEngine()

if __name__ == "__main__":
    # –ê–≤—Ç–æ—Ç–µ—Å—Ç –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    print("üöÄ MusicGen Wrapper - –ê–≤—Ç–æ—Ç–µ—Å—Ç")
    print("=" * 50)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç
    basic_test = test_musicgen_engine()
    
    if basic_test:
        print("\nüé≠ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ—Ö –∂–∞–Ω—Ä–æ–≤...")
        batch_results = create_test_batch()
        
        successful_genres = sum(1 for r in batch_results.values() if r.get("success"))
        print(f"\nüéâ –ò–¢–û–ì–û: {successful_genres}/6 –∂–∞–Ω—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç!")
        
        if successful_genres == 6:
            print("‚úÖ –í–°–Å –†–ê–ë–û–¢–ê–ï–¢ –ò–î–ï–ê–õ–¨–ù–û!")
        elif successful_genres >= 4:
            print("üëç –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∂–∞–Ω—Ä–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ")
        else:
            print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, –Ω–æ –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞")
    
    else:
        print("‚ùå –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç –Ω–µ –ø—Ä–æ—à–µ–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π.")
    
    print("\nüèÅ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
