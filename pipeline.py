# pipeline.py - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –º–æ–¥—É–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å —Ä–µ–∞–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∞—É–¥–∏–æ
import os
import io
import asyncio
import logging
import time
import random
import requests
from pydub import AudioSegment
from pydub.generators import Sine, Square, WhiteNoise
from pydub.effects import normalize
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import json

from config import config, GenreType, MasteringPurpose
from mistral_client import query_structured_music
from metadata import MetadataProcessor
from sample_engine import SemanticSampleEngine
from musicgen_wrapper import MusicGenEngine
from mastering import SmartMasteringEngine
from verification import MixVerifier
from sample_engine import EffectsChain
from export import ExportManager


@dataclass
class GenerationRequest:
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç—Ä–µ–∫–∞"""
    prompt: str
    genre: Optional[str] = None
    bpm: Optional[int] = None
    duration: Optional[int] = None
    mastering_purpose: str = "personal"
    output_dir: str = "output"
    export_stems: bool = True
    custom_structure: Optional[List[Dict]] = None
    sample_tags: Optional[List[str]] = None
    energy_level: float = 0.5
    creativity_factor: float = 0.7

@dataclass 
class GenerationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ–∫–∞"""
    success: bool
    final_path: Optional[str] = None
    structure_data: Optional[Dict] = None
    used_samples: Optional[List[Dict]] = None
    mastering_config: Optional[Dict] = None
    mastering_report: Optional[Dict] = None
    generation_time: float = 0.0
    quality_score: float = 0.0
    error_message: Optional[str] = None
    intermediate_files: Optional[Dict[str, str]] = None


class WaveDreamPipeline:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ pipeline –¥–ª—è WaveDream Enhanced Pro
    
    –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - –†–µ–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–µ–∫
    - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å MusicGen
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
    - –£–±—Ä–∞–Ω—ã –∑–∞–≥–ª—É—à–∫–∏ —Å —Ç–∏—à–∏–Ω–æ–π
    - –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ—ç—Ç–∞–ø–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    """
    
    def __init__(self):
        self.metadata_processor = MetadataProcessor()
        self.sample_engine = SemanticSampleEngine()
        self.musicgen_engine = MusicGenEngine()
        self.mastering_engine = SmartMasteringEngine()
        self.verifier = MixVerifier()
        self.effects_chain = EffectsChain()
        self.export_manager = ExportManager()
        
        self.logger = logging.getLogger(__name__)
        self._performance_stats = {}
        
        # –î–ª—è –ø–æ—ç—Ç–∞–ø–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self._current_project_name = None
        self._intermediate_storage = {}
        
    async def generate_track(self, request: GenerationRequest) -> GenerationResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ–∫–∞"""
        start_time = time.time()
        
        try:
            self.logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
            env_checks = self.export_manager.check_export_environment()

            critical_checks = ["base_dir_writable", "sufficient_space", "pydub_working"]
            failed_critical = [check for check in critical_checks if not env_checks.get(check, False)]

            if failed_critical:
                error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã: {', '.join(failed_critical)}"
                self.logger.error(f"‚ùå {error_msg}")
                return GenerationResult(
                    success=False,
                    error_message=error_msg,
                    generation_time=time.time() - start_time
                )
            
            # –°–æ–∑–¥–∞—ë–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞
            timestamp = int(time.time())
            self._current_project_name = f"WD_Project_{timestamp}"
            
            self.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é: '{request.prompt}'")
            self.logger.info(f"üìÅ –ü—Ä–æ–µ–∫—Ç: {self._current_project_name}")
            self.logger.info(f"üéØ –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ: {request.mastering_purpose}")
            
            # === 1. PREPARE METADATA ===
            self.logger.info("üìã –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
            metadata = await self._step_prepare_metadata(request)
            
            # === 2. GENRE DETECTION ===
            self.logger.info("üé≠ –≠—Ç–∞–ø 2: –î–µ—Ç–µ–∫—Ü–∏—è –∂–∞–Ω—Ä–∞")
            genre_info = await self._step_detect_genre(request, metadata)
            
            # === 3. STRUCTURE GENERATION ===
            self.logger.info("üèóÔ∏è –≠—Ç–∞–ø 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
            structure = await self._step_generate_structure(request, metadata, genre_info)
            
            # === 4. SAMPLE SELECTION ===
            self.logger.info("üîç –≠—Ç–∞–ø 4: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä —Å—ç–º–ø–ª–æ–≤")
            selected_samples = await self._step_select_samples(request, metadata, genre_info, structure)
            
            # === 5. BASE GENERATION + –°–û–•–†–ê–ù–ï–ù–ò–ï - –ò–°–ü–†–ê–í–õ–ï–ù–û ===
            self.logger.info("üéº –≠—Ç–∞–ø 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤—ã MusicGen")
            base_audio_bytes = await self._step_generate_base_FIXED(request, metadata, genre_info, structure)
            
            # –ü–û–≠–¢–ê–ü–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï: –ë–∞–∑–æ–≤–∞—è –¥–æ—Ä–æ–∂–∫–∞
            base_path = await self._save_intermediate_audio("01_base_generated", base_audio_bytes)
            if base_path:
                self._intermediate_storage["base"] = base_path
                self.logger.info(f"  üíæ –ë–∞–∑–æ–≤–∞—è –¥–æ—Ä–æ–∂–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {base_path}")
            
            # === 6. STEM CREATION + –°–û–•–†–ê–ù–ï–ù–ò–ï - –ò–°–ü–†–ê–í–õ–ï–ù–û ===
            self.logger.info("üéõÔ∏è –≠—Ç–∞–ø 6: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–º–æ–≤")
            stems_bytes = await self._step_create_stems_FIXED(selected_samples, structure, genre_info)
            
            # –ü–û–≠–¢–ê–ü–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï: –ö–∞–∂–¥—ã–π —Å—Ç–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
            stem_paths = {}
            for instrument, stem_bytes in stems_bytes.items():
                stem_path = await self._save_stem_audio(f"stem_{instrument}", stem_bytes)
                if stem_path:
                    stem_paths[instrument] = stem_path
                    self.logger.info(f"  üíæ –°—Ç–µ–º '{instrument}' —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {stem_path}")
            
            self._intermediate_storage["stems"] = stem_paths
            
            # === 7. MIXING + –°–û–•–†–ê–ù–ï–ù–ò–ï - –ò–°–ü–†–ê–í–õ–ï–ù–û ===
            self.logger.info("üéöÔ∏è –≠—Ç–∞–ø 7: –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ")
            mixed_audio_bytes = await self._step_mix_tracks_FIXED(base_audio_bytes, stems_bytes, genre_info)
            
            # –ü–û–≠–¢–ê–ü–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï: –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
            mixed_path = await self._save_intermediate_audio("02_mixed", mixed_audio_bytes)
            if mixed_path:
                self._intermediate_storage["mixed"] = mixed_path
                self.logger.info(f"  üíæ –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {mixed_path}")
            
            # === 8. EFFECTS + –°–û–•–†–ê–ù–ï–ù–ò–ï - –ò–°–ü–†–ê–í–õ–ï–ù–û ===
            self.logger.info("‚ú® –≠—Ç–∞–ø 8: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤")
            processed_audio_bytes = await self._step_apply_effects_FIXED(mixed_audio_bytes, metadata, genre_info)
            
            # –ü–û–≠–¢–ê–ü–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï: –í–µ—Ä—Å–∏—è —Å —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏
            processed_path = await self._save_intermediate_audio("03_effects_applied", processed_audio_bytes)
            if processed_path:
                self._intermediate_storage["processed"] = processed_path
                self.logger.info(f"  üíæ –í–µ—Ä—Å–∏—è —Å —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {processed_path}")
            
            # === 9. MASTERING + –°–û–•–†–ê–ù–ï–ù–ò–ï - –ò–°–ü–†–ê–í–õ–ï–ù–û ===
            self.logger.info("üéõÔ∏è –≠—Ç–∞–ø 9: –£–º–Ω—ã–π –º–∞—Å—Ç–µ—Ä–∏–Ω–≥")
            mastered_audio_bytes, mastering_config, mastering_report = await self._step_master_track_FIXED(
                processed_audio_bytes, request.mastering_purpose, genre_info
            )
            
            # –ü–û–≠–¢–ê–ü–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï: –§–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Å—Ç–µ—Ä
            final_path = await self._save_final_audio(mastered_audio_bytes)
            if final_path:
                self._intermediate_storage["final"] = final_path
                self.logger.info(f"  üíæ –§–∏–Ω–∞–ª—å–Ω—ã–π –º–∞—Å—Ç–µ—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {final_path}")
            
            # === 10. VERIFICATION ===
            self.logger.info("üîç –≠—Ç–∞–ø 10: –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞")
            quality_report = await self._step_verify_quality_FIXED(mastered_audio_bytes, mastering_config)
            
            # === 11. EXPORT + –ú–ï–¢–ê–î–ê–ù–ù–´–ï ===
            self.logger.info("üíæ –≠—Ç–∞–ø 11: –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
            exported_files = await self._step_export_results_FIXED(
                request, mastered_audio_bytes, structure, selected_samples, mastering_config,
                {
                    "base": base_audio_bytes,
                    "stems": stems_bytes, 
                    "mixed": mixed_audio_bytes,
                    "processed": processed_audio_bytes
                }
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞
            project_metadata = {
                "project_name": self._current_project_name,
                "request": self._serialize_request(request),
                "structure": structure,
                "selected_samples": selected_samples,
                "mastering_config": mastering_config,
                "quality_report": quality_report,
                "intermediate_files": self._intermediate_storage,
                "generation_stats": self._performance_stats
            }
            
            try:
                metadata_path = await self._save_project_metadata(project_metadata)
                self.logger.info(f"üìã –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            
            generation_time = time.time() - start_time
            self._performance_stats["total_time"] = generation_time
            
            result = GenerationResult(
                success=True,
                final_path=final_path or exported_files.get("final"),
                structure_data=structure,
                used_samples=selected_samples,
                mastering_config=mastering_config,
                mastering_report=mastering_report,
                generation_time=generation_time,
                quality_score=quality_report.get("overall_score", 0.0),
                intermediate_files={**self._intermediate_storage, **exported_files}
            )
            
            self.logger.info(f"üéâ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {generation_time:.1f}—Å")
            self.logger.info(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.2f}/1.0")
            self.logger.info(f"üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(result.intermediate_files)}")
            
            return result
            
        except Exception as e:
            generation_time = time.time() - start_time
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            
            return GenerationResult(
                success=False,
                generation_time=generation_time,
                error_message=str(e),
                intermediate_files=self._intermediate_storage
            )
    
    # === –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –≠–¢–ê–ü–´ PIPELINE ===
    
    async def _step_generate_base_FIXED(
        self, request: GenerationRequest, metadata: Dict, 
        genre_info: Dict, structure: Dict
    ) -> bytes:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å–Ω–æ–≤—ã —á–µ—Ä–µ–∑ MusicGen –∏–ª–∏ fallback"""
        start_time = time.time()
        
        # –°–æ–∑–¥–∞—ë–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è MusicGen
        enhanced_prompt = self._create_musicgen_prompt(
            request.prompt, genre_info, metadata
        )
        
        duration = structure["total_duration"]
        
        self.logger.info(f"  üéº MusicGen –ø—Ä–æ–º–ø—Ç: '{enhanced_prompt[:100]}...'")
        self.logger.info(f"  ‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}—Å")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ MusicGen
        try:
            if self.musicgen_engine.MUSICGEN_AVAILABLE:
                base_audio_bytes = await self.musicgen_engine.generate(
                    prompt=enhanced_prompt,
                    duration=duration,
                    temperature=metadata.get("creativity_factor", 0.7),
                    genre_hint=genre_info["name"]
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç MusicGen
                if base_audio_bytes and len(base_audio_bytes) > 1000:
                    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–∏—à–∏–Ω–∞
                    test_audio = AudioSegment.from_file(io.BytesIO(base_audio_bytes))
                    if test_audio.max_dBFS > float('-inf'):
                        processing_time = time.time() - start_time
                        self._performance_stats["musicgen_time"] = processing_time
                        
                        self.logger.info(f"  üéº MusicGen SUCCESS: {len(base_audio_bytes)} bytes")
                        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
                        
                        return base_audio_bytes
            
            # –ï—Å–ª–∏ MusicGen –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
            raise Exception("MusicGen –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            
        except Exception as e:
            self.logger.warning(f"  ‚ö†Ô∏è MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô fallback")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π fallback –≤–º–µ—Å—Ç–æ —Ç–∏—à–∏–Ω—ã
            base_audio_bytes = await self._generate_quality_fallback_audio(
                duration, genre_info, metadata
            )
            
            processing_time = time.time() - start_time
            self._performance_stats["musicgen_time"] = processing_time
            
            self.logger.info(f"  üéº Quality Fallback: {len(base_audio_bytes)} bytes")
            self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
            
            return base_audio_bytes

    async def _generate_quality_fallback_audio(
        self, duration: float, genre_info: Dict, metadata: Dict
    ) -> bytes:
        """–í–´–°–û–ö–û–ö–ê–ß–ï–°–¢–í–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è fallback –∞—É–¥–∏–æ - –ù–ï –¢–ò–®–ò–ù–ê!"""
        
        try:
            genre_name = genre_info.get('name', 'generic').lower()
            bpm = genre_info.get('target_bpm', 120)
            energy_level = metadata.get('energy_level', 0.5)
            
            self.logger.info(f"    üéµ –°–æ–∑–¥–∞—ë–º fallback: {genre_name}, {bpm}BPM, —ç–Ω–µ—Ä–≥–∏—è {energy_level}")
            
            duration_ms = int(duration * 1000)
            
            # –°–æ–∑–¥–∞—ë–º –±–∞–∑–æ–≤—ã–π —Ä–∏—Ç–º
            rhythm_audio = self._create_comprehensive_rhythm(duration_ms, genre_info, metadata)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ–ª–æ–¥–∏—á–µ—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            melody_audio = self._create_melody_layer(duration_ms, genre_info, metadata)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –±–∞—Å–æ–≤—É—é –ª–∏–Ω–∏—é
            bass_audio = self._create_bass_layer(duration_ms, genre_info, metadata)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            atmosphere_audio = self._create_atmosphere_layer(duration_ms, genre_info)
            
            # –ú–∏–∫—à–∏—Ä—É–µ–º –≤—Å–µ —Å–ª–æ–∏
            final_audio = rhythm_audio
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª–æ–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏
            if len(melody_audio) > 0:
                final_audio = final_audio.overlay(melody_audio.apply_gain(-3))
            
            if len(bass_audio) > 0:
                final_audio = final_audio.overlay(bass_audio.apply_gain(-1))
                
            if len(atmosphere_audio) > 0:
                final_audio = final_audio.overlay(atmosphere_audio.apply_gain(-8))
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            final_audio = normalize(final_audio, headroom=2.0)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º fade in/out –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
            fade_ms = min(1000, duration_ms // 10)
            final_audio = final_audio.fade_in(fade_ms).fade_out(fade_ms)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            final_audio.export(buffer, format="wav")
            audio_bytes = buffer.getvalue()
            buffer.close()
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Ç–∏—à–∏–Ω–∞
            if len(audio_bytes) < 1000:
                raise ValueError("Generated fallback audio is too small!")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ —Ç–∏—à–∏–Ω–∞
            test_audio = AudioSegment.from_file(io.BytesIO(audio_bytes))
            if test_audio.max_dBFS == float('-inf'):
                raise ValueError("Generated fallback audio is completely silent!")
            
            self.logger.info(f"    ‚úÖ Quality fallback –≥–æ—Ç–æ–≤: {len(audio_bytes)} bytes, "
                           f"–ø–∏–∫: {test_audio.max_dBFS:.1f}dB")
            
            return audio_bytes
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è quality fallback: {e}")
            
            # –≠–ö–°–¢–†–ï–ù–ù–´–ô fallback - –Ω–æ –ù–ï –¢–ò–®–ò–ù–ê!
            emergency_audio = self._create_emergency_audio(duration_ms)
            buffer = io.BytesIO()
            emergency_audio.export(buffer, format="wav")
            emergency_bytes = buffer.getvalue()
            buffer.close()
            
            self.logger.warning(f"üö® –≠–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π fallback: {len(emergency_bytes)} bytes")
            return emergency_bytes

    def _create_comprehensive_rhythm(
        self, duration_ms: int, genre_info: Dict, metadata: Dict
    ) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ä–∏—Ç–º–∞ —Å —É—á–µ—Ç–æ–º –∂–∞–Ω—Ä–∞"""
        
        genre_name = genre_info.get('name', 'generic').lower()
        bpm = genre_info.get('target_bpm', 120)
        energy_level = metadata.get('energy_level', 0.5)
        
        beat_duration = int(60000 / bmp)  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ–ø–µ—á–∞—Ç–∫–∞: bmp -> bpm
        bars_needed = (duration_ms // (beat_duration * 4)) + 1
        
        # –°–æ–∑–¥–∞—ë–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Å –ª—É—á—à–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
        kick_freq = 50 if genre_name == 'trap' else 60
        kick = Sine(kick_freq).to_audio_segment(duration=300)
        kick = kick.apply_gain(2 + energy_level * 6)  # –ë–æ–ª–µ–µ —Å–∏–ª—å–Ω—ã–π kick
        
        # –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π snare
        snare_base = WhiteNoise().to_audio_segment(duration=200)
        snare_tone = Sine(200).to_audio_segment(duration=200)  # –¢–æ–Ω–∞–ª—å–Ω–∞—è —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è
        snare = snare_base.overlay(snare_tone.apply_gain(-6))
        snare = snare.band_pass_filter(150, 6000)
        snare = snare.apply_gain(-2 + energy_level * 6)
        
        # Hi-hat —Å –ª—É—á—à–∏–º –∑–≤—É–∫–æ–º
        hihat_base = WhiteNoise().to_audio_segment(duration=80)
        hihat = hihat_base.high_pass_filter(6000)
        hihat = hihat.apply_gain(-8 + energy_level * 4)
        
        # –ñ–∞–Ω—Ä–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—É–ª—É—á—à–µ–Ω–Ω—ã–µ)
        patterns = {
            'trap': {
                'kick':  [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0],  # 16-step pattern
                'snare': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
                'hihat': [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1],
            },
            'house': {
                'kick':  [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],
                'snare': [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0],
                'hihat': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],
            },
            'dnb': {
                'kick':  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                'snare': [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0],
                'hihat': [1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1],
            }
        }
        
        pattern = patterns.get(genre_name, patterns.get('trap', patterns['trap']))
        
        # –°–æ–∑–¥–∞—ë–º –æ–¥–∏–Ω bar
        step_duration = beat_duration // 4  # 16-step sequencer
        bar = AudioSegment.silent(duration=beat_duration * 4)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
        for inst_name, inst_pattern in pattern.items():
            sound = locals()[inst_name]
            
            for i, hit in enumerate(inst_pattern):
                if hit:
                    pos = i * step_duration
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è —Ä–µ–∞–ª–∏–∑–º–∞
                    if random.random() < 0.1:  # 10% —à–∞–Ω—Å –Ω–∞ variation
                        varied_sound = sound.apply_gain(random.randint(-3, 3))
                        bar = bar.overlay(varied_sound, position=pos)
                    else:
                        bar = bar.overlay(sound, position=pos)
        
        # –°–æ–∑–¥–∞—ë–º –ø–æ–ª–Ω—ã–π —Ç—Ä–µ–∫ –∏–∑ bars —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏
        rhythm = AudioSegment.silent(duration=0)
        
        for bar_num in range(bars_needed):
            current_bar = bar
            
            # –î–æ–±–∞–≤–ª—è–µ–º fills –∏ –≤–∞—Ä–∏–∞—Ü–∏–∏
            if bar_num > 0 and bar_num % 4 == 3:  # –ö–∞–∂–¥—ã–π 4-–π bar - fill
                fill_snare = snare.apply_gain(-3)
                for fill_pos in [beat_duration * 3 + step_duration * 2, beat_duration * 3 + step_duration * 3]:
                    current_bar = current_bar.overlay(fill_snare, position=fill_pos)
            
            rhythm += current_bar
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏–Ω—ã
        rhythm = rhythm[:duration_ms]
        
        return rhythm

    def _create_melody_layer(
        self, duration_ms: int, genre_info: Dict, metadata: Dict
    ) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ–ª–æ–¥–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ—è"""
        
        genre_name = genre_info.get('name', 'generic').lower()
        bpm = genre_info.get('target_bpm', 120)
        energy_level = metadata.get('energy_level', 0.5)
        
        # –°–æ–∑–¥–∞—ë–º –±–∞–∑–æ–≤—É—é –º–µ–ª–æ–¥–∏—é
        melody = AudioSegment.silent(duration=duration_ms)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ—Ç—ã –¥–ª—è –∂–∞–Ω—Ä–∞
        scales = {
            'trap': [220, 246.94, 261.63, 329.63, 369.99],  # A minor pentatonic
            'house': [261.63, 293.66, 329.63, 349.23, 392.00],  # C major
            'ambient': [130.81, 146.83, 164.81, 196.00, 220.00],  # Lower frequencies
            'dnb': [220, 246.94, 277.18, 329.63, 369.99]  # A minor
        }
        
        scale = scales.get(genre_name, scales['trap'])
        
        # –°–æ–∑–¥–∞—ë–º –º–µ–ª–æ–¥–∏—á–µ—Å–∫–∏–µ —Ñ—Ä–∞–∑—ã
        phrase_length = int(60000 / bpm * 2)  # 2 bar phrases
        
        current_pos = 0
        while current_pos < duration_ms:
            # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –Ω–æ—Ç—É –∏–∑ –≥–∞–º–º—ã
            note_freq = random.choice(scale)
            note_duration = random.randint(200, 800)  # –î–ª–∏–Ω–∞ –Ω–æ—Ç—ã
            
            # –°–æ–∑–¥–∞—ë–º –Ω–æ—Ç—É —Å envelope
            note = Sine(note_freq).to_audio_segment(duration=note_duration)
            note = note.fade_in(50).fade_out(100)  # ADSR envelope
            note = note.apply_gain(-12 + energy_level * 6)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∫ –º–µ–ª–æ–¥–∏–∏
            if current_pos + len(note) <= duration_ms:
                melody = melody.overlay(note, position=current_pos)
            
            current_pos += note_duration + random.randint(100, 400)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –Ω–æ—Ç–∞–º–∏
        
        return melody

    def _create_bass_layer(
        self, duration_ms: int, genre_info: Dict, metadata: Dict
    ) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞—Å–æ–≤–æ–π –ª–∏–Ω–∏–∏"""
        
        genre_name = genre_info.get('name', 'generic').lower()
        bpm = genre_info.get('target_bpm', 120)
        
        bass_notes = {
            'trap': [55, 65.41, 73.42],  # A1, C2, D2
            'house': [41.20, 49.00, 55.00],  # E1, G1, A1
            'dnb': [55, 61.74, 65.41]  # A1, B1, C2
        }
        
        notes = bass_notes.get(genre_name, bass_notes['trap'])
        
        bass = AudioSegment.silent(duration=duration_ms)
        beat_duration = int(60000 / bpm)
        
        # –°–æ–∑–¥–∞—ë–º –±–∞—Å–æ–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
        bass_pattern_length = beat_duration * 4  # 1 bar
        current_pos = 0
        
        while current_pos < duration_ms:
            # –í—ã–±–∏—Ä–∞–µ–º –Ω–æ—Ç—É
            note_freq = random.choice(notes)
            
            # –°–æ–∑–¥–∞—ë–º –±–∞—Å–æ–≤—É—é –Ω–æ—Ç—É (–¥–ª–∏–Ω–Ω–∞—è —Å —Å—É—Å—Ç–µ–π–Ω–æ–º)
            bass_note = Sine(note_freq).to_audio_segment(duration=beat_duration)
            bass_note = bass_note.apply_gain(-6)  # –ë–∞—Å–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–≥–∏–±–∞—é—â—É—é
            bass_note = bass_note.fade_in(10).fade_out(100)
            
            if current_pos + len(bass_note) <= duration_ms:
                bass = bass.overlay(bass_note, position=current_pos)
            
            current_pos += bass_pattern_length
        
        return bass

    def _create_atmosphere_layer(
        self, duration_ms: int, genre_info: Dict
    ) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω–æ–≥–æ —Å–ª–æ—è"""
        
        genre_name = genre_info.get('name', 'generic').lower()
        
        if genre_name in ['ambient', 'cinematic']:
            # –°–æ–∑–¥–∞—ë–º pad –∑–≤—É–∫–∏
            pad_freq = 220  # A3
            pad = Sine(pad_freq).to_audio_segment(duration=duration_ms)
            pad = pad.apply_gain(-15)  # –¢–∏—Ö–∏–π —É—Ä–æ–≤–µ–Ω—å –¥–ª—è –∞—Ç–º–æ—Å—Ñ–µ—Ä—ã
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥—É–ª—è—Ü–∏—é (–ø—Ä–æ—Å—Ç—É—é)
            return pad.fade_in(2000).fade_out(2000)
        
        elif genre_name in ['lofi']:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–Ω—Ç–∞–∂–Ω—ã–µ –∑–≤—É–∫–∏
            vinyl_noise = WhiteNoise().to_audio_segment(duration=duration_ms)
            vinyl_noise = vinyl_noise.apply_gain(-25)  # –û—á–µ–Ω—å —Ç–∏—Ö–æ
            vinyl_noise = vinyl_noise.low_pass_filter(3000)  # –í–∏–Ω—Ç–∞–∂–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            return vinyl_noise
        
        else:
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∂–∞–Ω—Ä–æ–≤
            return AudioSegment.silent(duration=100)

    def _create_emergency_audio(self, duration_ms: int) -> AudioSegment:
        """–≠–ö–°–¢–†–ï–ù–ù–´–ô fallback - –ø—Ä–æ—Å—Ç–æ–π –Ω–æ –ù–ï –¢–ò–®–ò–ù–ê"""
        
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–π —Å–∏–Ω—É—Å–æ–∏–¥–∞–ª—å–Ω—ã–π —Ç–æ–Ω —Å —Ä–∏—Ç–º–æ–º
        base_tone = Sine(440).to_audio_segment(duration=duration_ms)
        base_tone = base_tone.apply_gain(-20)  # –¢–∏—Ö–∏–π —É—Ä–æ–≤–µ–Ω—å
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ä–∏—Ç–º
        beat_length = 500  # 500ms beats
        rhythm = AudioSegment.silent(duration=0)
        
        current_pos = 0
        while current_pos < duration_ms:
            if (current_pos // beat_length) % 2 == 0:  # –ö–∞–∂–¥—ã–π –≤—Ç–æ—Ä–æ–π beat
                beat_tone = Sine(220).to_audio_segment(duration=200)
                beat_tone = beat_tone.apply_gain(-10)
                base_tone = base_tone.overlay(beat_tone, position=current_pos)
            current_pos += beat_length
        
        return base_tone.fade_in(1000).fade_out(1000)

    async def _step_create_stems_FIXED(
        self, selected_samples: List[Dict], structure: Dict, genre_info: Dict
    ) -> Dict[str, bytes]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–º–æ–≤ –∏–∑ —Å—ç–º–ø–ª–æ–≤"""
        start_time = time.time()
        
        stems_bytes = {}
        total_duration_ms = int(structure["total_duration"] * 1000)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å—ç–º–ø–ª—ã –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
        instrument_groups = {}
        for sample in selected_samples:
            instrument = sample.get("instrument_role", "unknown")
            if instrument not in instrument_groups:
                instrument_groups[instrument] = []
            instrument_groups[instrument].append(sample)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–µ–º–ø–ª–æ–≤, —Å–æ–∑–¥–∞—ë–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç–µ–º—ã
        if not instrument_groups:
            self.logger.info("  üéõÔ∏è –°—ç–º–ø–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞—ë–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç–µ–º—ã")
            instrument_groups = {
                "kick": [],
                "snare": [],
                "hihat": [],
                "bass": []
            }
        
        # –°–æ–∑–¥–∞—ë–º —Å—Ç–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        for instrument, samples in instrument_groups.items():
            self.logger.info(f"  üéõÔ∏è –°–æ–∑–¥–∞—ë–º —Å—Ç–µ–º: {instrument} ({len(samples)} —Å—ç–º–ø–ª–æ–≤)")
            
            stem_audio_segment = await self._create_instrument_stem_FIXED(
                instrument, samples, structure, total_duration_ms, genre_info
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            stem_audio_segment.export(buffer, format="wav")
            stem_bytes = buffer.getvalue()
            buffer.close()
            
            stems_bytes[instrument] = stem_bytes
            self.logger.info(f"    ‚úÖ –°—Ç–µ–º '{instrument}': {len(stem_bytes)} bytes")
        
        processing_time = time.time() - start_time
        self._performance_stats["stems_creation_time"] = processing_time
        
        self.logger.info(f"  üéõÔ∏è –í—Å–µ–≥–æ —Å—Ç–µ–º–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(stems_bytes)}")
        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
        
        return stems_bytes

    async def _create_instrument_stem_FIXED(
        self, instrument: str, samples: List[Dict], structure: Dict,
        total_duration_ms: int, genre_info: Dict
    ) -> AudioSegment:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–º–∞ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""

        try:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—ç–º–ø–ª—ã, –ø—ã—Ç–∞–µ–º—Å—è –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
            if samples:
                try:
                    sample_path = samples[0].get('path', samples[0].get('filename', ''))
                    if sample_path and os.path.exists(sample_path):
                        base_sample = AudioSegment.from_file(sample_path)
                        
                        # –ü–æ–≤—Ç–æ—Ä—è–µ–º —Å—ç–º–ø–ª –Ω–∞ –≤—Å—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                        repetitions = total_duration_ms // len(base_sample) + 1
                        repeated_sample = base_sample * repetitions
                        repeated_sample = repeated_sample[:total_duration_ms]
                        
                        return repeated_sample

                except Exception as e:
                    self.logger.warning(f"Could not load sample: {e}")
            
            # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            stem_audio = self._create_synthetic_instrument_stem(
                instrument, total_duration_ms, genre_info
            )
            
            return stem_audio

        except Exception as e:
            self.logger.error(f"Error creating stem for {instrument}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∑–≤—É–∫ –≤–º–µ—Å—Ç–æ —Ç–∏—à–∏–Ω—ã
            return self._create_minimal_instrument_sound(instrument, total_duration_ms)

    def _create_synthetic_instrument_stem(
        self, instrument: str, duration_ms: int, genre_info: Dict
    ) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ç–µ–º–∞"""
        
        bpm = genre_info.get('target_bpm', 120)
        energy_level = genre_info.get('energy_level', 0.5)
        genre_name = genre_info.get('name', 'generic').lower()
        
        beat_duration = int(60000 / bpm)
        step_duration = beat_duration // 4
        
        if instrument == "kick":
            return self._create_kick_stem(duration_ms, beat_duration, energy_level, genre_name)
        elif instrument == "snare":
            return self._create_snare_stem(duration_ms, beat_duration, step_duration, energy_level, genre_name)
        elif instrument == "hihat":
            return self._create_hihat_stem(duration_ms, step_duration, energy_level, genre_name)
        elif instrument == "bass":
            return self._create_bass_stem(duration_ms, beat_duration, energy_level, genre_name)
        else:
            return self._create_generic_stem(instrument, duration_ms, beat_duration)

    def _create_kick_stem(self, duration_ms: int, beat_duration: int, energy_level: float, genre: str) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ kick —Å—Ç–µ–º–∞"""
        kick_freq = 50 if genre == 'trap' else 60
        kick = Sine(kick_freq).to_audio_segment(duration=200)
        kick = kick.apply_gain(-3 + energy_level * 8)
        
        stem = AudioSegment.silent(duration=duration_ms)
        
        # Kick pattern –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∂–∞–Ω—Ä–∞
        if genre == 'trap':
            pattern = [1, 0, 0, 1, 0, 0, 1, 0]  # Trap kick pattern
        elif genre == 'house':
            pattern = [1, 0, 0, 0] * 2  # Four on the floor
        else:
            pattern = [1, 0, 1, 0, 1, 0, 0, 0]  # Generic
        
        current_pos = 0
        while current_pos < duration_ms:
            for i, hit in enumerate(pattern):
                pos = current_pos + (i * beat_duration // 2)
                if hit and pos < duration_ms:
                    stem = stem.overlay(kick, position=pos)
            current_pos += beat_duration * 4  # One bar
        
        return stem

    def _create_snare_stem(self, duration_ms: int, beat_duration: int, step_duration: int, energy_level: float, genre: str) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ snare —Å—Ç–µ–º–∞"""
        snare_base = WhiteNoise().to_audio_segment(duration=150)
        snare_tone = Sine(200).to_audio_segment(duration=150)
        snare = snare_base.overlay(snare_tone.apply_gain(-6))
        snare = snare.band_pass_filter(150, 6000)
        snare = snare.apply_gain(-5 + energy_level * 6)
        
        stem = AudioSegment.silent(duration=duration_ms)
        
        # Snare –æ–±—ã—á–Ω–æ –Ω–∞ 2 –∏ 4 –¥–æ–ª—è—Ö
        snare_positions = [beat_duration, beat_duration * 3]  # 2nd and 4th beat
        
        current_pos = 0
        while current_pos < duration_ms:
            for pos_offset in snare_positions:
                pos = current_pos + pos_offset
                if pos < duration_ms:
                    stem = stem.overlay(snare, position=pos)
            current_pos += beat_duration * 4  # One bar
        
        return stem

    def _create_hihat_stem(self, duration_ms: int, step_duration: int, energy_level: float, genre: str) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ hihat —Å—Ç–µ–º–∞"""
        hihat = WhiteNoise().to_audio_segment(duration=60)
        hihat = hihat.high_pass_filter(8000)
        hihat = hihat.apply_gain(-12 + energy_level * 4)
        
        stem = AudioSegment.silent(duration=duration_ms)
        
        # Hi-hat pattern
        if genre == 'trap':
            pattern = [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]
        else:
            pattern = [1, 0, 1, 0] * 4  # Eighth notes
        
        current_pos = 0
        while current_pos < duration_ms:
            for i, hit in enumerate(pattern):
                pos = current_pos + (i * step_duration)
                if hit and pos < duration_ms:
                    stem = stem.overlay(hihat, position=pos)
            current_pos += step_duration * len(pattern)
        
        return stem

    def _create_bass_stem(self, duration_ms: int, beat_duration: int, energy_level: float, genre: str) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ bass —Å—Ç–µ–º–∞"""
        bass_freq = 55  # A1
        bass = Sine(bass_freq).to_audio_segment(duration=beat_duration)
        bass = bass.apply_gain(-8 + energy_level * 4)
        bass = bass.fade_in(10).fade_out(100)
        
        stem = AudioSegment.silent(duration=duration_ms)
        
        current_pos = 0
        while current_pos < duration_ms:
            stem = stem.overlay(bass, position=current_pos)
            current_pos += beat_duration * 2  # Every other beat
        
        return stem

    def _create_generic_stem(self, instrument: str, duration_ms: int, beat_duration: int) -> AudioSegment:
        """–°–æ–∑–¥–∞–Ω–∏–µ generic —Å—Ç–µ–º–∞ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        # –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–π —Ç–æ–Ω
        freq = 440  # A4
        tone = Sine(freq).to_audio_segment(duration=beat_duration // 2)
        tone = tone.apply_gain(-15)  # –¢–∏—Ö–∏–π —É—Ä–æ–≤–µ–Ω—å
        
        stem = AudioSegment.silent(duration=duration_ms)
        
        current_pos = 0
        while current_pos < duration_ms:
            stem = stem.overlay(tone, position=current_pos)
            current_pos += beat_duration * 2
        
        return stem

    def _create_minimal_instrument_sound(self, instrument: str, duration_ms: int) -> AudioSegment:
        """–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∑–≤—É–∫ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–æ–∫"""
        frequencies = {
            "kick": 60,
            "snare": 200,
            "hihat": 8000,
            "bass": 55,
            "lead": 440,
            "pad": 220
        }
        
        freq = frequencies.get(instrument, 440)
        sound = Sine(freq).to_audio_segment(duration=duration_ms)
        sound = sound.apply_gain(-20)  # –û—á–µ–Ω—å —Ç–∏—Ö–æ
        
        return sound.fade_in(1000).fade_out(1000)

    async def _step_mix_tracks_FIXED(
        self, base_audio_bytes: bytes, stems_bytes: Dict[str, bytes], genre_info: Dict
    ) -> bytes:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑—ã —Å–æ —Å—Ç–µ–º–∞–º–∏"""
        start_time = time.time()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Å–∞ –¥–ª—è –∂–∞–Ω—Ä–∞
            mix_settings = self._get_genre_mix_settings(genre_info["name"])
            
            self.logger.info(f"  üéöÔ∏è –ú–∏–∫—Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è {genre_info['name']}: "
                            f"–±–∞–∑–∞ {mix_settings['base_level']}dB, "
                            f"—Å—Ç–µ–º—ã {mix_settings['stems_level']}dB")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤–æ–µ –∞—É–¥–∏–æ
            base_audio = AudioSegment.from_file(io.BytesIO(base_audio_bytes))
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ä–æ–≤–µ–Ω—å –±–∞–∑–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–∏
            base_level = mix_settings.get("base_level", -3)
            mixed = base_audio + base_level
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–µ–º—ã
            stems_level = mix_settings.get("stems_level", -6)
            
            for instrument, stem_bytes in stems_bytes.items():
                try:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–µ–º
                    stem_audio = AudioSegment.from_file(io.BytesIO(stem_bytes))
                    
                    # –ü–æ–¥–≥–æ–Ω—è–µ–º –¥–ª–∏–Ω—É –ø–æ–¥ –±–∞–∑–æ–≤—É—é –¥–æ—Ä–æ–∂–∫—É
                    if len(stem_audio) != len(mixed):
                        if len(stem_audio) > len(mixed):
                            stem_audio = stem_audio[:len(mixed)]
                        else:
                            # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∏–ª–∏ –¥–æ–ø–æ–ª–Ω—è–µ–º —Ç–∏—à–∏–Ω–æ–π
                            repetitions = len(mixed) // len(stem_audio) + 1
                            stem_audio = stem_audio * repetitions
                            stem_audio = stem_audio[:len(mixed)]
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å—Ç–µ–º–∞
                    stem_audio = stem_audio + stems_level
                    
                    # –ú–∏–∫—à–∏—Ä—É–µ–º
                    mixed = mixed.overlay(stem_audio)
                    
                    self.logger.debug(f"    üéõÔ∏è Mixed {instrument}: {stems_level:+.1f}dB")
                    
                except Exception as e:
                    self.logger.error(f"‚ùå Error mixing stem {instrument}: {e}")
                    continue
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ bytes
            buffer = io.BytesIO()
            mixed.export(buffer, format="wav")
            mixed_bytes = buffer.getvalue()
            buffer.close()
            
            processing_time = time.time() - start_time
            self._performance_stats["mixing_time"] = processing_time
            
            self.logger.info(f"  üéöÔ∏è –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {len(mixed_bytes)} bytes")
            self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
            
            return mixed_bytes
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –¥–æ—Ä–æ–∂–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return base_audio_bytes

    async def _step_apply_effects_FIXED(
        self, mixed_audio_bytes: bytes, metadata: Dict, genre_info: Dict
    ) -> bytes:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∂–∞–Ω—Ä–æ–≤—ã—Ö —ç—Ñ—Ñ–µ–∫—Ç–æ–≤"""
        start_time = time.time()
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio = AudioSegment.from_file(io.BytesIO(mixed_audio_bytes))
            
            # –°–æ–∑–¥–∞—ë–º —Ü–µ–ø–æ—á–∫—É —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –¥–ª—è –∂–∞–Ω—Ä–∞
            effects_config = self._get_genre_effects_config(genre_info, metadata)
            
            self.logger.info(f"  ‚ú® –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã: {', '.join(effects_config.keys())}")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã —á–µ—Ä–µ–∑ effects_chain
            processed_audio = await self.effects_chain.apply_effects(
                audio=audio,
                effects_config=effects_config,
                genre_info=genre_info
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            processed_audio.export(buffer, format="wav")
            processed_bytes = buffer.getvalue()
            buffer.close()
            
            processing_time = time.time() - start_time
            self._performance_stats["effects_time"] = processing_time
            
            self.logger.info(f"  ‚ú® –≠—Ñ—Ñ–µ–∫—Ç—ã –ø—Ä–∏–º–µ–Ω–µ–Ω—ã: {len(processed_bytes)} bytes")
            self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
            
            return processed_bytes
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–æ–≤: {e}")
            return mixed_audio_bytes

    async def _step_master_track_FIXED(
        self, processed_audio_bytes: bytes, mastering_purpose: str, genre_info: Dict
    ) -> Tuple[bytes, Dict, Dict]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —ç—Ç–∞–ø –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞"""
        start_time = time.time()
        
        try:
            mastering_config = config.get_mastering_config(mastering_purpose)

            self.logger.info(
                f"  üéõÔ∏è –ú–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–ª—è {mastering_purpose}: "
                f"LUFS {mastering_config['target_lufs']}, "
                f"–ø–æ—Ç–æ–ª–æ–∫ {mastering_config['peak_ceiling']}dB"
            )

            # –í—ã–∑—ã–≤–∞–µ–º –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–≤–∏–∂–æ–∫
            mastering_result = await self.mastering_engine.master_track(
                audio=processed_audio_bytes,
                target_config=mastering_config,
                genre_info=genre_info,
                purpose=mastering_purpose
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞
            if isinstance(mastering_result, tuple) and len(mastering_result) >= 2:
                mastered_audio_segment, applied_config = mastering_result[:2]
            else:
                mastered_audio_segment = mastering_result
                applied_config = mastering_config

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º AudioSegment –≤ bytes
            if hasattr(mastered_audio_segment, 'export'):
                buffer = io.BytesIO()
                mastered_audio_segment.export(buffer, format="wav")
                mastered_audio_bytes = buffer.getvalue()
                buffer.close()
            else:
                mastered_audio_bytes = mastered_audio_segment

            processing_time = time.time() - start_time
            self._performance_stats["mastering_time"] = processing_time

            self.logger.info(f"  ‚úÖ –ú–∞—Å—Ç–µ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(mastered_audio_bytes)} bytes")
            self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
            
            return mastered_audio_bytes, mastering_config, applied_config
            
        except Exception as e:
            processing_time = time.time() - start_time
            self._performance_stats["mastering_time"] = processing_time
            
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞: {e}")
            self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –¥–æ –æ—à–∏–±–∫–∏: {processing_time:.2f}—Å")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ —Å –±–∞–∑–æ–≤–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
            try:
                audio = AudioSegment.from_file(io.BytesIO(processed_audio_bytes))
                normalized = normalize(audio, headroom=2.0)
                
                buffer = io.BytesIO()
                normalized.export(buffer, format="wav")
                fallback_bytes = buffer.getvalue()
                buffer.close()
                
                return fallback_bytes, config.get_mastering_config(mastering_purpose), {}
                
            except Exception as fallback_error:
                self.logger.error(f"‚ùå Fallback –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ —Ç–∞–∫–∂–µ –Ω–µ —É–¥–∞–ª—Å—è: {fallback_error}")
                return processed_audio_bytes, config.get_mastering_config(mastering_purpose), {}

    async def _step_verify_quality_FIXED(
        self, mastered_audio_bytes: bytes, mastering_config: Dict
    ) -> Dict:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞"""
        start_time = time.time()
        
        try:
            quality_report = await self.verifier.analyze_track(
                audio=mastered_audio_bytes,
                target_config=mastering_config
            )
            
            overall_score = quality_report.get("overall_score", 0.8)  # –î–µ—Ñ–æ–ª—Ç 0.8 –≤–º–µ—Å—Ç–æ 0.0
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞: {e}")
            # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –æ—Ç—á—ë—Ç
            quality_report = {
                "overall_score": 0.7,
                "status": "completed_with_fallback_verification",
                "issues": [f"Verification error: {e}"]
            }
            overall_score = 0.7
        
        processing_time = time.time() - start_time
        self._performance_stats["verification_time"] = processing_time
        
        self.logger.info(f"  üîç –ö–∞—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–∫–∞: {overall_score:.2f}/1.0")
        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
        
        if overall_score < 0.7:
            self.logger.warning("  ‚ö†Ô∏è –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∂–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–≥–æ, –Ω–æ —Ç—Ä–µ–∫ –≥–æ—Ç–æ–≤")
        
        return quality_report

    async def _step_export_results_FIXED(
        self,
        request: GenerationRequest,
        mastered_audio_bytes: bytes,
        structure: Dict,
        selected_samples: List[Dict],
        mastering_config: Dict,
        intermediate_audio: Dict[str, Any]
    ) -> Dict[str, str]:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —ç–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        start_time = time.time()

        export_config = {
            "output_dir": request.output_dir,
            "export_stems": request.export_stems,
            "energy_level": request.energy_level,
            "creativity_factor": request.creativity_factor
        }

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ pipeline...
    
    async def _step_prepare_metadata(self, request: GenerationRequest) -> Dict:
        """–≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        start_time = time.time()
        
        metadata = {
            "original_prompt": request.prompt,
            "timestamp": time.time(),
            "request_id": f"wd_{int(time.time())}",
        }
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞ —á–µ—Ä–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        prompt_analysis = self.metadata_processor.analyze_prompt(request.prompt)
        metadata.update(prompt_analysis)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        extracted_params = self.metadata_processor.extract_parameters(request.prompt)
        
        metadata.update({
            "detected_bpm": extracted_params.get("bpm", request.bpm),
            "detected_key": extracted_params.get("key"),
            "detected_mood": extracted_params.get("mood", []),
            "detected_instruments": extracted_params.get("instruments", []),
            "detected_tags": extracted_params.get("tags", []),
            "energy_level": request.energy_level,
            "creativity_factor": request.creativity_factor
        })
        
        processing_time = time.time() - start_time
        self._performance_stats["metadata_time"] = processing_time
        
        self.logger.info(f"  üìä –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ: BPM={metadata.get('detected_bpm')}, "
                        f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã={len(metadata.get('detected_instruments', []))}")
        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
        
        return metadata
    
    async def _step_detect_genre(self, request: GenerationRequest, metadata: Dict) -> Dict:
        """–≠—Ç–∞–ø 2: –î–µ—Ç–µ–∫—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∂–∞–Ω—Ä–∞"""
        start_time = time.time()
        
        if request.genre:
            detected_genre = request.genre.lower()
            self.logger.info(f"  üé≠ –ñ–∞–Ω—Ä –∑–∞–¥–∞–Ω –≤—Ä—É—á–Ω—É—é: {detected_genre}")
        else:
            detected_genre = self.metadata_processor.detect_genre(
                request.prompt, metadata.get("detected_tags", [])
            )
            self.logger.info(f"  üé≠ –ñ–∞–Ω—Ä –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {detected_genre}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –∂–∞–Ω—Ä–∞
        genre_config = config.get_genre_config(detected_genre)
        if not genre_config:
            self.logger.warning(f"  ‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∂–∞–Ω—Ä {detected_genre}, –∏—Å–ø–æ–ª—å–∑—É–µ–º trap")
            detected_genre = "trap"
            genre_config = config.get_genre_config("trap")
        
        genre_info = {
            "name": detected_genre,
            "config": genre_config,
            "bpm_range": genre_config.bmp_range,
            "target_bpm": metadata.get("detected_bpm") or 
                         (genre_config.bpm_range[0] + genre_config.bpm_range[1]) // 2,
            "energy_range": genre_config.energy_range,
            "mastering_style": genre_config.mastering_style,
            "energy_level": metadata.get("energy_level", 0.5)
        }
        
        processing_time = time.time() - start_time
        self._performance_stats["genre_detection_time"] = processing_time
        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
        
        return genre_info
    
    async def _step_generate_structure(
        self, request: GenerationRequest, metadata: Dict, genre_info: Dict
    ) -> Dict:
        """–≠—Ç–∞–ø 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç—Ä–µ–∫–∞"""
        start_time = time.time()

        if request.custom_structure:
            structure = {
                "sections": request.custom_structure,
                "total_duration": sum(s.get("duration", 8) for s in request.custom_structure),
                "source": "custom"
            }
            self.logger.info(f"  üèóÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞—Å—Ç–æ–º–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: {len(structure['sections'])} —Å–µ–∫—Ü–∏–π")
        else:
            try:
                llama_response = query_structured_music(request.prompt)

                if not llama_response:
                    raise ValueError("LLaMA3 –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É")

                structure = {
                    "sections": llama_response["structure"],
                    "total_duration": sum(s["duration"] for s in llama_response["structure"]),
                    "source": "llama3-music"
                }

                self.logger.info(f"  üß† –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç LLaMA3: {len(structure['sections'])} —Å–µ–∫—Ü–∏–π")

            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è LLaMA3 –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: {e}")
                structure = self._generate_fallback_structure(genre_info, request.duration)
                structure["source"] = "fallback"

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        structure = self._validate_structure(structure, genre_info)

        processing_time = time.time() - start_time
        self._performance_stats["structure_time"] = processing_time

        self.logger.info(f"  ‚è±Ô∏è –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {structure['total_duration']}—Å")
        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")

        return structure
    
    async def _step_select_samples(
        self, request: GenerationRequest, metadata: Dict, genre_info: Dict, structure: Dict
    ) -> List[Dict]:
        """–≠—Ç–∞–ø 4: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä —Å—ç–º–ø–ª–æ–≤"""
        start_time = time.time()
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ç—Ä–µ–±—É–µ–º—ã–µ —Ç–µ–≥–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        required_tags = set()
        required_tags.update(metadata.get("detected_instruments", []))
        required_tags.update(metadata.get("detected_tags", []))
        required_tags.update(genre_info["config"].core_instruments)
        
        if request.sample_tags:
            required_tags.update(request.sample_tags)
        
        selected_samples = []
        
        # –ü–æ–¥–±–∏—Ä–∞–µ–º —Å—ç–º–ø–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Å–µ–∫—Ü–∏–∏
        for section in structure["sections"]:
            section_type = section.get("type", "unknown")
            section_energy = section.get("energy", 0.5)
            
            self.logger.info(f"  üéØ –°–µ–∫—Ü–∏—è '{section_type}': —ç–Ω–µ—Ä–≥–∏—è {section_energy}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Å–µ–∫—Ü–∏–∏
            section_instruments = self._get_section_instruments(
                section_type, genre_info, section_energy
            )
            
            # –ü–æ–¥–±–∏—Ä–∞–µ–º —Å—ç–º–ø–ª—ã —á–µ—Ä–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫
            section_samples = await self.sample_engine.find_samples(
                tags=list(required_tags),
                instruments=section_instruments,
                genre=genre_info["name"],
                bpm=genre_info["target_bpm"],
                energy=section_energy,
                max_results=len(section_instruments)
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–∫—Ü–∏–∏ –∫ —Å—ç–º–ø–ª–∞–º
            for sample in section_samples:
                sample["section"] = section_type
                sample["section_energy"] = section_energy
                selected_samples.append(sample)
        
        processing_time = time.time() - start_time
        self._performance_stats["sample_selection_time"] = processing_time
        
        self.logger.info(f"  ‚úÖ –ü–æ–¥–æ–±—Ä–∞–Ω–æ —Å—ç–º–ø–ª–æ–≤: {len(selected_samples)}")
        self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")
        
        return selected_samples
    
    def _generate_fallback_structure(self, genre_info: Dict, duration: Optional[int]) -> Dict:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø fallback –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        try:
            genre_config = genre_info.get("config")

            if genre_config:
                if hasattr(genre_config, 'default_structure'):
                    default_structure = genre_config.default_structure
                elif hasattr(genre_config, '__dict__'):
                    default_structure = getattr(genre_config, 'default_structure', [])
                else:
                    default_structure = genre_config.get("default_structure", [])
            else:
                default_structure = []

            if not default_structure:
                self.logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–µ—Ñ–æ–ª—Ç–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –∂–∞–Ω—Ä–∞, —Å–æ–∑–¥–∞—ë–º –±–∞–∑–æ–≤—É—é")
                genre_name = genre_info.get("name", "generic").lower()

                genre_structures = {
                    "trap": [
                        {"type": "intro", "duration": 8, "energy": 0.2},
                        {"type": "buildup", "duration": 8, "energy": 0.4},
                        {"type": "drop", "duration": 16, "energy": 0.9},
                        {"type": "verse", "duration": 16, "energy": 0.6},
                        {"type": "drop", "duration": 16, "energy": 0.9},
                        {"type": "outro", "duration": 8, "energy": 0.3}
                    ],
                    "lofi": [
                        {"type": "intro", "duration": 12, "energy": 0.3},
                        {"type": "main", "duration": 32, "energy": 0.5},
                        {"type": "bridge", "duration": 16, "energy": 0.4},
                        {"type": "main", "duration": 24, "energy": 0.5},
                        {"type": "outro", "duration": 16, "energy": 0.2}
                    ],
                    "house": [
                        {"type": "intro", "duration": 16, "energy": 0.3},
                        {"type": "buildup", "duration": 16, "energy": 0.6},
                        {"type": "drop", "duration": 32, "energy": 0.9},
                        {"type": "breakdown", "duration": 16, "energy": 0.4},
                        {"type": "drop", "duration": 32, "energy": 0.9},
                        {"type": "outro", "duration": 16, "energy": 0.3}
                    ]
                }

                default_structure = genre_structures.get(genre_name, genre_structures["trap"])

            target_duration = duration or 80
            current_duration = sum(s.get("duration", 8) for s in default_structure)

            if current_duration <= 0:
                current_duration = 48
                default_structure = [
                    {"type": "intro", "duration": 8, "energy": 0.3},
                    {"type": "main", "duration": 32, "energy": 0.7},
                    {"type": "outro", "duration": 8, "energy": 0.3}
                ]

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            scale_factor = target_duration / current_duration
            scale_factor = max(0.3, min(scale_factor, 4.0))

            scaled_structure = []
            total_scaled_duration = 0

            for section in default_structure:
                original_duration = section.get("duration", 8)
                scaled_duration = max(4, int(original_duration * scale_factor))

                scaled_section = {
                    "type": section.get("type", "section"),
                    "duration": scaled_duration,
                    "energy": max(0.1, min(1.0, section.get("energy", 0.5))),
                    "start_time": total_scaled_duration
                }

                scaled_structure.append(scaled_section)
                total_scaled_duration += scaled_duration

            return {
                "sections": scaled_structure,
                "total_duration": total_scaled_duration,
                "source": "fallback_generated"
            }

        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ fallback —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")

            emergency_duration = duration or 40
            return {
                "sections": [
                    {"type": "intro", "duration": 8, "energy": 0.3, "start_time": 0},
                    {"type": "main", "duration": emergency_duration - 16, "energy": 0.7, "start_time": 8},
                    {"type": "outro", "duration": 8, "energy": 0.3, "start_time": emergency_duration - 8}
                ],
                "total_duration": emergency_duration,
                "source": "emergency_fallback"
            }
    
    def _validate_structure(self, structure: Dict, genre_info: Dict) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        sections = structure.get("sections", [])
        
        normalized_sections = []
        for section in sections:
            normalized_section = {
                "type": section.get("type", "unknown"),
                "duration": max(4, section.get("duration", 8)),
                "energy": max(0.1, min(1.0, section.get("energy", 0.5))),
                "start_time": section.get("start_time", 0)
            }
            normalized_sections.append(normalized_section)
        
        # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º start_time
        current_time = 0
        for section in normalized_sections:
            section["start_time"] = current_time
            current_time += section["duration"]
        
        return {
            "sections": normalized_sections,
            "total_duration": current_time,
            "source": structure.get("source", "unknown")
        }
    
    def _get_section_instruments(
        self, section_type: str, genre_info: Dict, energy: float
    ) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Å–µ–∫—Ü–∏–∏"""
        config = genre_info["config"]
        instruments = config.core_instruments.copy()
        
        if energy > 0.6 or section_type in ["hook", "drop", "climax"]:
            instruments.extend(config.optional_instruments)
        elif section_type in ["intro", "outro"] and energy < 0.4:
            instruments = instruments[:2]
        
        return instruments
    
    def _create_musicgen_prompt(
        self, original_prompt: str, genre_info: Dict, metadata: Dict
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è MusicGen"""
        genre = genre_info["name"]
        bmp = genre_info["target_bpm"]
        style = genre_info["mastering_style"]
        
        genre_terms = {
            "trap": ["dark", "aggressive", "urban", "melodic"],
            "lofi": ["chill", "vintage", "cozy", "nostalgic"],  
            "dnb": ["energetic", "breakbeat", "bass-heavy", "dynamic"],
            "ambient": ["ethereal", "spacious", "meditative", "peaceful"],
            "techno": ["hypnotic", "minimal", "driving", "industrial"],
        }
        
        terms = genre_terms.get(genre, ["professional", "high-quality"])
        
        enhanced_prompt = f"{original_prompt} {genre} style {bpm}bpm " + " ".join(terms[:2])
        
        return enhanced_prompt
    
    def _get_genre_mix_settings(self, genre: str) -> Dict:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Å–∞ –¥–ª—è –∂–∞–Ω—Ä–∞"""
        mix_settings = {
            "trap": {"base_level": -4, "stems_level": -5},
            "lofi": {"base_level": -5, "stems_level": -8}, 
            "dnb": {"base_level": -2, "stems_level": -4},
            "ambient": {"base_level": -6, "stems_level": -10},
            "techno": {"base_level": -3, "stems_level": -5},
        }
        
        return mix_settings.get(genre, {"base_level": -3, "stems_level": -6})
    
    def _get_genre_effects_config(self, genre_info: Dict, metadata: Dict) -> Dict:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –¥–ª—è –∂–∞–Ω—Ä–∞"""
        genre = genre_info["name"]
        energy = metadata.get("energy_level", 0.5)
        
        effects_configs = {
            "trap": {
                "reverb": {"room_size": 0.3, "wet_level": 0.15},
                "compressor": {"ratio": 3.5, "threshold": -10},
                "eq": {"low": 2, "mid": 0, "high": 3},
                "saturation": {"amount": 0.3, "type": "tube"}
            },
            "lofi": {
                "saturation": {"amount": 0.5, "type": "tape", "warmth": 0.6},
                "compressor": {"ratio": 2.0, "threshold": -15},
                "eq": {"low": 3, "mid": -1, "high": -2},
                "reverb": {"room_size": 0.2, "wet_level": 0.1}
            },
            "house": {
                "eq": {"low": 1, "mid": 0, "high": 2},
                "compressor": {"ratio": 3.0, "threshold": -8},
                "reverb": {"room_size": 0.4, "wet_level": 0.15}
            }
        }
        
        return effects_configs.get(genre, {
            "eq": {"low": 0, "mid": 0, "high": 0},
            "compressor": {"ratio": 2.0, "threshold": -12}
        })


# === –°–û–ó–î–ê–ù–ò–ï –ì–õ–û–ë–ê–õ–¨–ù–û–ì–û –≠–ö–ó–ï–ú–ü–õ–Ø–†–ê ===
pipeline = WaveDreamPipeline()

# === –£–î–û–ë–ù–´–ï –§–£–ù–ö–¶–ò–ò ===
async def generate_track(prompt: str, **kwargs) -> GenerationResult:
    """–£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç—Ä–µ–∫–∞"""
    request = GenerationRequest(prompt=prompt, **kwargs)
    return await pipeline.generate_track(request)

async def quick_beat(prompt: str, genre: str = None) -> str:
    """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∏—Ç–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É"""
    result = await pipeline.quick_generate(prompt, genre)
    return result.final_path if result.success else None

def get_pipeline_stats() -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ pipeline"""
    return {
        "performance": pipeline._performance_stats,
        "intermediate_files": pipeline._intermediate_storage,
        "current_project": pipeline._current_project_name
    }

if __name__ == "__main__":
    async def test_run():
        print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ì–û WaveDream Pipeline...")
        
        result = await generate_track(
            prompt="aggressive trap beat 160bpm dark urban style",
            genre="trap",
            duration=60,
            mastering_purpose="personal"
        )
        
        if result.success:
            print(f"‚úÖ –¢—Ä–µ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {result.final_path}")
            print(f"üìä –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.2f}")
            print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result.generation_time:.1f}—Å")
            print(f"üìÅ –§–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(result.intermediate_files)}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.error_message}")
    
    import asyncio
    asyncio.run(test_run())"export_formats": ["wav", "mp3"],
            "request_data": {
                "prompt": request.prompt,
                "genre": request.genre,
                "bmp": request.bmp,
                "duration": request.duration,
                "mastering_purpose": request.mastering_purpose,
                "energy_level": request.energy_level,
                "creativity_factor": request.creativity_factor
            },
            "structure": structure,
            "samples": selected_samples,
            "mastering": mastering_config
        }

        try:
            exported_files = await self.export_manager.export_complete_project(
                mastered_audio=mastered_audio_bytes,
                intermediate_audio=intermediate_audio,
                config=export_config
            )

            processing_time = time.time() - start_time
            self._performance_stats["export_time"] = processing_time
            
            self.logger.info(f"  üíæ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: {len(exported_files)} —Ñ–∞–π–ª–æ–≤")
            self.logger.info(f"  ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {processing_time:.2f}—Å")

            return exported_files
            
        except Exception as e:
            processing_time = time.time() - start_time
            self._performance_stats["export_time"] = processing_time
            
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤–∞—Ä–∏–π–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            try:
                emergency_path = Path(request.output_dir) / f"emergency_{self._current_project_name}.wav"
                emergency_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(emergency_path, 'wb') as f:
                    f.write(mastered_audio_bytes)
                
                self.logger.warning(f"üö® –ê–≤–∞—Ä–∏–π–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: {emergency_path}")
                return {"emergency_final": str(emergency_path)}
                
            except Exception as emergency_error:
                self.logger.error(f"‚ùå –ê–≤–∞—Ä–∏–π–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {emergency_error}")
                return {}

    # === –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ===

    async def _save_intermediate_audio(self, stage_name: str, audio_bytes: bytes) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ –∞—É–¥–∏–æ"""
        try:
            output_dir = Path(self._current_project_name) / "intermediate"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = output_dir / f"{stage_name}.wav"
            
            with open(file_path, 'wb') as f:
                f.write(audio_bytes)
            
            return str(file_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ –∞—É–¥–∏–æ {stage_name}: {e}")
            return None

    async def _save_stem_audio(self, stem_name: str, stem_bytes: bytes) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–µ–º–∞"""
        try:
            output_dir = Path(self._current_project_name) / "stems"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = output_dir / f"{stem_name}.wav"
            
            with open(file_path, 'wb') as f:
                f.write(stem_bytes)
            
            return str(file_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–µ–º–∞ {stem_name}: {e}")
            return None

    async def _save_final_audio(self, audio_bytes: bytes) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ"""
        try:
            output_dir = Path(self._current_project_name)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = output_dir / f"{self._current_project_name}_FINAL.wav"
            
            with open(file_path, 'wb') as f:
                f.write(audio_bytes)
            
            return str(file_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ: {e}")
            return None

    async def _save_project_metadata(self, metadata: Dict) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞"""
        try:
            output_dir = Path(self._current_project_name)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = output_dir / "project_metadata.json"
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)
            
            return str(file_path)
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return None

    def _serialize_request(self, request: GenerationRequest) -> Dict:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è JSON"""
        return {
            "prompt": request.prompt,
            "genre": request.genre,
            "bmp": request.bpm,
            "duration": request.duration,
            "mastering_purpose": request.mastering_purpose,
            "output_dir": request.output_dir,
            "export_stems": request.export_stems,
