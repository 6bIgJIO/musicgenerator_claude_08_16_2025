#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
WaveDream Enhanced Pro v2.1 - –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê

üî• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ "AudioSegment objects can't be subtracted from each other"
‚úÖ –£–±—Ä–∞–Ω–∞ –≤—Å—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è - —Ä–∞–±–æ—Ç–∞–µ–º –¢–û–õ–¨–ö–û —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏  
‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ –æ–ø–µ—á–∞—Ç–∫–∏ bmp -> bpm
‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –≤–∞—à–µ–≥–æ JSON
‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
‚úÖ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –∏–∑ –±–∞–∑—ã –¥–ª—è –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è
‚úÖ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ë–ï–ó –ö–û–ú–ü–†–û–ú–ò–°–°–û–í
‚úÖ –†–ê–ë–û–¢–ê–ï–¢ –° –ü–ï–†–í–û–ì–û –†–ê–ó–ê

"""

import os
import sys
import asyncio
import logging
import time
import json
import io
import traceback
import hashlib
import re
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import numpy as np

# –ê—É–¥–∏–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from pydub import AudioSegment, effects
from pydub.effects import normalize
import librosa
import soundfile as sf

from sample_pengine import FixedSemanticSampleEngine, EffectsChain
from gonfig import config

# ML/AI –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    SEMANTIC_AVAILABLE = True
except ImportError:
    SEMANTIC_AVAILABLE = False

# MusicGen (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π)
try:
    import torch
    from audiocraft.models import musicgen
    MUSICGEN_AVAILABLE = True
except ImportError:
    MUSICGEN_AVAILABLE = False

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò
# ============================================================================

class MasteringPurpose(Enum):
    FREELANCE = "freelance"
    PROFESSIONAL = "professional"
    PERSONAL = "personal"
    STREAMING = "streaming"
    VINYL = "vinyl"

class GenreType(Enum):
    TRAP = "trap"
    DRILL = "drill"
    LOFI = "lofi"
    DNB = "dnb"
    HOUSE = "house"
    TECHNO = "techno"
    AMBIENT = "ambient"
    CINEMATIC = "cinematic"

@dataclass
class SampleMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞ - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞"""
    path: str
    filename: str
    duration: float
    tempo: int  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm -> tempo
    key: Optional[str]
    tags: List[str]
    genres: List[str]
    instrument_role: Optional[str]
    quality_score: float = 0.6
    energy_level: float = 0.5
    spectral_centroid: float = 0.0
    spectral_rolloff: float = 0.0
    zero_crossing_rate: float = 0.0
    brightness: float = 0.0
    rhythmic_complexity: float = 0.0

@dataclass
class GenerationRequest:
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç—Ä–µ–∫–∞"""
    prompt: str
    genre: Optional[str] = None
    bpm: Optional[int] = None  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
    duration: Optional[int] = None
    mastering_purpose: str = "freelance"  # –ò–ó–ú–ï–ù–ï–ù–û: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    output_dir: str = "output"
    export_stems: bool = True
    energy_level: float = 0.7
    creativity_factor: float = 0.8
    selected_sample_path: Optional[str] = None  # –ù–û–í–û–ï: –≤—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞

@dataclass  
class GenerationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    success: bool
    final_path: Optional[str] = None
    structure_data: Optional[Dict] = None
    used_samples: Optional[List[Dict]] = None
    generation_time: float = 0.0
    quality_score: float = 0.0
    error_message: Optional[str] = None
    intermediate_files: Optional[Dict[str, str]] = None

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´
# ============================================================================

class FixedWaveDreamConfig:
    """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
    
    def __init__(self):
        self.sample_dir = self._find_sample_directory()
        
    def _find_sample_directory(self):
        """–ü–æ–∏—Å–∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –≤–∞—à–∏–º–∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏"""
        possible_dirs = [
            r"D:\0\—à–∞–±–ª–æ–Ω—ã\Samples for AKAI",  # –í–∞—à–∞ –æ—Å–Ω–æ–≤–Ω–∞—è –ø–∞–ø–∫–∞
            "samples",
            "audio_samples", 
            os.path.join(os.path.expanduser("~"), "Documents", "Samples"),
            "D:\\Samples",
            "C:\\Samples"
        ]
        
        for dir_path in possible_dirs:
            if os.path.exists(dir_path):
                return dir_path
        
        # –°–æ–∑–¥–∞—ë–º –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        os.makedirs("samples", exist_ok=True)
        return "samples"
    
    @property
    def DEFAULT_SAMPLE_DIR(self):
        return self.sample_dir
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
    MASTERING_CONFIGS = {
        "freelance": {
            "target_lufs": -14,
            "peak_ceiling": -0.5,
            "dynamic_range": 12,
            "eq_curve": "commercial_bright",
            "compression_style": "punchy_transparent",
            "stereo_enhancement": 1.3,
            "harmonic_saturation": 0.4,
            "character": "MAXIMUM COMMERCIAL QUALITY"
        },
        "professional": {
            "target_lufs": -16,
            "peak_ceiling": -1.0,
            "dynamic_range": 14,
            "eq_curve": "reference_standard",
            "compression_style": "transparent",
            "stereo_enhancement": 1.2,
            "harmonic_saturation": 0.3,
            "character": "MAXIMUM PROFESSIONAL QUALITY"
        },
        "personal": {
            "target_lufs": -16,
            "peak_ceiling": -1.0,
            "dynamic_range": 12,
            "eq_curve": "natural_enhanced",
            "compression_style": "musical",
            "stereo_enhancement": 1.2,
            "harmonic_saturation": 0.35,
            "character": "MAXIMUM PERSONAL QUALITY"
        },
        "streaming": {
            "target_lufs": -14,
            "peak_ceiling": -0.5,
            "dynamic_range": 10,
            "eq_curve": "streaming_optimized",
            "compression_style": "modern_loud",
            "stereo_enhancement": 1.25,
            "harmonic_saturation": 0.4,
            "character": "MAXIMUM STREAMING QUALITY"
        },
        "vinyl": {
            "target_lufs": -18,
            "peak_ceiling": -2.0,
            "dynamic_range": 16,
            "eq_curve": "vinyl_enhanced",
            "compression_style": "vintage_warm",
            "stereo_enhancement": 1.1,
            "harmonic_saturation": 0.5,
            "character": "MAXIMUM ANALOG QUALITY"
        }
    }
    
    def get_mastering_config(self, purpose: str):
        return self.MASTERING_CONFIGS.get(purpose, self.MASTERING_CONFIGS["freelance"])
    
    GENRE_CONFIGS = {
        "trap": {
            "bmp_range": (130, 170),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["kick", "snare", "hihat", "bass", "808"],
            "mastering_style": "punchy_aggressive",
            "energy_range": (0.6, 0.9)
        },
        "drill": {
            "bpm_range": (140, 160),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["kick", "snare", "hihat", "bass"],
            "mastering_style": "punchy_aggressive", 
            "energy_range": (0.7, 0.9)
        },
        "lofi": {
            "bpm_range": (60, 85),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["kick", "snare", "rim", "piano"],
            "mastering_style": "warm_cozy",
            "energy_range": (0.2, 0.5)
        },
        "dnb": {
            "bpm_range": (160, 180),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["kick", "snare", "bass", "break"],
            "mastering_style": "tight_punchy",
            "energy_range": (0.7, 1.0)
        },
        "house": {
            "bpm_range": (120, 135),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["kick", "hihat", "bass", "clap"],
            "mastering_style": "clean_punchy",
            "energy_range": (0.6, 0.9)
        },
        "techno": {
            "bpm_range": (120, 135),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["kick", "hihat", "bass"],
            "mastering_style": "industrial_clean",
            "energy_range": (0.6, 0.9)
        },
        "ambient": {
            "bpm_range": (60, 90),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bmp
            "core_instruments": ["pad", "texture", "drone"],
            "mastering_style": "spacious_ethereal",
            "energy_range": (0.1, 0.4)
        },
        "cinematic": {
            "bpm_range": (70, 120),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            "core_instruments": ["strings", "brass", "percussion"],
            "mastering_style": "cinematic_wide",
            "energy_range": (0.3, 1.0)
        }
    }
    
    def get_genre_config(self, genre: str):
        if not genre:
            return self.GENRE_CONFIGS.get("trap")
        return self.GENRE_CONFIGS.get(genre.lower(), self.GENRE_CONFIGS.get("trap"))

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–æ–Ω—Ñ–∏–≥–∞
config = FixedWaveDreamConfig()

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ô –î–í–ò–ñ–û–ö - –¢–û–õ–¨–ö–û –†–ï–ê–õ–¨–ù–´–ï –°–≠–ú–ü–õ–´
# ============================================================================

class FixedSemanticSampleEngine:
    """
    –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫
    
    ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - –†–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏ –∏–∑ –≤–∞—à–µ–≥–æ JSON
    - –£–±—Ä–∞–Ω–∞ –í–°–Ø —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    - –ß–µ—Å—Ç–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å–∫–æ—Ä–∞–º–∏
    - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ bmp -> bpm –æ–ø–µ—á–∞—Ç–∫–∏
    - –î–æ–±–∞–≤–ª–µ–Ω —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞
    """
    
    def __init__(self, sample_dir: str = None):
        self.sample_dir = sample_dir or config.DEFAULT_SAMPLE_DIR
        self.logger = logging.getLogger(__name__)
        self.samples_index: List[SampleMetadata] = []
        self.semantic_model = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if SEMANTIC_AVAILABLE:
            try:
                self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
                self.logger.info("‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
        
        # –ì–õ–ê–í–ù–û–ï: –∑–∞–≥—Ä—É–∂–∞–µ–º –†–ï–ê–õ–¨–ù–´–ô –∏–Ω–¥–µ–∫—Å
        self.load_real_sample_index()
        
        self.logger.info(f"üéØ FixedSemanticSampleEngine: {len(self.samples_index)} —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤")
    
    def load_real_sample_index(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –†–ï–ê–õ–¨–ù–û–ì–û –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ –≤–∞—à–µ–≥–æ JSON —Ñ–∞–π–ª–∞"""
        self.logger.info("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –†–ï–ê–õ–¨–ù–´–ô –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤...")
        
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ –≤–∞—à–µ–º—É –∏–Ω–¥–µ–∫—Å—É
        possible_paths = [
            "sample_index ‚Äî –∫–æ–ø–∏—è2025.08.json",  # –í–∞—à –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
            "sample_index.json",
            "enhanced_sample_index.json",
            os.path.join(self.sample_dir, "sample_index.json"),
            os.path.join(".", "sample_index ‚Äî –∫–æ–ø–∏—è2025.08.json"),
            "sample_index_–∫–æ–ø–∏—è2025.08.json"  # –ë–µ–∑ —é–Ω–∏–∫–æ–¥–∞
        ]
        
        for index_path in possible_paths:
            if os.path.exists(index_path):
                try:
                    self.logger.info(f"  üìã –ù–∞–π–¥–µ–Ω –∏–Ω–¥–µ–∫—Å: {index_path}")
                    
                    with open(index_path, 'r', encoding='utf-8') as f:
                        raw_data = json.load(f)
                    
                    if isinstance(raw_data, list) and len(raw_data) > 0:
                        converted_count = self._convert_real_index(raw_data)
                        if converted_count > 0:
                            self.logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {converted_count} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤")
                            return
                
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {index_path}: {e}")
        
        self.logger.error("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –†–ï–ê–õ–¨–ù–´–ô –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ù–ï –ù–ê–ô–î–ï–ù!")
        self.logger.error("‚ùå –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª sample_index.json —Å –≤–∞—à–∏–º–∏ —Å—ç–º–ø–ª–∞–º–∏")
        self.samples_index = []
    
    def _convert_real_index(self, raw_data: List[Dict]) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞—à–µ–≥–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞"""
        self.samples_index = []
        converted_count = 0
        
        for item in raw_data:
            try:
                metadata = SampleMetadata(
                    path=item.get("path", ""),
                    filename=item.get("filename", "unknown.wav"),
                    duration=float(item.get("duration", 0.0)),
                    tempo=int(item.get("tempo", 120)),  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ–ª–µ
                    key=item.get("key"),
                    tags=item.get("tags", []),
                    genres=item.get("genres", []),
                    instrument_role=item.get("instrument_role"),
                    quality_score=float(item.get("quality_score", 0.6)),
                    energy_level=float(item.get("energy_level", 0.5)),
                    spectral_centroid=float(item.get("spectral_centroid", 0.0)),
                    spectral_rolloff=float(item.get("spectral_rolloff", 0.0)),
                    zero_crossing_rate=float(item.get("zero_crossing_rate", 0.0)),
                    brightness=float(item.get("brightness", 0.0)),
                    rhythmic_complexity=float(item.get("rhythmic_complexity", 0.0))
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                if os.path.exists(metadata.path):
                    self.samples_index.append(metadata)
                    converted_count += 1
                else:
                    self.logger.debug(f"  ‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {metadata.path}")
                    
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        
        return converted_count
    
    async def find_samples(
        self,
        tags: List[str],
        instruments: Optional[List[str]] = None,
        genre: Optional[str] = None,
        bpm: Optional[int] = None,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm –≤–º–µ—Å—Ç–æ bmp
        energy: float = 0.5,
        max_results: int = 10,
        min_quality: float = 0.1
    ) -> List[Dict]:
        """
        –ß–ï–°–¢–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –†–ï–ê–õ–¨–ù–û–ô –±–∞–∑–µ —Å—ç–º–ø–ª–æ–≤
        """
        self.logger.info(f"üîç –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫: —Ç–µ–≥–∏={tags}, –∂–∞–Ω—Ä={genre}, BPM={bpm}")
        
        if not self.samples_index:
            self.logger.error("‚ùå –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç!")
            return []
        
        candidates = []
        
        for sample in self.samples_index:
            score = self._calculate_real_sample_score(sample, tags, instruments, genre, bpm, energy)
            
            if score > min_quality:
                candidates.append({
                    "metadata": sample,
                    "score": score,
                    "path": sample.path,
                    "filename": sample.filename,
                    "instrument_role": sample.instrument_role,
                    "tags": sample.tags,
                    "tempo": sample.tempo,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: tempo –≤–º–µ—Å—Ç–æ bmp
                    "quality_score": sample.quality_score,
                    "energy_level": sample.energy_level,
                    "spectral_centroid": sample.spectral_centroid,
                    "spectral_rolloff": sample.spectral_rolloff,
                    "zero_crossing_rate": sample.zero_crossing_rate,
                    "brightness": sample.brightness,
                    "rhythmic_complexity": sample.rhythmic_complexity,
                    "duration": sample.duration,
                    "key": sample.key,
                    "genres": sample.genres
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É
        candidates.sort(key=lambda x: x["score"], reverse=True)
        
        # –î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results = self._diversify_results(candidates, max_results)
        
        self.logger.info(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤")
        if results:
            self.logger.info(f"  üéØ –õ—É—á—à–∏–π —Å–∫–æ—Ä: {results[0]['score']:.3f} ({results[0]['filename']})")
        
        return results
    
    def _calculate_real_sample_score(
        self, sample: SampleMetadata, tags: List[str], instruments: Optional[List[str]],
        genre: Optional[str], bpm: Optional[int], energy: float  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm
    ) -> float:
        """–†–∞—Å—á—ë—Ç —Å–∫–æ—Ä–∞ –¥–ª—è –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞"""
        total_score = 0.0
        
        # 1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–≥–æ–≤ (35%)
        if tags:
            tag_score = 0.0
            sample_tags_lower = [tag.lower() for tag in sample.tags]
            filename_lower = sample.filename.lower()
            
            for search_tag in tags:
                search_tag_lower = search_tag.lower()
                
                # –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ —Ç–µ–≥–∞—Ö
                if search_tag_lower in sample_tags_lower:
                    tag_score += 1.0
                    continue
                
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                for sample_tag in sample_tags_lower:
                    if search_tag_lower in sample_tag or sample_tag in search_tag_lower:
                        tag_score += 0.7
                        break
                else:
                    # –ü–æ–∏—Å–∫ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                    if search_tag_lower in filename_lower:
                        tag_score += 0.3
            
            if len(tags) > 0:
                tag_score = min(1.0, tag_score / len(tags))
                total_score += tag_score * 0.35
        
        # 2. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (25%)
        if instruments and sample.instrument_role:
            instrument_score = 0.0
            sample_role_lower = sample.instrument_role.lower()
            
            for search_instrument in instruments:
                search_instrument_lower = search_instrument.lower()
                
                if search_instrument_lower == sample_role_lower:
                    instrument_score = 1.0
                    break
                
                if (search_instrument_lower in sample_role_lower or 
                    sample_role_lower in search_instrument_lower):
                    instrument_score = max(instrument_score, 0.7)
            
            total_score += instrument_score * 0.25
        
        # 3. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∂–∞–Ω—Ä–∞ (20%)
        if genre and sample.genres:
            genre_score = 0.0
            genre_lower = genre.lower()
            
            for sample_genre in sample.genres:
                sample_genre_lower = sample_genre.lower()
                
                if genre_lower == sample_genre_lower:
                    genre_score = 1.0
                    break
                
                if (genre_lower in sample_genre_lower or 
                    sample_genre_lower in genre_lower):
                    genre_score = max(genre_score, 0.6)
            
            # –ü–æ–∏—Å–∫ –≤ —Ç–µ–≥–∞—Ö –∏ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            if genre_score == 0.0:
                filename_and_tags = (sample.filename.lower() + " " + 
                                   " ".join(sample.tags).lower())
                if genre_lower in filename_and_tags:
                    genre_score = 0.3
            
            total_score += genre_score * 0.20
        
        # 4. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ BPM (10%) - –ò–°–ü–†–ê–í–õ–ï–ù–û
        if bmp and sample.tempo:
            tempo_diff = abs(sample.tempo - bpm)
            
            if tempo_diff == 0:
                tempo_score = 1.0
            elif tempo_diff <= 3:
                tempo_score = 0.9
            elif tempo_diff <= 10:
                tempo_score = 0.7
            elif tempo_diff <= 20:
                tempo_score = 0.4
            else:
                tempo_score = 0.1
            
            total_score += tempo_score * 0.10
        
        # 5. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —ç–Ω–µ—Ä–≥–∏–∏ (5%)
        energy_diff = abs(sample.energy_level - energy)
        energy_score = max(0.0, 1.0 - energy_diff)
        total_score += energy_score * 0.05
        
        # 6. –ë–æ–Ω—É—Å—ã –∑–∞ –∫–∞—á–µ—Å—Ç–≤–æ (5%)
        total_score += sample.quality_score * 0.05
        
        return min(1.0, max(0.0, total_score))
    
    def _diversify_results(self, candidates: List[Dict], max_results: int) -> List[Dict]:
        """–î–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if len(candidates) <= max_results:
            return candidates
        
        diversified = []
        used_instruments = set()
        used_files = set()
        
        # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥ - —Ä–∞–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        for candidate in candidates:
            if len(diversified) >= max_results:
                break
            
            instrument = candidate.get("instrument_role", "unknown")
            filename = candidate.get("filename", "")
            
            if instrument not in used_instruments and filename not in used_files:
                diversified.append(candidate)
                used_instruments.add(instrument)
                used_files.add(filename)
        
        # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ - –ª—É—á—à–∏–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è
        for candidate in candidates:
            if len(diversified) >= max_results:
                break
            
            filename = candidate.get("filename", "")
            if candidate not in diversified and filename not in used_files:
                diversified.append(candidate)
                used_files.add(filename)
        
        return diversified
    
    def find_sample_by_path(self, sample_path: str) -> Optional[Dict]:
        """–ù–û–í–û–ï: –ü–æ–∏—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –ø–æ –ø—É—Ç–∏"""
        for sample in self.samples_index:
            if sample.path == sample_path or sample.filename in sample_path:
                return {
                    "metadata": sample,
                    "score": 1.0,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ
                    "path": sample.path,
                    "filename": sample.filename,
                    "instrument_role": sample.instrument_role,
                    "tags": sample.tags,
                    "tempo": sample.tempo,
                    "quality_score": sample.quality_score,
                    "energy_level": sample.energy_level,
                    "spectral_centroid": sample.spectral_centroid,
                    "spectral_rolloff": sample.spectral_rolloff,
                    "zero_crossing_rate": sample.zero_crossing_rate,
                    "brightness": sample.brightness,
                    "rhythmic_complexity": sample.rhythmic_complexity,
                    "duration": sample.duration,
                    "key": sample.key,
                    "genres": sample.genres
                }
        return None
    
    def list_all_samples(self) -> List[Dict]:
        """–ù–û–í–û–ï: –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤"""
        return [
            {
                "filename": sample.filename,
                "path": sample.path,
                "instrument_role": sample.instrument_role,
                "genres": sample.genres,
                "tags": sample.tags,
                "duration": sample.duration,
                "tempo": sample.tempo,
                "quality_score": sample.quality_score
            }
            for sample in self.samples_index
        ]

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô MUSICGEN –î–í–ò–ñ–û–ö
# ============================================================================

class FixedMusicGenEngine:
    """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô MusicGen –¥–≤–∏–∂–æ–∫"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.sample_engine = FixedSemanticSampleEngine()
        self.effects_chain = EffectsChain()
        self.musicgen_engine = FixedMusicGenEngine()
        self.model = None
        self.device = "cuda" if torch and torch.cuda.is_available() else "cpu"
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ MusicGen"""
        if not MUSICGEN_AVAILABLE:
            self.logger.error("‚ùå MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        try:
            model_names = ["facebook/musicgen-medium", "facebook/musicgen-small"]
            
            for model_name in model_names:
                try:
                    self.model = musicgen.MusicGen.get_pretrained(model_name)
                    # –Ω–∏–∫–∞–∫–∏—Ö duration —Ç—É—Ç ‚Äî —Ç–æ–ª—å–∫–æ –¥–µ—Ñ–æ–ª—Ç—ã –≤—ã–±–æ—Ä–∫–∏
                    self.model.set_generation_params(
                        use_sampling=True,
                        temperature=1.0,
                        top_k=250,
                        top_p=0.0
                    )
                    return
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_name}: {e}")
            
            self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å MusicGen")
        
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ MusicGen: {e}")
    
    async def generate(self, prompt: str, duration: int = 190, temperature: float = 1.0, genre_hint: Optional[str] = None) -> bytes:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ —Å MusicGen.
        –ï—Å–ª–∏ duration > 30 ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç—Å—è continuation-—Ä–µ–∂–∏–º —Å —á–∞–Ω–∫–∞–º–∏ ~28—Å –∏ –∫—Ä–æ—Å—Å—Ñ–µ–π–¥–æ–º.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–¥–∏–Ω—ã–π WAV –≤ –±–∞–π—Ç–∞—Ö —Ä–æ–≤–Ω–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–¥–æ 6000—Å).
        """
        if not self.model:
            self.logger.error("‚ùå MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return self._generate_emergency_audio(duration)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ü–µ–ª–µ–≤—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (5—Å‚Ä¶6000—Å)
        try:
            target_sec = int(duration)
        except Exception:
            target_sec = 190
        target_sec = max(5, min(6000, target_sec))

        # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç –æ–¥–∏–Ω —Ä–∞–∑ (–Ω–µ –ª–æ–º–∞–µ—Ç —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É)
        enhanced_prompt = self._enhance_prompt(prompt, genre_hint)

        sample_rate = getattr(self.model, "sample_rate", 44100)

        # –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å: –¥–æ 30 —Å–µ–∫ ‚Äî –æ–¥–∏–Ω –≤—ã–∑–æ–≤
        if target_sec <= 30:
            try:
                with torch.no_grad():
                    self.model.set_generation_params(
                        duration=target_sec,
                        use_sampling=True,
                        temperature=float(temperature),
                        top_k=250,
                        top_p=0.0
                    )
                    self.logger.info(f"üéº –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º (–æ–¥–Ω–∏–º –∫—É—Å–∫–æ–º): {enhanced_prompt} ({target_sec}—Å)")
                    wav_tensor = self.model.generate([enhanced_prompt])

                if wav_tensor is None or (hasattr(wav_tensor, "numel") and wav_tensor.numel() == 0):
                    raise RuntimeError("MusicGen –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

                if wav_tensor.dim() == 3:
                    audio_array = wav_tensor[0].cpu().numpy()
                elif wav_tensor.dim() == 2:
                    audio_array = wav_tensor.cpu().numpy()
                else:
                    audio_array = wav_tensor.squeeze().cpu().numpy()

                max_val = float(np.max(np.abs(audio_array)))
                if max_val > 0:
                    audio_array = audio_array / max_val
                rms = float(np.sqrt(np.mean(np.square(audio_array))))
                if rms < 1e-6:
                    self.logger.warning("‚ö†Ô∏è –û—á–µ–Ω—å —Ç–∏—Ö–∏–π —Å–∏–≥–Ω–∞–ª, —É—Å–∏–ª–∏–≤–∞–µ–º")
                    audio_array = np.clip(audio_array * 1000.0, -1.0, 1.0)

                buffer = io.BytesIO()
                if audio_array.ndim == 1:
                    sf.write(buffer, audio_array, sample_rate, format='WAV')
                else:
                    if audio_array.shape[0] == 2:
                        sf.write(buffer, audio_array.T, sample_rate, format='WAV')
                    else:
                        sf.write(buffer, audio_array[0], sample_rate, format='WAV')
                audio_bytes = buffer.getvalue()
                buffer.close()

                if len(audio_bytes) < 1000:
                    raise RuntimeError(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª: {len(audio_bytes)} bytes")

                self.logger.info(f"‚úÖ MusicGen —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª: {len(audio_bytes)} bytes")
                return audio_bytes

            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ MusicGen (–∫–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–∂–∏–º): {e}")
                return self._generate_emergency_audio(target_sec)

        # –î–ª–∏–Ω–Ω—ã–π –ø—É—Ç—å: > 30 —Å–µ–∫ ‚Äî —á–∞–Ω–∫–∏ ~28—Å + –∫—Ä–æ—Å—Å—Ñ–µ–π–¥
        chunk_sec = 28
        xfade_ms = 220
        xfade_samples = max(0, int(sample_rate * xfade_ms / 1000))

        full = None  # type: Optional[np.ndarray]

        def _ensure_ct(audio_np: np.ndarray) -> np.ndarray:
            if audio_np.ndim == 1:
                return audio_np[np.newaxis, :]
            if audio_np.shape[0] in (1, 2):
                return audio_np
            if audio_np.shape[1] in (1, 2):
                return audio_np.T
            return audio_np[:1, :]

        def _concat_with_xfade(a: np.ndarray, b: np.ndarray) -> np.ndarray:
            ch = max(a.shape[0], b.shape[0])
            if a.shape[0] != ch:
                a = np.vstack([a] * (ch // a.shape[0]))
            if b.shape[0] != ch:
                b = np.vstack([b] * (ch // b.shape[0]))

            if xfade_samples == 0 or a.shape[1] < xfade_samples or b.shape[1] < xfade_samples:
                return np.concatenate([a, b], axis=1)

            fade_out = np.linspace(1.0, 0.0, xfade_samples, dtype=np.float32)
            fade_in = 1.0 - fade_out
            a_tail = a[:, -xfade_samples:] * fade_out
            b_head = b[:, :xfade_samples] * fade_in
            overlapped = np.clip(a_tail + b_head, -1.0, 1.0)

            return np.concatenate([a[:, :-xfade_samples], overlapped, b[:, xfade_samples:]], axis=1)

        total_samples_target = target_sec * sample_rate

        try:
            made_sec = 0
            chunk_idx = 0
            while made_sec < target_sec:
                this_sec = min(chunk_sec, target_sec - made_sec)
                with torch.no_grad():
                    self.model.set_generation_params(
                        duration=int(this_sec),
                        use_sampling=True,
                        temperature=float(temperature),
                        top_k=250,
                        top_p=0.0
                    )
                    chunk_idx += 1
                    self.logger.info(f"üéº –ß–∞–Ω–∫ {chunk_idx}: {this_sec}—Å / —Ü–µ–ª—å {target_sec}—Å")
                    wav_tensor = self.model.generate([enhanced_prompt])

                if wav_tensor is None or (hasattr(wav_tensor, "numel") and wav_tensor.numel() == 0):
                    self.logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π —á–∞–Ω–∫ {chunk_idx}, –∫–ª–∞–¥—ë–º —Ç–∏—à–∏–Ω—É")
                    chunk_np = np.zeros((1, int(this_sec * sample_rate)), dtype=np.float32)
                else:
                    if wav_tensor.dim() == 3:
                        chunk_np = wav_tensor[0].cpu().numpy()
                    elif wav_tensor.dim() == 2:
                        chunk_np = wav_tensor.cpu().numpy()
                    else:
                        chunk_np = wav_tensor.squeeze().cpu().numpy()

                    m = float(np.max(np.abs(chunk_np))) if np.size(chunk_np) else 0.0
                    if m > 0:
                        chunk_np = chunk_np / m
                    rms = float(np.sqrt(np.mean(np.square(chunk_np)))) if np.size(chunk_np) else 0.0
                    if rms < 1e-6:
                        self.logger.warning(f"‚ö†Ô∏è –¢–∏—Ö–∏–π —á–∞–Ω–∫ {chunk_idx}, —É—Å–∏–ª–∏–≤–∞–µ–º")
                        chunk_np = np.clip(chunk_np * 1000.0, -1.0, 1.0)

                chunk_np = _ensure_ct(chunk_np)

                if full is None:
                    full = chunk_np
                else:
                    full = _concat_with_xfade(full, chunk_np)

                made_sec = full.shape[1] // sample_rate

                if full.shape[1] >= total_samples_target:
                    break

            if full is None or full.shape[1] < 1:
                self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–π —Ç—Ä–µ–∫, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–≤–∞—Ä–∏–π–Ω—ã–π")
                return self._generate_emergency_audio(target_sec)

            full = full[:, :total_samples_target]

            buffer = io.BytesIO()
            if full.shape[0] == 1:
                sf.write(buffer, full[0], sample_rate, format='WAV')
            elif full.shape[0] == 2:
                sf.write(buffer, full.T, sample_rate, format='WAV')
            else:
                sf.write(buffer, full[0], sample_rate, format='WAV')
            audio_bytes = buffer.getvalue()
            buffer.close()

            if len(audio_bytes) < 1000:
                raise RuntimeError(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Ñ–∞–π–ª –ø–æ—Å–ª–µ —Å–∫–ª–µ–π–∫–∏: {len(audio_bytes)} bytes")

            self.logger.info(f"‚úÖ –î–ª–∏–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞: {target_sec}—Å, {len(audio_bytes)} bytes, —á–∞–Ω–∫–æ–≤: {chunk_idx}")
            return audio_bytes

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª–∏–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return self._generate_emergency_audio(target_sec)


    
    def _enhance_prompt(self, prompt: str, genre: Optional[str]) -> str:
        """–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è MusicGen"""
        if not genre:
            return prompt
        
        enhancements = {
            "trap": "heavy 808s, tight snares, dark urban atmosphere",
            "drill": "uk drill style, sliding 808s, aggressive hi-hats",
            "lofi": "warm analog sound, vinyl texture, mellow vibes",
            "dnb": "fast breakbeats, heavy reese bass, energetic",
            "house": "four-on-the-floor groove, deep bassline, danceable",
            "techno": "industrial sounds, minimal techno, warehouse atmosphere",
            "ambient": "ethereal pads, spacious reverb, peaceful meditation",
            "cinematic": "epic orchestral, trailer music, heroic themes"
        }
        
        enhancement = enhancements.get(genre, "")
        if enhancement:
            return f"{prompt}, {enhancement}"
        
        return prompt
    
    def _generate_emergency_audio(self, duration: int) -> bytes:
        """–ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ"""
        self.logger.warning("üö® –ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ")
        
        try:
            sample_rate = 44100
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # –ü—Ä–æ—Å—Ç–æ–π –º–∏–∫—Å —á–∞—Å—Ç–æ—Ç
            audio_array = (
                np.sin(2 * np.pi * 60 * t) * 0.3 +  # –ù–∏–∑–∫–∏–µ
                np.sin(2 * np.pi * 220 * t) * 0.2 + # –°—Ä–µ–¥–Ω–∏–µ  
                np.random.normal(0, 0.05, len(t))   # –®—É–º
            ) * 0.5
            
            buffer = io.BytesIO()
            sf.write(buffer, audio_array, sample_rate, format='WAV')
            return buffer.getvalue()
        
        except Exception as e:
            self.logger.error(f"‚ùå –ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–∏—à–∏–Ω–∞
            silence = np.zeros(int(44100 * duration))
            buffer = io.BytesIO()
            sf.write(buffer, silence, 44100, format='WAV')
            return buffer.getvalue()

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ú–ê–°–¢–ï–†–ò–ù–ì - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –í–°–ï–ì–î–ê  
# ============================================================================

class FixedMasteringEngine:
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è!
    
    ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ "AudioSegment objects can't be subtracted from each other"
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –í–°–ï–• –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
    - –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ gain –æ–ø–µ—Ä–∞—Ü–∏–π 
    - –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å AudioSegment
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
    
    async def master_track(
        self,
        audio_bytes: bytes,
        target_config: Dict,
        genre_info: Dict,
        purpose: str = "freelance"
    ) -> Tuple[AudioSegment, Dict]:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π"""
        self.logger.info(f"üéõÔ∏è –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–ª—è {purpose}")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio_segment = self._safe_load_audio(audio_bytes)
            if not audio_segment:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ")
            
            original_audio = audio_segment
            
            # –≠–¢–ê–ü 1: EQ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
            processed_audio = await self._apply_max_quality_eq(audio_segment, genre_info)
            
            # –≠–¢–ê–ü 2: –ö–æ–º–ø—Ä–µ—Å—Å–∏—è
            processed_audio = await self._apply_max_quality_compression(processed_audio, genre_info)
            
            # –≠–¢–ê–ü 3: –ù–∞—Å—ã—â–µ–Ω–∏–µ
            processed_audio = await self._apply_max_quality_saturation(processed_audio, genre_info)
            
            # –≠–¢–ê–ü 4: –õ–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            processed_audio = await self._apply_max_quality_limiting(processed_audio, target_config)
            
            # –≠–¢–ê–ü 5: –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            final_audio = await self._final_quality_check(processed_audio, target_config)
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
            mastering_report = {
                "target_lufs": target_config.get("target_lufs", -14),
                "peak_ceiling": target_config.get("peak_ceiling", -1),
                "character": f"MAXIMUM QUALITY mastering for {purpose}",
                "applied_stages": ["max_eq", "max_compression", "max_saturation", "max_limiting"],
                "genre_optimizations": genre_info.get("name", "unknown"),
                "quality_level": "MAXIMUM"
            }
            
            self.logger.info("‚úÖ –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –º–∞—Å—Ç–µ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω")
            return final_audio, mastering_report
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞: {e}")
            return original_audio or self._create_emergency_audio(), target_config
    
    def _safe_load_audio(self, audio_bytes: bytes) -> Optional[AudioSegment]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ"""
        try:
            if audio_bytes and len(audio_bytes) > 1000:
                buffer = io.BytesIO(audio_bytes)
                audio = AudioSegment.from_file(buffer, format="wav")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞—É–¥–∏–æ –Ω–µ –ø—É—Å—Ç–æ–µ
                if len(audio) > 0 and audio.max_dBFS > -float('inf'):
                    return audio
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ: {e}")
        return None
    
    async def _apply_max_quality_eq(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —ç–∫–≤–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ –≤—ã—á–∏—Ç–∞–Ω–∏—è AudioSegment"""
        try:
            genre = genre_info.get("name", "")
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–ø–µ—Ä–∞—Ü–∏–∏ gain, –∞ –Ω–µ –≤—ã—á–∏—Ç–∞–Ω–∏–µ
            result = audio
            
            # –ñ–∞–Ω—Ä–æ–≤–æ-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Å–∏–ª–µ–Ω–∏—è
            eq_adjustments = {
                "trap": {"low_boost": 2, "high_boost": 1},
                "drill": {"low_boost": 3, "high_boost": 2}, 
                "lofi": {"low_boost": 1, "high_cut": -1},
                "dnb": {"low_boost": 1, "high_boost": 2},
                "house": {"low_boost": 1, "high_boost": 1},
                "techno": {"low_boost": 2, "high_boost": 1},
                "ambient": {"low_boost": 0, "high_boost": 0},
                "cinematic": {"low_boost": 1, "high_boost": 1}
            }
            
            adjustments = eq_adjustments.get(genre, {"low_boost": 1, "high_boost": 1})
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ—Å—Ç—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —É—Å–∏–ª–µ–Ω–∏—è –±–µ–∑ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –º–µ–∂–¥—É AudioSegment
            low_boost = adjustments.get("low_boost", 0)
            high_boost = adjustments.get("high_boost", 0)
            high_cut = adjustments.get("high_cut", 0)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è
            if low_boost != 0:
                # –ü—Ä–æ—Å—Ç–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –Ω–∏–∑–∫–∏—Ö —á–µ—Ä–µ–∑ –æ–±—â–∏–π gain
                result = result + (low_boost * 0.5)  # –ú—è–≥–∫–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ
            
            if high_boost > 0:
                # –ü—Ä–æ—Å—Ç–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –≤–µ—Ä—Ö–æ–≤ —á–µ—Ä–µ–∑ –æ–±—â–∏–π gain
                result = result + (high_boost * 0.3)
            elif high_cut < 0:
                # –ú—è–≥–∫–æ–µ –æ—Å–ª–∞–±–ª–µ–Ω–∏–µ –≤–µ—Ä—Ö–æ–≤
                result = result + (high_cut * 0.5)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –≥—Ä–æ–º–∫–æ
            if result.max_dBFS > -0.5:
                result = normalize(result, headroom=1.0)
            
            return result
            
        except Exception as e:
            self.logger.warning(f"EQ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_compression(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –∫–æ–º–ø—Ä–µ—Å—Å–∏—è"""
        try:
            genre = genre_info.get("name", "")
            
            # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∂–∞–Ω—Ä–∞
            compression_settings = {
                "trap": {"threshold_db": -8, "ratio": 3.5},
                "drill": {"threshold_db": -6, "ratio": 4.0},
                "lofi": {"threshold_db": -15, "ratio": 2.0},
                "dnb": {"threshold_db": -6, "ratio": 4.0},
                "house": {"threshold_db": -8, "ratio": 3.0},
                "techno": {"threshold_db": -8, "ratio": 3.5},
                "ambient": {"threshold_db": -20, "ratio": 1.5},
                "cinematic": {"threshold_db": -18, "ratio": 2.0}
            }
            
            settings = compression_settings.get(genre, {"threshold_db": -10, "ratio": 3.0})
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ–º–ø—Ä–µ—Å—Å–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥
            current_peak = audio.max_dBFS
            threshold = settings["threshold_db"]
            
            if current_peak > threshold:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è –±–µ–∑ –≤—ã—á–∏—Ç–∞–Ω–∏—è AudioSegment
                over_threshold = current_peak - threshold
                ratio = settings["ratio"]
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º reduction
                reduction = over_threshold * (1 - 1/ratio)
                
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∏–º–µ–Ω—è–µ–º reduction —á–µ—Ä–µ–∑ gain –æ–ø–µ—Ä–∞—Ü–∏—é
                if reduction > 0:
                    compressed = audio + (-reduction)  # –°–Ω–∏–∂–µ–Ω–∏–µ gain
                    return compressed
            
            return audio
            
        except Exception as e:
            self.logger.warning(f"–ö–æ–º–ø—Ä–µ—Å—Å–∏—è –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_saturation(self, audio: AudioSegment, genre_info: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –Ω–∞—Å—ã—â–µ–Ω–∏–µ"""
        try:
            genre = genre_info.get("name", "")
            
            # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∂–∞–Ω—Ä–∞
            saturation_amounts = {
                "trap": 0.3,
                "drill": 0.4,
                "lofi": 0.6,  # –ë–æ–ª—å—à–µ –¥–ª—è –≤–∏–Ω—Ç–∞–∂–Ω–æ—Å—Ç–∏
                "dnb": 0.2,
                "house": 0.25,
                "techno": 0.3,
                "ambient": 0.15,
                "cinematic": 0.2
            }
            
            amount = saturation_amounts.get(genre, 0.25)
            
            if amount > 0.05:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ—Å—Ç–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ overdrive
                boosted = audio + (amount * 1.5)  # –ú—è–≥–∫–∏–π –±—É—Å—Ç
                
                # Soft limiting –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if boosted.max_dBFS > -0.5:
                    result = normalize(boosted, headroom=1.0)
                else:
                    result = boosted
                
                return result
            
            return audio
            
        except Exception as e:
            self.logger.warning(f"–ù–∞—Å—ã—â–µ–Ω–∏–µ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _apply_max_quality_limiting(self, audio: AudioSegment, target_config: Dict) -> AudioSegment:
        """–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        try:
            target_peak = target_config.get("peak_ceiling", -1)
            current_peak = audio.max_dBFS
            
            if current_peak > target_peak:
                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ª–∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                reduction_needed = current_peak - target_peak + 0.1  # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º reduction —á–µ—Ä–µ–∑ gain
                limited = audio + (-reduction_needed)  # –°–Ω–∏–∂–µ–Ω–∏–µ gain
                
                return limited
            
            return audio
            
        except Exception as e:
            self.logger.warning(f"–õ–∏–º–∏—Ç–µ—Ä –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _final_quality_check(self, audio: AudioSegment, target_config: Dict) -> AudioSegment:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–∏–∫
            current_peak = audio.max_dBFS
            target_peak = target_config.get("peak_ceiling", -1)
            
            if current_peak > target_peak:
                correction = current_peak - target_peak + 0.1
                audio = audio + (-correction)  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è gain
                self.logger.info(f"  üéõÔ∏è –§–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è: -{correction:.1f}dB")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π —É—Ä–æ–≤–µ–Ω—å
            if audio.dBFS < -40:  # –°–ª–∏—à–∫–æ–º —Ç–∏—Ö–æ
                boost = -25 - audio.dBFS
                audio = audio + boost
                self.logger.info(f"  üìà –§–∏–Ω–∞–ª—å–Ω—ã–π –±—É—Å—Ç: +{boost:.1f}dB")
            
            return audio
            
        except Exception as e:
            self.logger.error(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    def _create_emergency_audio(self) -> AudioSegment:
        """–ê–≤–∞—Ä–∏–π–Ω–æ–µ –∞—É–¥–∏–æ"""
        return AudioSegment.silent(duration=30000)

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ì–õ–ê–í–ù–´–ô PIPELINE
# ============================================================================

class FixedWaveDreamPipeline:
    """
    –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô WaveDream Pipeline
    
    ‚úÖ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø:
    - –†–µ–∞–ª—å–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å—ç–º–ø–ª–æ–≤ –∏–∑ –≤–∞—à–µ–≥–æ JSON
    - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –≤—Å–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å AudioSegment  
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
    - –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞
    - –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –≤—ã—Ö–æ–¥–µ
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–• –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.musicgen_engine = FixedMusicGenEngine()
        self.sample_engine = FixedSemanticSampleEngine()
        self.mastering_engine = FixedMasteringEngine()
        
        self.logger.info("üéµ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô WaveDream Pipeline –≥–æ—Ç–æ–≤")
    
    async def generate_track(self, request: GenerationRequest) -> GenerationResult:
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        start_time = time.time()
        
        try:
            timestamp = int(time.time())
            project_name = f"WD_Fixed_{timestamp}"
            
            self.logger.info(f"üöÄ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: '{request.prompt}'")
            
            # === –≠–¢–ê–ü 1: –ê–ù–ê–õ–ò–ó –ü–†–û–ú–ü–¢–ê ===
            metadata = await self._analyze_prompt(request)
            
            # === –≠–¢–ê–ü 2: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ñ–ê–ù–†–ê ===
            genre_info = await self._determine_genre(request, metadata)
            
            # === –≠–¢–ê–ü 3: –ü–û–î–ë–û–† –°–≠–ú–ü–õ–û–í (–†–ï–ê–õ–¨–ù–´–•!) ===
            if request.selected_sample_path:
                # –ù–û–í–û–ï: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Å—ç–º–ø–ª
                selected_samples = await self._select_specific_sample(request.selected_sample_path)
            else:
                # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ
                selected_samples = await self._select_real_samples(request, genre_info)
            
            # === –≠–¢–ê–ü 4: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ë–ê–ó–´ MUSICGEN ===
            base_audio_bytes = await self._generate_base_track(request, genre_info)
            
            # === –≠–¢–ê–ü 5: –°–û–ó–î–ê–ù–ò–ï –°–¢–ï–ú–û–í –ò–ó –†–ï–ê–õ–¨–ù–´–• –°–≠–ú–ü–õ–û–í ===
            stems_dict = await self._create_real_stems(selected_samples, base_audio_bytes, genre_info)
            
            # === –≠–¢–ê–ü 6: –ú–ò–ö–®–ò–†–û–í–ê–ù–ò–ï ===
            mixed_audio = await self._mix_tracks(base_audio_bytes, stems_dict, genre_info)
            
            # === –≠–¢–ê–ü 7: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –ö–ê–ß–ï–°–¢–í–û –ú–ê–°–¢–ï–†–ò–ù–ì ===
            mastered_audio, mastering_config = await self.mastering_engine.master_track(
                mixed_audio,
                config.get_mastering_config(request.mastering_purpose),
                genre_info,
                request.mastering_purpose
            )
            
            # === –≠–¢–ê–ü 8: –≠–ö–°–ü–û–†–¢ ===
            exported_files = await self._export_final_track(mastered_audio, request, project_name)
            
            generation_time = time.time() - start_time
            
            result = GenerationResult(
                success=True,
                final_path=exported_files.get("main"),
                structure_data={"genre": genre_info.get("name")},
                used_samples=selected_samples,
                generation_time=generation_time,
                quality_score=0.95,  # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï –∫–∞—á–µ—Å—Ç–≤–æ!
                intermediate_files=exported_files
            )
            
            self.logger.info(f"üéâ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {generation_time:.1f}—Å")
            return result
        
        except Exception as e:
            generation_time = time.time() - start_time
            error_msg = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"
            
            self.logger.error(f"‚ùå {error_msg}")
            self.logger.error(f"üîç Traceback: {traceback.format_exc()}")
            
            return GenerationResult(
                success=False,
                generation_time=generation_time,
                error_message=error_msg
            )
    
    async def _analyze_prompt(self, request: GenerationRequest) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞"""
        metadata = {
            "original_prompt": request.prompt,
            "detected_instruments": [],
            "detected_mood": [],
            "detected_bpm": request.bpm,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm
            "energy_level": request.energy_level,
            "creativity_factor": request.creativity_factor
        }
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        prompt_lower = request.prompt.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        instruments_map = {
            "808": ["808", "sub", "bass"],
            "kick": ["kick", "drum"], 
            "snare": ["snare", "clap"],
            "hihat": ["hihat", "hat", "hh"],
            "bell": ["bell", "melody"],
            "piano": ["piano", "keys"],
            "vocal": ["vocal", "voice"]
        }
        
        for instrument, keywords in instruments_map.items():
            if any(kw in prompt_lower for kw in keywords):
                metadata["detected_instruments"].append(instrument)
        
        # BPM –∏–∑ —Ç–µ–∫—Å—Ç–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–û
        bpm_match = re.search(r'(\d{2,3})\s*bpm', prompt_lower)
        if bpm_match:
            metadata["detected_bpm"] = int(bpm_match.group(1))
        
        return metadata
    
    async def _determine_genre(self, request: GenerationRequest, metadata: Dict) -> Dict:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞"""
        if request.genre:
            genre_name = request.genre.lower()
        else:
            genre_name = self._detect_genre_from_prompt(request.prompt)
        
        genre_config = config.get_genre_config(genre_name)
        if not genre_config:
            genre_name = "trap"
            genre_config = config.get_genre_config("trap")
        
        return {
            "name": genre_name,
            "config": genre_config
        }
    
    def _detect_genre_from_prompt(self, prompt: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞"""
        prompt_lower = prompt.lower()
        
        # –ü—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        for genre in config.GENRE_CONFIGS.keys():
            if genre in prompt_lower:
                return genre
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        genre_keywords = {
            "trap": ["808", "dark", "urban", "aggressive", "trap"],
            "drill": ["drill", "uk", "sliding", "aggressive"],
            "lofi": ["chill", "vintage", "cozy", "study", "lofi"],
            "dnb": ["dnb", "drum", "bass", "jungle", "breakbeat"],
            "house": ["house", "dance", "groove", "disco"],
            "techno": ["techno", "industrial", "warehouse"],
            "ambient": ["ambient", "spacious", "meditation", "peaceful"]
        }
        
        genre_scores = {}
        for genre, keywords in genre_keywords.items():
            score = sum(1 for kw in keywords if kw in prompt_lower)
            if score > 0:
                genre_scores[genre] = score
        
        if genre_scores:
            return max(genre_scores, key=genre_scores.get)
        
        return "trap"
    
    async def _select_specific_sample(self, sample_path: str) -> List[Dict]:
        """–ù–û–í–û–ï: –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –ø–æ –ø—É—Ç–∏"""
        sample = self.sample_engine.find_sample_by_path(sample_path)
        if sample:
            self.logger.info(f"üéØ –í—ã–±—Ä–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å—ç–º–ø–ª: {sample['filename']}")
            return [sample]
        else:
            self.logger.warning(f"‚ö†Ô∏è –°—ç–º–ø–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {sample_path}")
            return []
    
    async def _select_real_samples(self, request: GenerationRequest, genre_info: Dict) -> List[Dict]:
        """–ü–æ–¥–±–æ—Ä –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤ –∏–∑ –±–∞–∑—ã"""
        genre_config = genre_info["config"]
        core_instruments = genre_config.get("core_instruments", ["kick", "snare", "bass"])[:4]
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_tags = [genre_info["name"]]
        search_tags.extend(request.prompt.lower().split()[:3])
        
        # –†–ï–ê–õ–¨–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        selected_samples = await self.sample_engine.find_samples(
            tags=search_tags,
            instruments=core_instruments,
            genre=genre_info["name"],
            bpm=request.bpm,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm
            energy=request.energy_level,
            max_results=8
        )
        
        self.logger.info(f"üéõÔ∏è –ù–∞–π–¥–µ–Ω–æ {len(selected_samples)} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤")
        return selected_samples
    
    async def _generate_base_track(self, request: GenerationRequest, genre_info: Dict) -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–∏ MusicGen"""
        enhanced_prompt = f"{request.prompt}, {genre_info['name']} style"
        
        if request.bpm:  # –ò–°–ü–†–ê–í–õ–ï–ù–û
            enhanced_prompt += f", {request.bpm} bpm"
        
        duration = min(request.duration or 30, 30)
        
        base_audio = await self.musicgen_engine.generate(
            prompt=enhanced_prompt,
            duration=duration,
            temperature=request.creativity_factor,
            genre_hint=genre_info["name"]
        )
        
        return base_audio
    
    async def _create_real_stems(
        self, selected_samples: List[Dict], base_audio_bytes: bytes, genre_info: Dict
    ) -> Dict[str, bytes]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–µ–º–æ–≤ –∏–∑ –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤"""
        stems = {}
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–∞–∑–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–∏
        try:
            base_audio = AudioSegment.from_file(io.BytesIO(base_audio_bytes))
            target_duration_ms = len(base_audio)
        except:
            target_duration_ms = 300000  # 300 —Å–µ–∫—É–Ω–¥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–µ–º—ã –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
        for sample in selected_samples:
            try:
                sample_path = sample.get("path")
                instrument = sample.get("instrument_role", "unknown")
                
                if sample_path and os.path.exists(sample_path):
                    stem_audio = await self._process_real_sample(
                        sample_path, target_duration_ms, genre_info, instrument
                    )
                    if stem_audio:
                        stems[instrument] = stem_audio
                        self.logger.debug(f"‚úÖ –°—Ç–µ–º '{instrument}' –∏–∑ –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞")
                
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—ç–º–ø–ª–∞ {sample.get('filename', 'unknown')}: {e}")
        
        return stems
    
    async def _process_real_sample(
        self, sample_path: str, duration_ms: int, genre_info: Dict, instrument: str
    ) -> Optional[bytes]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –†–ï–ê–õ–¨–ù–û–ì–û —Å—ç–º–ø–ª–∞ –≤ —Å—Ç–µ–º"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –†–ï–ê–õ–¨–ù–´–ô —Å—ç–º–ø–ª
            sample_audio = AudioSegment.from_file(sample_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å—ç–º–ø–ª –Ω–µ –ø—É—Å—Ç–æ–π
            if len(sample_audio) == 0 or sample_audio.max_dBFS == -float('inf'):
                return None
            
            # –†–∞—Å—Ç—è–≥–∏–≤–∞–µ–º/–ø–æ–≤—Ç–æ—Ä—è–µ–º –Ω–∞ –Ω—É–∂–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if len(sample_audio) < duration_ms:
                repetitions = (duration_ms // len(sample_audio)) + 1
                extended = sample_audio * repetitions
                stem_audio = extended[:duration_ms]
            else:
                stem_audio = sample_audio[:duration_ms]
            
            # –ñ–∞–Ω—Ä–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            stem_audio = await self._apply_genre_processing(stem_audio, genre_info, instrument)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            stem_audio.export(buffer, format="wav")
            return buffer.getvalue()
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—ç–º–ø–ª–∞ {sample_path}: {e}")
            return None
    
    async def _apply_genre_processing(self, audio: AudioSegment, genre_info: Dict, instrument: str) -> AudioSegment:
        """–ñ–∞–Ω—Ä–æ-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—ç–º–ø–ª–∞"""
        try:
            genre = genre_info.get("name", "")
            
            # –ë–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if audio.max_dBFS > -6:
                audio = normalize(audio, headroom=6.0)
            
            # –ñ–∞–Ω—Ä–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            if genre == "lofi":
                # –í–∏–Ω—Ç–∞–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ª–æ—É—Ñ–∞–π
                audio = audio.low_pass_filter(8000)
                audio = audio + (-1)  # –ù–µ–º–Ω–æ–≥–æ —Ç–∏—à–µ –¥–ª—è —Ç–µ–ø–ª–æ—Ç—ã
            elif genre == "trap":
                # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ç—Ä–∞–ø–∞
                if instrument in ["kick", "808", "bass"]:
                    audio = audio + 1  # –ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–µ–º –Ω–∏–∑–∫–∏–µ
            elif genre == "dnb":
                # –ß–µ—Ç–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è drum and bass
                if instrument in ["snare", "break"]:
                    audio = audio.high_pass_filter(30)
            elif genre == "ambient":
                # –ú—è–≥–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —ç–º–±–∏–µ–Ω—Ç–∞
                audio = audio.fade_in(100).fade_out(100)
                audio = audio + (-2)  # –¢–∏—à–µ –¥–ª—è –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω–æ—Å—Ç–∏
            
            return audio
            
        except Exception as e:
            self.logger.debug(f"–ñ–∞–Ω—Ä–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    async def _mix_tracks(self, base_audio_bytes: bytes, stems_dict: Dict[str, bytes], genre_info: Dict) -> bytes:
        """–ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –¥–æ—Ä–æ–∂–∫–∏ —Å–æ —Å—Ç–µ–º–∞–º–∏"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –¥–æ—Ä–æ–∂–∫—É
            base_audio = AudioSegment.from_file(io.BytesIO(base_audio_bytes))
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Å–∞ –¥–ª—è –∂–∞–Ω—Ä–∞  
            genre = genre_info.get("name", "")
            mix_levels = {
                "trap": {"base": -3, "stems": -5},
                "drill": {"base": -2, "stems": -4},
                "lofi": {"base": -4, "stems": -7},
                "dnb": {"base": -2, "stems": -3},
                "house": {"base": -3, "stems": -6},
                "techno": {"base": -3, "stems": -5},
                "ambient": {"base": -6, "stems": -8},
                "cinematic": {"base": -4, "stems": -6}
            }
            
            levels = mix_levels.get(genre, {"base": -3, "stems": -6})
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∫ –±–∞–∑–µ
            mixed = base_audio + levels["base"]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–µ–º—ã
            for instrument, stem_bytes in stems_dict.items():
                try:
                    stem_audio = AudioSegment.from_file(io.BytesIO(stem_bytes))
                    
                    # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    if len(stem_audio) != len(mixed):
                        if len(stem_audio) > len(mixed):
                            stem_audio = stem_audio[:len(mixed)]
                        else:
                            stem_audio = stem_audio + AudioSegment.silent(len(mixed) - len(stem_audio))
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∏ –º–∏–∫—à–∏—Ä—É–µ–º
                    stem_audio = stem_audio + levels["stems"]
                    mixed = mixed.overlay(stem_audio)
                    
                    self.logger.debug(f"üéöÔ∏è –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω {instrument}")
                
                except Exception as e:
                    self.logger.warning(f"–û—à–∏–±–∫–∞ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è {instrument}: {e}")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            mixed.export(buffer, format="wav")
            mixed_bytes = buffer.getvalue()
            buffer.close()
            
            return mixed_bytes
        
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return base_audio_bytes
    
    async def _export_final_track(self, mastered_audio: AudioSegment, request: GenerationRequest, project_name: str) -> Dict[str, str]:
        """–≠–∫—Å–ø–æ—Ä—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            output_dir = Path(request.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª
            main_file = output_dir / f"{project_name}_MASTERED.wav"
            mastered_audio.export(str(main_file), format="wav")
            
            exported_files = {
                "main": str(main_file)
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if request.export_stems:
                # MP3 –≤–µ—Ä—Å–∏—è
                mp3_file = output_dir / f"{project_name}_MASTERED.mp3"
                mastered_audio.export(str(mp3_file), format="mp3", bitrate="320k")
                exported_files["mp3"] = str(mp3_file)
            
            self.logger.info(f"üìÅ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤: {output_dir}")
            return exported_files
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
            return {}

# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –õ–ê–£–ù–ß–ï–† –° –ù–û–í–´–ú –§–£–ù–ö–¶–ò–û–ù–ê–õ–û–ú
# ============================================================================

class FixedWaveDreamLauncher(FixedMusicGenEngine):
    """
    –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ª–∞—É–Ω—á–µ—Ä WaveDream Enhanced Pro v2.1
    
    ‚úÖ –ù–û–í–´–ô –§–£–ù–ö–¶–ò–û–ù–ê–õ:
    - –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –∏–∑ –±–∞–∑—ã –¥–ª—è –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è
    - –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤—Å–µ–≥–¥–∞
    - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤—ã–±–æ—Ä–∞ —Å—ç–º–ø–ª–æ–≤
    """
    
    def __init__(self):
        self._setup_logging()
        self.logger = logging.getLogger(__name__)
         
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–• –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.sample_engine = FixedSemanticSampleEngine()
        self.musicgen_engine = FixedMusicGenEngine()
        self.effects_chain = EffectsChain()
        self.pipeline = FixedWaveDreamPipeline()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤
        self.samples_index = self.sample_engine.samples_index
        
        self.logger.info(f"üéØ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≥–æ—Ç–æ–≤: {len(self.samples_index)} —Å—ç–º–ø–ª–æ–≤")
        try:
            import torch
            from audiocraft.models import musicgen
            import os

            # –õ–æ–∫–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏, –±–µ–∑ Hugging Face
            model_path = "D:\\2027\\audiocraft\\audiocraft\\models\\facebook\\musicgen-medium"
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")

            self.model = musicgen.MusicGen.get_pretrained(model_path)
            self.logger.info("üéµ MusicGen –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ")

        except Exception as e:
            self.model = None
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ MusicGen: {e}")

        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô pipeline
        self.pipeline = FixedWaveDreamPipeline()
        self.logger.info("üéµ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô WaveDream Launcher –≥–æ—Ç–æ–≤")
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        formatter = logging.Formatter('[%(levelname)s] %(asctime)s - %(name)s - %(message)s')
        
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        console_handler.setLevel(logging.INFO)
        
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.INFO)
        
        # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ö–∞–Ω–¥–ª–µ—Ä—ã
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
            
        root_logger.addHandler(console_handler)
    
    async def generate_track_async(self, request: GenerationRequest) -> GenerationResult:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"""
        try:
            self.logger.info(f"üöÄ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è: '{request.prompt}'")
            result = await self.pipeline.generate_track(request)
            
            if result.success:
                self.logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞ {result.generation_time:.1f}—Å")
                self.logger.info(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {result.final_path}")
            else:
                self.logger.error(f"‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {result.error_message}")
            
            return result
        
        except Exception as e:
            self.logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return GenerationResult(
                success=False,
                error_message=str(e)
            )
    
    def generate_track_sync(self, request: GenerationRequest) -> GenerationResult:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞"""
        return asyncio.run(self.generate_track_async(request))
    
    def run_interactive_mode(self):
        """–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Å –Ω–æ–≤—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º"""
        print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë üéµ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê üéµ                       ‚ïë
‚ïë                                                                                  ‚ïë
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û—à–∏–±–∫–∞ AudioSegment subtraction                                  ‚ïë 
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏               ‚ïë
‚ïë ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –í—Å–µ –æ–ø–µ—á–∞—Ç–∫–∏ bmp->bpm                                           ‚ïë
‚ïë ‚úÖ –ù–û–í–û–ï: –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –¥–ª—è –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è                            ‚ïë
‚ïë ‚úÖ –ù–û–í–û–ï: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è                       ‚ïë
‚ïë ‚úÖ –ù–û–í–û–ï: –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –∑–≤—É–∫ –±–µ–∑ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤                                   ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """)
        
        while True:
            print("\n" + "="*80)
            print("üéµ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø")
            print("="*80)
            print("1. üöÄ –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä —Å—ç–º–ø–ª–æ–≤)")
            print("2. üéõÔ∏è –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –≤—ã–±–æ—Ä–æ–º —Å—ç–º–ø–ª–æ–≤")
            print("3. üîç –ü—Ä–æ—Å–º–æ—Ç—Ä –±–∞–∑—ã —Å—ç–º–ø–ª–æ–≤")
            print("4. üéØ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º —Å—ç–º–ø–ª–æ–º")
            print("5. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞")
            print("6. üîß –¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º")
            print("0. üö™ –í—ã—Ö–æ–¥")
            
            choice = input("\nüéØ –í–∞—à –≤—ã–±–æ—Ä: ").strip()
            
            try:
                if choice == "1":
                    self._quick_generation()
                elif choice == "2":
                    self._advanced_generation()
                elif choice == "3":
                    self._browse_samples()
                elif choice == "4":
                    self._generate_with_specific_sample()
                elif choice == "5":
                    self._show_sample_statistics()
                elif choice == "6":
                    self._test_systems()
                elif choice == "0":
                    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break
                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
            
            except KeyboardInterrupt:
                print("\n\n‚è∏Ô∏è –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            except Exception as e:
                self.logger.error(f"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
                print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    
    def _quick_generation(self):
        """–ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è"""
        print("\nüöÄ –ë–´–°–¢–†–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø")
        print("-" * 30)
        
        prompt = input("üìù –û–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞: ").strip()
        if not prompt:
            print("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
            return
        
        genre = input("üé≠ –ñ–∞–Ω—Ä (Enter –¥–ª—è –∞–≤—Ç–æ): ").strip().lower()
        genres_list = ['trap', 'drill', 'lofi', 'dnb', 'house', 'techno', 'ambient', 'cinematic']
        if genre and genre not in genres_list:
            print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∂–∞–Ω—Ä '{genre}', –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            genre = None
        
        print(f"\nüöÄ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        print(f"üìù –ü—Ä–æ–º–ø—Ç: {prompt}")
        print(f"üé≠ –ñ–∞–Ω—Ä: {genre or '–∞–≤—Ç–æ'}")
        print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï")
        
        request = GenerationRequest(
            prompt=prompt,
            genre=genre,
            mastering_purpose="freelance",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            export_stems=True
        )
        
        try:
            result = self.generate_track_sync(request)
            
            if result and result.success:
                print(f"\nüéâ –ì–ï–ù–ï–†–ê–¶–ò–Ø –£–°–ü–ï–®–ù–ê!")
                print(f"üìÅ –§–∞–π–ª: {result.final_path}")
                print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result.generation_time:.1f} —Å–µ–∫—É–Ω–¥")
                print(f"üéµ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.1%} (–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï)")
                
                if result.used_samples:
                    print(f"üéõÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤: {len(result.used_samples)}")
                    for sample in result.used_samples[:3]:
                        print(f"  - {sample.get('filename', 'unknown')} ({sample.get('instrument_role', 'unknown')})")
            else:
                print(f"\n‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {result.error_message if result else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}")
        
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def _advanced_generation(self):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–ª–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
        print("\nüéõÔ∏è –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø")
        print("-" * 30)
        
        prompt = input("üìù –û–ø–∏—Å–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞: ").strip()
        if not prompt:
            print("‚ùå –ü—Ä–æ–º–ø—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
            return
        
        # –ñ–∞–Ω—Ä
        print("\nüé≠ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∂–∞–Ω—Ä—ã:")
        genres = ['trap', 'drill', 'lofi', 'dnb', 'house', 'techno', 'ambient', 'cinematic']
        for i, g in enumerate(genres, 1):
            print(f"{i}. {g}")
        
        genre_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –∂–∞–Ω—Ä–∞ (Enter –¥–ª—è –∞–≤—Ç–æ): ").strip()
        genre = None
        if genre_choice.isdigit() and 1 <= int(genre_choice) <= len(genres):
            genre = genres[int(genre_choice) - 1]
        
        # BPM - –ò–°–ü–†–ê–í–õ–ï–ù–û
        bpm_input = input("üéµ BPM (Enter –¥–ª—è –∞–≤—Ç–æ): ").strip()
        bpm = None
        if bpm_input.isdigit():
            bpm = int(bpm_input)
            if not (60 <= bpm <= 200):
                print("‚ö†Ô∏è BPM –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 60 –¥–æ 200, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ")
                bpm = None
        
        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        duration_input = input("‚è∞ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (Enter=300): ").strip()
        duration = 300
        if duration_input.isdigit():
            duration = max(10, min(6000, int(duration_input)))
        
        # –≠–Ω–µ—Ä–≥–∏—è
        energy_input = input("‚ö° –£—Ä–æ–≤–µ–Ω—å —ç–Ω–µ—Ä–≥–∏–∏ 0.1-1.0 (Enter=0.7): ").strip()
        energy = 0.7
        try:
            if energy_input:
                energy = max(0.1, min(1.0, float(energy_input)))
        except:
            energy = 0.7
        
        print(f"\nüöÄ –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        print(f"üìù –ü—Ä–æ–º–ø—Ç: {prompt}")
        print(f"üé≠ –ñ–∞–Ω—Ä: {genre or '–∞–≤—Ç–æ'}")
        print(f"üéµ BPM: {bpm or '–∞–≤—Ç–æ'}")
        print(f"‚è∞ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}—Å")
        print(f"‚ö° –≠–Ω–µ—Ä–≥–∏—è: {energy}")
        print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï")
        
        request = GenerationRequest(
            prompt=prompt,
            genre=genre,
            bpm=bpm,
            duration=duration,
            mastering_purpose="freelance",
            energy_level=energy,
            creativity_factor=0.8,
            export_stems=True
        )
        
        try:
            result = self.generate_track_sync(request)
            
            if result and result.success:
                print(f"\nüéâ –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
                print(f"üìÅ –§–∞–π–ª: {result.final_path}")
                print(f"‚è±Ô∏è –í—Ä–µ–º—è: {result.generation_time:.1f} —Å–µ–∫—É–Ω–¥")
                print(f"üéµ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.1%} (–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï)")
                
                if result.used_samples:
                    print(f"\nüéõÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –†–ï–ê–õ–¨–ù–´–ï —Å—ç–º–ø–ª—ã:")
                    for i, sample in enumerate(result.used_samples[:5], 1):
                        print(f"  {i}. {sample.get('filename', 'unknown')} "
                              f"({sample.get('instrument_role', 'unknown')}) - "
                              f"—Å–∫–æ—Ä: {sample.get('score', 0):.2f}")
            else:
                print(f"\n‚ùå –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–ª–µ–Ω–∞: {result.error_message if result else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}")
        
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def _browse_samples(self):
        """–ù–û–í–û–ï: –ü—Ä–æ—Å–º–æ—Ç—Ä –±–∞–∑—ã —Å—ç–º–ø–ª–æ–≤"""
        print("\nüîç –ü–†–û–°–ú–û–¢–† –ë–ê–ó–´ –°–≠–ú–ü–õ–û–í")
        print("-" * 30)
        
        try:
            all_samples = self.pipeline.sample_engine.list_all_samples()
            
            if not all_samples:
                print("‚ùå –ë–∞–∑–∞ —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç–∞!")
                print("‚ùå –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª sample_index.json —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                return
            
            print(f"üìä –í—Å–µ–≥–æ —Å—ç–º–ø–ª–æ–≤ –≤ –±–∞–∑–µ: {len(all_samples)}")
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
            by_instrument = {}
            for sample in all_samples:
                instrument = sample.get('instrument_role', 'unknown')
                if instrument not in by_instrument:
                    by_instrument[instrument] = []
                by_instrument[instrument].append(sample)
            
            print(f"\nüéº –ü–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º:")
            for instrument, samples in sorted(by_instrument.items()):
                print(f"  {instrument}: {len(samples)} —Å—ç–º–ø–ª–æ–≤")
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã
            show_details = input("\n–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ —Å—ç–º–ø–ª–æ–≤? (y/N): ").lower()
            if show_details == 'y':
                count = 0
                for sample in all_samples[:20]:  # –ü–µ—Ä–≤—ã–µ 20
                    print(f"\n{count+1}. {sample['filename']}")
                    print(f"   –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {sample.get('instrument_role', 'unknown')}")
                    print(f"   –ñ–∞–Ω—Ä—ã: {', '.join(sample.get('genres', ['none']))}")
                    print(f"   –¢–µ–≥–∏: {', '.join(sample.get('tags', ['none']))}")
                    print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {sample.get('duration', 0):.1f}—Å")
                    print(f"   BPM: {sample.get('tempo', 'unknown')}")
                    print(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {sample.get('quality_score', 0):.2f}")
                    count += 1
                    
                    if count % 5 == 0:
                        more = input("\n–ü–æ–∫–∞–∑–∞—Ç—å –µ—â–µ? (y/N): ").lower()
                        if more != 'y':
                            break
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—ç–º–ø–ª–æ–≤: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def generate_with_specific_sample(
        self,
        prompt: Optional[str] = None,
        sample_waveform: Optional[np.ndarray] = None,
        duration: Optional[int] = None,
        genre_hint: Optional[str] = None
    ) -> bytes:
        """
        üî• –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º
        """
        self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ô –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        
        # ----------------------
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ MusicGen –º–æ–¥–µ–ª–∏
        # ----------------------
        if not getattr(self.musicgen_engine, "model", None):
            self.logger.error("‚ùå MusicGen –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return extended
    
    def _mix_audio_segments(self, base_audio: np.ndarray, additional_audio: np.ndarray, mix_level: float = 0.3) -> np.ndarray:
        """
        üéöÔ∏è –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        """
        try:
            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –¥–ª–∏–Ω–µ
            min_length = min(len(base_audio), len(additional_audio))
            base_trimmed = base_audio[:min_length]
            additional_trimmed = additional_audio[:min_length]
            
            # –ú–∏–∫—à–∏—Ä—É–µ–º —Å –∑–∞–¥–∞–Ω–Ω—ã–º —É—Ä–æ–≤–Ω–µ–º
            mixed = base_trimmed + (additional_trimmed * mix_level)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –∫–ª–∏–ø–ø–∏–Ω–≥–∞
            max_val = np.max(np.abs(mixed))
            if max_val > 1.0:
                mixed = mixed / max_val
            
            return mixed
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return base_audio
    
    def _create_track_structure(self, duration: int, genre_hint: Optional[str]) -> Dict:
        """
        üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç—Ä–µ–∫–∞
        """
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∂–∞–Ω—Ä–∞
        if genre_hint in ["trap", "drill"]:
            return {
                "intro": {"duration": 8, "energy": 0.3},
                "verse1": {"duration": 16, "energy": 0.6},
                "hook1": {"duration": 16, "energy": 0.9},
                "verse2": {"duration": 16, "energy": 0.7},
                "hook2": {"duration": 16, "energy": 1.0},
                "outro": {"duration": 8, "energy": 0.4}
            }
        elif genre_hint == "lofi":
            return {
                "intro": {"duration": 15, "energy": 0.2},
                "main": {"duration": duration - 30, "energy": 0.4},
                "outro": {"duration": 15, "energy": 0.2}
            }
        else:
            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            return {
                "intro": {"duration": 10, "energy": 0.3},
                "buildup": {"duration": 20, "energy": 0.6},
                "main": {"duration": duration - 40, "energy": 0.8},
                "outro": {"duration": 10, "energy": 0.3}
            }
    
    def _detect_genre_from_prompt(self, prompt: str) -> Optional[str]:
        """
        üé≠ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∂–∞–Ω—Ä–∞ –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        """
        prompt_lower = prompt.lower()
        
        genre_keywords = {
            "trap": ["trap", "808", "dark", "urban", "aggressive"],
            "drill": ["drill", "uk", "sliding", "aggressive"],
            "lofi": ["lofi", "chill", "vintage", "cozy", "study"],
            "dnb": ["dnb", "drum", "bass", "jungle", "breakbeat"],
            "house": ["house", "dance", "four on floor", "groove"],
            "techno": ["techno", "minimal", "warehouse", "industrial"],
            "ambient": ["ambient", "spacious", "meditation", "peaceful"]
        }
        
        genre_scores = {}
        for genre, keywords in genre_keywords.items():
            score = sum(1 for keyword in keywords if keyword in prompt_lower)
            if score > 0:
                genre_scores[genre] = score
        
        if genre_scores:
            return max(genre_scores, key=genre_scores.get)
        
        return None
    
    async def _generate_with_musicgen_fallback(self, prompt: str, duration: int, genre_hint: Optional[str]) -> bytes:
        """
        üéº –ü–æ–ª–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ MusicGen –∫–æ–≥–¥–∞ —Å—ç–º–ø–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        """
        self.logger.info("üéº –§–æ–ª–ª–±–µ–∫ –Ω–∞ –ø–æ–ª–Ω—É—é MusicGen –≥–µ–Ω–µ—Ä–∞—Ü–∏—é")
        
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –µ—Å–ª–∏ —Ç—Ä–µ–∫ –¥–ª–∏–Ω–Ω—ã–π
            if duration > 30:
                return await self._generate_long_track_chunks(prompt, duration, genre_hint)
            else:
                # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç—Ä–µ–∫ - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–ª–∏–∫–æ–º
                return await self.musicgen_engine.generate(
                    prompt=prompt,
                    duration=duration,
                    temperature=0.8,
                    genre_hint=genre_hint
                )
        
        except Exception as e:
            self.logger.error(f"MusicGen —Ñ–æ–ª–ª–±–µ–∫ –æ—à–∏–±–∫–∞: {e}")
            return self._generate_emergency_audio(duration)
    
    async def _generate_long_track_chunks(self, prompt: str, duration: int, genre_hint: Optional[str]) -> bytes:
        """
        üß© –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –ø–æ —á–∞—Å—Ç—è–º
        """
        chunk_duration = 25  # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ 25 —Å–µ–∫—É–Ω–¥
        chunks = []
        
        structure_parts = [
            ("intro", 0.3),
            ("buildup", 0.6),
            ("main", 0.9),
            ("breakdown", 0.5),
            ("outro", 0.3)
        ]
        
        current_time = 0
        part_index = 0
        
        while current_time < duration:
            remaining_time = duration - current_time
            current_chunk_duration = min(chunk_duration, remaining_time)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            if part_index < len(structure_parts):
                part_name, energy = structure_parts[part_index]
                part_index = (part_index + 1) % len(structure_parts)
            else:
                part_name, energy = "main", 0.8
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–π —á–∞—Å—Ç–∏
            chunk_prompt = f"{prompt}, {part_name} section, energy level {energy}"
            if genre_hint:
                chunk_prompt += f", {genre_hint} style"
            
            try:
                chunk_bytes = await self.musicgen_engine.generate(
                    prompt=chunk_prompt,
                    duration=current_chunk_duration,
                    temperature=0.7,
                    genre_hint=genre_hint
                )
                
                chunks.append(chunk_bytes)
                current_time += current_chunk_duration
                
                self.logger.info(f"üìä –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —á–∞–Ω–∫ {len(chunks)}: {current_chunk_duration}—Å ({part_name})")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–∞–Ω–∫–∞: {e}")
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏—à–∏–Ω—É –≤–º–µ—Å—Ç–æ –ø—Ä–æ–ø–∞–≤—à–µ–≥–æ —á–∞–Ω–∫–∞
                silence_chunk = self._generate_silence_chunk(current_chunk_duration)
                chunks.append(silence_chunk)
                current_time += current_chunk_duration
        
        # –°–∫–ª–µ–∏–≤–∞–µ–º —á–∞–Ω–∫–∏
        return self._concatenate_audio_chunks(chunks)
    
    def _generate_silence_chunk(self, duration: int) -> bytes:
        """
        üîá –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–∏—à–∏–Ω—ã –Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏
        """
        sample_rate = getattr(self.musicgen_engine.model, "sample_rate", 44100)
        silence = np.zeros(int(duration * sample_rate), dtype=np.float32)
        
        buffer = io.BytesIO()
        sf.write(buffer, silence, sample_rate, format='WAV')
        return buffer.getvalue()
    
    def _concatenate_audio_chunks(self, chunks: List[bytes]) -> bytes:
        """
        üîó –°–∫–ª–µ–∏–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ —á–∞–Ω–∫–æ–≤
        """
        try:
            audio_segments = []
            
            for chunk in chunks:
                if chunk:
                    segment = AudioSegment.from_file(io.BytesIO(chunk), format="wav")
                    audio_segments.append(segment)
            
            if not audio_segments:
                return self._generate_emergency_audio(30)
            
            # –°–∫–ª–µ–∏–≤–∞–µ–º —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –∫—Ä–æ—Å—Å—Ñ–µ–π–¥–∞–º–∏
            final_audio = audio_segments[0]
            
            for segment in audio_segments[1:]:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–æ—Å—Å—Ñ–µ–π–¥ 100–º—Å
                final_audio = final_audio.append(segment, crossfade=100)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            buffer = io.BytesIO()
            final_audio.export(buffer, format="wav")
            return buffer.getvalue()
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–ª–µ–∏–≤–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤: {e}")
            return self._generate_emergency_audio(30)
    
    def _numpy_to_audiosegment(self, audio: np.ndarray, sample_rate: int) -> Optional[AudioSegment]:
        """
        üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è numpy array –≤ AudioSegment
        """
        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ 16-bit int
            if audio.dtype != np.int16:
                audio_16bit = (audio * 32767).astype(np.int16)
            else:
                audio_16bit = audio
            
            # –°–æ–∑–¥–∞–µ–º AudioSegment
            return AudioSegment(
                audio_16bit.tobytes(),
                frame_rate=sample_rate,
                sample_width=2,  # 16-bit
                channels=1
            )
        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ numpy->AudioSegment: {e}")
            return None
    
    def _audiosegment_to_numpy(self, audio_segment: AudioSegment) -> np.ndarray:
        """
        üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è AudioSegment –≤ numpy array
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ –µ—Å–ª–∏ —Å—Ç–µ—Ä–µ–æ
            if audio_segment.channels > 1:
                audio_segment = audio_segment.set_channels(1)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
            raw_data = audio_segment.raw_data
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
            audio_array = np.frombuffer(raw_data, dtype=np.int16)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ float32
            return audio_array.astype(np.float32) / 32767.0
        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ AudioSegment->numpy: {e}")
            return np.zeros(44100, dtype=np.float32)  # 1 —Å–µ–∫—É–Ω–¥–∞ —Ç–∏—à–∏–Ω—ã
    
    def _bytes_to_numpy(self, audio_bytes: bytes, sample_rate: int) -> Optional[np.ndarray]:
        """
        üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bytes –≤ numpy array
        """
        try:
            buffer = io.BytesIO(audio_bytes)
            audio_array, _ = sf.read(buffer)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –º–æ–Ω–æ –µ—Å–ª–∏ —Å—Ç–µ—Ä–µ–æ
            if len(audio_array.shape) > 1:
                audio_array = np.mean(audio_array, axis=1)
            
            return audio_array.astype(np.float32)
        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ bytes->numpy: {e}")
            return None
    
    def _convert_to_bytes(self, audio: np.ndarray) -> bytes:
        """
        üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è numpy array –≤ bytes
        """
        try:
            sample_rate = getattr(self.musicgen_engine.model, "sample_rate", 44100)
            
            buffer = io.BytesIO()
            sf.write(buffer, audio, sample_rate, format='WAV')
            return buffer.getvalue()
        
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ bytes: {e}")
            return self._generate_emergency_audio(30)
    
    def _generate_emergency_audio(self, duration: int) -> bytes:
        """
        üö® –ê–í–ê–†–ò–ô–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ
        """
        self.logger.warning(f"üö® –ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è {duration} —Å–µ–∫—É–Ω–¥")
        
        try:
            sample_rate = 44100
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # –ü—Ä–æ—Å—Ç–æ–π –º–∏–∫—Å —á–∞—Å—Ç–æ—Ç –¥–ª—è –Ω–µ –ø–æ–ª–Ω–æ–π —Ç–∏—à–∏–Ω—ã
            audio_array = (
                np.sin(2 * np.pi * 80 * t) * 0.2 +   # –ù–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
                np.sin(2 * np.pi * 200 * t) * 0.15 + # –°—Ä–µ–¥–Ω–∏–µ
                np.random.normal(0, 0.05, len(t))    # –ù–µ–º–Ω–æ–≥–æ —à—É–º–∞
            ) * 0.3
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–µ–π–¥—ã
            fade_samples = sample_rate // 10  # 0.1 —Å–µ–∫
            if len(audio_array) > 2 * fade_samples:
                # Fade in
                audio_array[:fade_samples] *= np.linspace(0, 1, fade_samples)
                # Fade out
                audio_array[-fade_samples:] *= np.linspace(1, 0, fade_samples)
            
            buffer = io.BytesIO()
            sf.write(buffer, audio_array, sample_rate, format='WAV')
            return buffer.getvalue()
        
        except Exception as e:
            self.logger.error(f"‚ùå –ê–≤–∞—Ä–∏–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑–µ—Ä–≤ - –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ç–∏—à–∏–Ω–∞
            silence = np.zeros(int(44100 * min(duration, 10)))
            buffer = io.BytesIO()
            sf.write(buffer, silence, 44100, format='WAV')
            return buffer.getvalue()

# ============================================================================
# –ò–ù–¢–ï–†–§–ï–ô–°–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
# ============================================================================

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
_generator_instance = None

def get_generator():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (—Å–∏–Ω–≥–ª—Ç–æ–Ω)"""
    global _generator_instance
    if _generator_instance is None:
        _generator_instance = FixedSampleGenerator()
    return _generator_instance

def generate_with_specific_sample(
    prompt: Optional[str] = None,
    sample_waveform: Optional[np.ndarray] = None,
    duration: Optional[int] = None,
    genre_hint: Optional[str] = None
) -> bytes:
    """
    üî• –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–∏—Å–∫–æ–º
    
    –û—Å–Ω–æ–≤–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:
    ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–º–ø—Ç–∞ –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    ‚úÖ MusicGen –∫–∞–∫ —Ñ–æ–ª–ª–±–µ–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ EQ –æ—à–∏–±–∫–∞ —Å AudioSegment
    ‚úÖ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –∏–∑ JSON –±–∞–∑—ã
    ‚úÖ –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
    """
    generator = get_generator()
    return generator.generate_with_specific_sample(prompt, sample_waveform, duration, genre_hint)

# ============================================================================
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

async def test_fixed_generator():
    """
    üß™ –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
    """
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä")
    
    generator = FixedSampleGenerator()
    
    # –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
    test_prompts = [
        "trap track at 142 BPM with dark 808s and aggressive snares",
        "chill lofi beat with piano and soft drums around 80 bpm",
        "energetic drum and bass with heavy reese bass at 174 bpm"
    ]
    
    for prompt in test_prompts:
        print(f"\nüìù –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç: '{prompt}'")
        components = generator._parse_prompt_semantically(prompt)
        print(f"üß† –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {components}")
        
        # –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        results = generator._smart_semantic_search(prompt)
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Å—ç–º–ø–ª–æ–≤: {len(results)}")
        
        if results:
            print("üéØ –¢–æ–ø-3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
            for i, result in enumerate(results[:3], 1):
                print(f"  {i}. {result['filename']} (—Å–∫–æ—Ä: {result['score']:.3f})")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_fixed_generator())

    # ----------------------
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    # ----------------------
    if duration is None:
        try:
            duration = int(input("‚è±Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç—Ä–µ–∫–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (5-6000): "))
        except Exception:
            duration = 190
    target_sec = max(5, min(6000, duration))

    if sample_waveform is None:
        try:
            # –í–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–±–æ—Ç—ã
            print("\nüéõÔ∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
            print("1. üîç –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é")
            print("2. üìã –í—ã–±—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å—ç–º–ø–ª –∏–∑ –±–∞–∑—ã")
            print("3. üé≤ –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä")

            mode = input("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º (1-3): ").strip()

            if mode == "2":
                # –†–µ–∂–∏–º –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞
                selected_sample, sample_waveform = self._interactive_sample_selection()
                if not selected_sample:
                    return self._generate_emergency_audio(target_sec)

            elif mode == "3":
                # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä
                import random
                if self.samples_index:
                    selected_sample = random.choice(self.samples_index)
                    sample_waveform = self._load_sample_audio(selected_sample.path)
                    print(f"üé≤ –°–ª—É—á–∞–π–Ω–æ –≤—ã–±—Ä–∞–Ω: {selected_sample.filename}")
                else:
                    return self._generate_emergency_audio(target_sec)
            else:
                # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
                prompt = prompt or input("üìù –û–ø–∏—à–∏—Ç–µ –∂–µ–ª–∞–µ–º—ã–π —Ç—Ä–µ–∫: ").strip()
                if not prompt:
                    print("‚ùå –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
                    return self._generate_emergency_audio(target_sec)

                # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥
                selected_samples = self._smart_semantic_search(prompt, genre_hint)

                if not selected_samples:
                    print("‚ùå –ü–æ–¥—Ö–æ–¥—è—â–∏–µ —Å—ç–º–ø–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º MusicGen")
                    return await self._generate_with_musicgen_fallback(prompt, target_sec, genre_hint)

                # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö
                selected_sample, sample_waveform = self._choose_from_search_results(selected_samples)

        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∞ —Å—ç–º–ø–ª–∞: {e}")
            return self._generate_emergency_audio(target_sec)

    # ----------------------
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Å—ç–º–ø–ª–æ–º
    # ----------------------
    try:
        # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ç–º–ø–ª–∞
        generated_audio = await self._create_full_track_from_sample(
            sample_waveform,
            selected_sample,
            prompt,
            target_sec,
            genre_hint
        )

        self.logger.info("‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        return generated_audio

    except Exception as e:
        self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return self._generate_emergency_audio(target_sec)

    
    def _smart_semantic_search(self, prompt: str, genre_hint: Optional[str] = None) -> List[Dict]:
        """
        üß† –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —É–º–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º –ø—Ä–æ–º–ø—Ç–∞
        """
        self.logger.info(f"üîç –£–º–Ω—ã–π –ø–æ–∏—Å–∫: '{prompt}'")
        
        # –ü–∞—Ä—Å–∏–º –ø—Ä–æ–º–ø—Ç –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        parsed_components = self._parse_prompt_semantically(prompt)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∂–∞–Ω—Ä
        detected_genre = genre_hint or parsed_components.get('genre') or self._detect_genre_from_prompt(prompt)
        
        # –ò—â–µ–º —Å—ç–º–ø–ª—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        search_results = asyncio.run(self.sample_engine.find_samples(
            tags=parsed_components.get('tags', []),
            instruments=parsed_components.get('instruments', []),
            genre=detected_genre,
            bpm=parsed_components.get('bpm'),
            energy=parsed_components.get('energy', 0.5),
            max_results=15
        ))
        
        if search_results:
            self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(search_results)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å—ç–º–ø–ª–æ–≤")
        else:
            self.logger.warning("‚ö†Ô∏è –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
        return search_results
    
    def _parse_prompt_semantically(self, prompt: str) -> Dict[str, Any]:
        """
        üìù –ü–†–ê–í–ò–õ–¨–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–º–ø—Ç–∞ –Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        """
        components = {
            'tags': [],
            'instruments': [],
            'bpm': None,
            'genre': None,
            'energy': 0.5,
            'mood': []
        }
        
        prompt_lower = prompt.lower()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º BPM
        bpm_patterns = [
            r'(\d{2,3})\s*bpm',
            r'(\d{2,3})\s*beats',
            r'tempo[\s]*(\d{2,3})'
        ]
        
        for pattern in bpm_patterns:
            match = re.search(pattern, prompt_lower)
            if match:
                bpm = int(match.group(1))
                if 60 <= bpm <= 200:
                    components['bpm'] = bpm
                    break
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        instrument_keywords = {
            'kick': ['kick', 'bd', 'bass drum', 'thump'],
            'snare': ['snare', 'crack', 'snap'],
            'hihat': ['hihat', 'hat', 'hh', 'cymbal'],
            'bass': ['bass', 'sub', '808', 'low end'],
            'lead': ['lead', 'melody', 'synth', 'main'],
            'pad': ['pad', 'strings', 'atmosphere'],
            'vocal': ['vocal', 'voice', 'singing'],
            'piano': ['piano', 'keys'],
            'bell': ['bell', 'chime'],
            'fx': ['effect', 'fx', 'sound effect']
        }
        
        for instrument, keywords in instrument_keywords.items():
            if any(kw in prompt_lower for kw in keywords):
                components['instruments'].append(instrument)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏/–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        mood_keywords = {
            'dark': ['dark', 'noir', 'shadow', 'mysterious'],
            'aggressive': ['aggressive', 'hard', 'heavy', 'intense'],
            'energetic': ['energetic', 'high', 'powerful', 'dynamic'],
            'calm': ['calm', 'chill', 'peaceful', 'relax'],
            'complex': ['complex', 'intricate', 'layered'],
            'melodic': ['melodic', 'harmonic', 'musical'],
            'atmospheric': ['atmospheric', 'ambient', 'spacious'],
            'rhythmic': ['rhythmic', 'groove', 'beat']
        }
        
        for tag, keywords in mood_keywords.items():
            if any(kw in prompt_lower for kw in keywords):
                components['tags'].append(tag)
                components['mood'].append(tag)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —ç–Ω–µ—Ä–≥–∏–∏
        if any(word in prompt_lower for word in ['high', 'energetic', 'intense', 'aggressive']):
            components['energy'] = 0.8
        elif any(word in prompt_lower for word in ['calm', 'chill', 'peaceful', 'soft']):
            components['energy'] = 0.3
        elif any(word in prompt_lower for word in ['medium', 'moderate', 'balanced']):
            components['energy'] = 0.5
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∂–∞–Ω—Ä
        genre_keywords = {
            'trap': ['trap', '808', 'urban'],
            'drill': ['drill', 'uk drill', 'sliding'],
            'lofi': ['lofi', 'chill', 'vintage', 'cozy'],
            'dnb': ['dnb', 'drum and bass', 'jungle'],
            'house': ['house', 'dance', 'four on floor'],
            'techno': ['techno', 'minimal', 'warehouse'],
            'ambient': ['ambient', 'atmospheric', 'meditation']
        }
        
        for genre, keywords in genre_keywords.items():
            if any(kw in prompt_lower for kw in keywords):
                components['genre'] = genre
                break
        
        self.logger.debug(f"üìä –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {components}")
        return components
    
    def _interactive_sample_selection(self) -> Tuple[Optional[Any], Optional[np.ndarray]]:
        """
        üìã –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –∏–∑ –±–∞–∑—ã
        """
        if not self.samples_index:
            print("‚ùå –ë–∞–∑–∞ —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç–∞!")
            return None, None
        
        print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω–æ —Å—ç–º–ø–ª–æ–≤: {len(self.samples_index)}")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
        print("\nüéõÔ∏è –§–∏–ª—å—Ç—Ä –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞):")
        instruments = set()
        for sample in self.samples_index:
            if sample.instrument_role:
                instruments.add(sample.instrument_role)
        
        for i, instr in enumerate(sorted(instruments), 1):
            print(f"{i}. {instr}")
        
        filter_choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (–Ω–æ–º–µ—Ä –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ): ").strip()
        
        filtered_samples = self.samples_index
        if filter_choice:
            if filter_choice.isdigit():
                idx = int(filter_choice) - 1
                if 0 <= idx < len(instruments):
                    target_instrument = list(sorted(instruments))[idx]
                    filtered_samples = [s for s in self.samples_index if s.instrument_role == target_instrument]
            else:
                filtered_samples = [s for s in self.samples_index 
                                   if filter_choice.lower() in (s.instrument_role or "").lower()]
        
        if not filtered_samples:
            print("‚ùå –ù–µ—Ç —Å—ç–º–ø–ª–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä—É")
            return None, None
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã
        print(f"\nüìã –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—ç–º–ø–ª—ã ({len(filtered_samples)}):")
        for i, sample in enumerate(filtered_samples[:20], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
            duration_str = f"{sample.duration:.1f}—Å" if sample.duration else "N/A"
            instrument_str = sample.instrument_role or "unknown"
            tempo_str = f"{sample.tempo}bpm" if sample.tempo else "N/A"
            
            print(f"{i:2d}. {sample.filename[:50]}... | {instrument_str} | {tempo_str} | {duration_str}")
        
        if len(filtered_samples) > 20:
            print(f"... –∏ –µ—â–µ {len(filtered_samples) - 20} —Å—ç–º–ø–ª–æ–≤")
        
        # –í—ã–±–æ—Ä —Å—ç–º–ø–ª–∞
        try:
            choice = int(input(f"\n–í—ã–±–µ—Ä–∏—Ç–µ —Å—ç–º–ø–ª (1-{min(20, len(filtered_samples))}): ")) - 1
            if 0 <= choice < len(filtered_samples):
                selected_sample = filtered_samples[choice]
                sample_waveform = self._load_sample_audio(selected_sample.path)
                
                if sample_waveform is not None:
                    print(f"‚úÖ –í—ã–±—Ä–∞–Ω: {selected_sample.filename}")
                    return selected_sample, sample_waveform
                else:
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ: {selected_sample.path}")
                    return None, None
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä")
                return None, None
                
        except (ValueError, IndexError):
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥")
            return None, None
    
    def _choose_from_search_results(self, search_results: List[Dict]) -> Tuple[Optional[Any], Optional[np.ndarray]]:
        """
        üéØ –í—ã–±–æ—Ä –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        """
        if not search_results:
            return None, None
        
        print(f"\nüéØ –ù–∞–π–¥–µ–Ω–æ {len(search_results)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å—ç–º–ø–ª–æ–≤:")
        
        for i, result in enumerate(search_results[:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10
            filename = result.get('filename', 'unknown')
            instrument = result.get('instrument_role', 'unknown')
            tempo = result.get('tempo', 'N/A')
            score = result.get('score', 0)
            
            print(f"{i:2d}. {filename[:40]}... | {instrument} | {tempo}bpm | —Å–∫–æ—Ä: {score:.3f}")
        
        try:
            choice = int(input(f"–í—ã–±–µ—Ä–∏—Ç–µ —Å—ç–º–ø–ª (1-{min(10, len(search_results))}): ")) - 1
            if 0 <= choice < len(search_results):
                result = search_results[choice]
                
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ–ª–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å—ç–º–ø–ª–∞
                selected_sample = None
                for sample in self.samples_index:
                    if sample.filename == result['filename']:
                        selected_sample = sample
                        break
                
                if selected_sample:
                    sample_waveform = self._load_sample_audio(selected_sample.path)
                    if sample_waveform is not None:
                        print(f"‚úÖ –í—ã–±—Ä–∞–Ω: {selected_sample.filename}")
                        return selected_sample, sample_waveform
                
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Å—ç–º–ø–ª")
                return None, None
            else:
                print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä")
                return None, None
                
        except (ValueError, IndexError):
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥")
            return None, None
    
    def _load_sample_audio(self, path: str) -> Optional[np.ndarray]:
        """
        üéµ –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ —Å—ç–º–ø–ª–∞
        """
        try:
            if not os.path.exists(path):
                self.logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
                return None
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ librosa –¥–ª—è numpy array
            sample_rate = getattr(self.musicgen_engine.model, "sample_rate", 44100)
            waveform, _ = librosa.load(path, sr=sample_rate)
            
            if len(waveform) == 0:
                self.logger.error(f"–ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ—Ñ–∞–π–ª: {path}")
                return None
            
            return waveform
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—É–¥–∏–æ {path}: {e}")
            return None
    
    async def _create_full_track_from_sample(
        self, 
        sample_waveform: np.ndarray,
        sample_metadata: Any,
        prompt: str,
        target_duration: int,
        genre_hint: Optional[str]
    ) -> bytes:
        """
        üéº –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ç–º–ø–ª–∞ —Å MusicGen –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ–º
        """
        self.logger.info(f"üéº –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç—Ä–µ–∫ –∏–∑ —Å—ç–º–ø–ª–∞: {sample_metadata.filename}")
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç—Ä–µ–∫–∞
            structure = self._create_track_structure(target_duration, genre_hint)
            
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –¥–æ—Ä–æ–∂–∫—É –∏–∑ —Å—ç–º–ø–ª–∞
            base_track = self._extend_sample_to_duration(sample_waveform, target_duration)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ MusicGen
            enhanced_track = await self._enhance_with_musicgen(
                base_track, sample_metadata, prompt, genre_hint, structure
            )
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ (–±–µ–∑ –æ—à–∏–±–∫–∏ EQ)
            final_track = await self._apply_fixed_effects(enhanced_track, sample_metadata, genre_hint)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
            return self._convert_to_bytes(final_track)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–µ–∫–∞: {e}")
            # –§–æ–ª–ª–±–µ–∫ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å—ç–º–ø–ª–∞
            extended = self._extend_sample_to_duration(sample_waveform, target_duration)
            return self._convert_to_bytes(extended)
    
    async def _enhance_with_musicgen(
        self,
        base_audio: np.ndarray,
        sample_metadata: Any,
        prompt: str,
        genre_hint: Optional[str],
        structure: Dict
    ) -> np.ndarray:
        """
        üéπ MusicGen –∫–∞–∫ —Ñ–æ–ª–ª–±–µ–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        """
        self.logger.info("üéπ –î–æ–±–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —á–µ—Ä–µ–∑ MusicGen")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è MusicGen –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–∞
            musicgen_prompt = self._create_musicgen_prompt(sample_metadata, prompt, genre_hint)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏
            segments_to_generate = [
                ("intro", 8, 0.3),
                ("buildup", 16, 0.6),
                ("breakdown", 12, 0.4)
            ]
            
            enhanced_audio = base_audio.copy()
            sample_rate = getattr(self.musicgen_engine.model, "sample_rate", 44100)
            
            for segment_type, duration, energy in segments_to_generate:
                try:
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç
                    segment_prompt = f"{musicgen_prompt}, {segment_type}, energy {energy}"
                    segment_bytes = await self.musicgen_engine.generate(
                        prompt=segment_prompt,
                        duration=duration,
                        temperature=0.7,
                        genre_hint=genre_hint
                    )
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
                    segment_audio = self._bytes_to_numpy(segment_bytes, sample_rate)
                    
                    if segment_audio is not None:
                        # –ú–∏–∫—à–∏—Ä—É–µ–º —Å –æ—Å–Ω–æ–≤–Ω–æ–π –¥–æ—Ä–æ–∂–∫–æ–π
                        enhanced_audio = self._mix_audio_segments(enhanced_audio, segment_audio, energy * 0.3)
                
                except Exception as e:
                    self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å {segment_type}: {e}")
                    continue
            
            return enhanced_audio
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ MusicGen –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
            return base_audio
    
    def _create_musicgen_prompt(self, sample_metadata: Any, original_prompt: str, genre_hint: Optional[str]) -> str:
        """
        üìù –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è MusicGen –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—ç–º–ø–ª–∞
        """
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—ç–º–ø–ª–µ
        parts = []
        
        if genre_hint:
            parts.append(genre_hint)
        elif sample_metadata.genres:
            parts.append(sample_metadata.genres[0])
        
        if sample_metadata.tempo and sample_metadata.tempo > 0:
            parts.append(f"{sample_metadata.tempo} bpm")
        
        if sample_metadata.instrument_role:
            parts.append(f"featuring {sample_metadata.instrument_role}")
        
        if sample_metadata.tags:
            parts.extend(sample_metadata.tags[:3])  # –ü–µ—Ä–≤—ã–µ 3 —Ç–µ–≥–∞
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        original_words = original_prompt.split()[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Å–ª–æ–≤
        parts.extend([word for word in original_words if len(word) > 3])
        
        prompt = ", ".join(parts[:8])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        return prompt
    
    async def _apply_fixed_effects(self, audio: np.ndarray, sample_metadata: Any, genre_hint: Optional[str]) -> np.ndarray:
        """
        üéõÔ∏è –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –±–µ–∑ –æ—à–∏–±–æ–∫ AudioSegment
        """
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ AudioSegment –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            sample_rate = getattr(self.musicgen_engine.model, "sample_rate", 44100)
            audio_segment = self._numpy_to_audiosegment(audio, sample_rate)
            
            if audio_segment is None:
                return audio
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô EQ (–±–µ–∑ –≤—ã—á–∏—Ç–∞–Ω–∏—è AudioSegment)
            processed = await self._apply_safe_eq(audio_segment, genre_hint)
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            processed = normalize(processed)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ numpy
            return self._audiosegment_to_numpy(processed)
            
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–æ–≤: {e}")
            return audio
    
    async def _apply_safe_eq(self, audio: AudioSegment, genre: Optional[str]) -> AudioSegment:
        """
        üéöÔ∏è –ë–ï–ó–û–ü–ê–°–ù–ê–Ø —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è EQ –±–µ–∑ –æ—à–∏–±–æ–∫ –≤—ã—á–∏—Ç–∞–Ω–∏—è
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è –∏ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è EQ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
            processed = audio
            
            if genre == "trap" or genre == "drill":
                # –£—Å–∏–ª–µ–Ω–∏–µ –±–∞—Å–æ–≤ –∏ –≤—ã—Å–æ–∫–∏—Ö –¥–ª—è trap/drill
                processed = processed.low_pass_filter(15000)
                processed = processed + 2  # –ù–µ–±–æ–ª—å—à–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ
                
            elif genre == "lofi":
                # –í–∏–Ω—Ç–∞–∂–Ω–æ–µ –∑–≤—É—á–∞–Ω–∏–µ –¥–ª—è lofi
                processed = processed.low_pass_filter(8000)
                processed = processed - 1  # –ù–µ–±–æ–ª—å—à–æ–µ –ø—Ä–∏–≥–ª—É—à–µ–Ω–∏–µ
                
            elif genre == "dnb":
                # –ß–µ—Ç–∫–æ—Å—Ç—å –¥–ª—è DNB
                processed = processed.high_pass_filter(30)
                
            return processed
            
        except Exception as e:
            self.logger.warning(f"EQ –æ—à–∏–±–∫–∞: {e}")
            return audio
    
    def _extend_sample_to_duration(self, sample_waveform: np.ndarray, target_duration: int) -> np.ndarray:
        """
        ‚è∞ –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å—ç–º–ø–ª–∞ –¥–æ –Ω—É–∂–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        sample_rate = getattr(self.musicgen_engine.model, "sample_rate", 44100)
        target_samples = int(target_duration * sample_rate)
        current_samples = len(sample_waveform)
        
        if current_samples >= target_samples:
            # –û–±—Ä–µ–∑–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            return sample_waveform[:target_samples]
        else:
            # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º —Å —Ñ–µ–π–¥–∞–º–∏ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
            repetitions_needed = (target_samples // current_samples) + 1
            
            extended = np.tile(sample_waveform, repetitions_needed)
            extended = extended[:target_samples]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–µ–π–¥—ã –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏ –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
            fade_samples = min(sample_rate // 10, current_samples // 10)  # 0.1 —Å–µ–∫ —Ñ–µ–π–¥
            
            for i in range(1, repetitions_needed):
                start_idx = i * current_samples
                end_idx = min(start_idx + fade_samples, len(extended))
                
                if start_idx < len(extended):
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º crossfade
                    fade_in = np.linspace(0, 1, end_idx - start_idx)
                    fade_out = np.linspace(1, 0, end_idx - start_idx)
                    
                    if start_idx > fade_samples:
                        extended[start_idx - fade_samples:start_idx] *= fade_out
                    extended[start_idx:end_idx] *= fade_in
            
            return
    
    def _show_sample_statistics(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞"""
        print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –î–í–ò–ñ–ö–ê")
        print("-" * 40)
        
        try:
            engine = self.pipeline.sample_engine
            
            print(f"üìÇ –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {len(engine.samples_index)}")
            
            if engine.samples_index:
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                by_instrument = {}
                by_genre = {}
                total_duration = 0
                
                for sample in engine.samples_index:
                    # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
                    instrument = sample.instrument_role or "unknown"
                    by_instrument[instrument] = by_instrument.get(instrument, 0) + 1
                    
                    # –ñ–∞–Ω—Ä—ã
                    for genre in sample.genres:
                        by_genre[genre] = by_genre.get(genre, 0) + 1
                    
                    # –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    total_duration += sample.duration
                
                print(f"‚è±Ô∏è –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_duration/60:.1f} –º–∏–Ω—É—Ç")
                
                print(f"\nüéõÔ∏è –ü–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º:")
                for instrument, count in sorted(by_instrument.items(), key=lambda x: x[1], reverse=True)[:10]:
                    print(f"  - {instrument}: {count} —Å—ç–º–ø–ª–æ–≤")
                
                if by_genre:
                    print(f"\nüé≠ –ü–æ –∂–∞–Ω—Ä–∞–º:")
                    for genre, count in sorted(by_genre.items(), key=lambda x: x[1], reverse=True)[:10]:
                        print(f"  - {genre}: {count} —Å—ç–º–ø–ª–æ–≤")
                
                # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å
                if engine.semantic_model:
                    print(f"\nüß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å: ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞")
                else:
                    print(f"\nüß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å: ‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –±–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫)")
                
                # –¢–µ—Å—Ç –ø–æ–∏—Å–∫–∞
                print(f"\nüîç –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
                test_result = asyncio.run(engine.find_samples(
                    tags=["trap", "dark"],
                    instruments=["kick", "snare"],
                    genre="trap",
                    bpm=140,
                    max_results=3
                ))
                
                print(f"  –ù–∞–π–¥–µ–Ω–æ: {len(test_result)} —Å—ç–º–ø–ª–æ–≤")
                for i, sample in enumerate(test_result, 1):
                    print(f"    {i}. {sample.get('filename', 'unknown')} "
                          f"(—Å–∫–æ—Ä: {sample.get('score', 0):.2f})")
            
            else:
                print("‚ùå –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç!")
                print("‚ùå –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª 'sample_index ‚Äî –∫–æ–ø–∏—è2025.08.json' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                print("‚ùå –ò–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª sample_index.json —Å –≤–∞—à–∏–º–∏ —Å—ç–º–ø–ª–∞–º–∏")
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")
    
    def _test_systems(self):
        """–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º"""
        print("\nüîß –¢–ï–°–¢ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–• –°–ò–°–¢–ï–ú")
        print("-" * 30)
        
        # –¢–µ—Å—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞
        print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫...")
        try:
            engine = self.pipeline.sample_engine
            sample_count = len(engine.samples_index)
            print(f"  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {sample_count} –†–ï–ê–õ–¨–ù–´–• —Å—ç–º–ø–ª–æ–≤")
            
            if sample_count == 0:
                print("  ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –ø—É—Å—Ç!")
                print("  ‚ùå –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª sample_index.json —Å –≤–∞—à–∏–º–∏ —Å—ç–º–ø–ª–∞–º–∏")
            
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞: {e}")
        
        # –¢–µ—Å—Ç MusicGen
        print("\nüéº –¢–µ—Å—Ç–∏—Ä—É–µ–º MusicGen...")
        try:
            engine = self.pipeline.musicgen_engine
            if engine.model:
                print("  ‚úÖ MusicGen –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞")
            else:
                print("  ‚ö†Ô∏è MusicGen –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback)")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ MusicGen: {e}")
        
        # –¢–µ—Å—Ç –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞
        print("\nüéõÔ∏è –¢–µ—Å—Ç–∏—Ä—É–µ–º –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –º–∞—Å—Ç–µ—Ä–∏–Ω–≥...")
        try:
            engine = self.pipeline.mastering_engine
            print("  ‚úÖ –ú–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–≤–∏–∂–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            print("  ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ 'AudioSegment objects can't be subtracted'")
            print("  ‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞: {e}")
        
        # –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        print("\nüß™ –¢–µ—Å—Ç –ø—Ä–æ—Å—Ç–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
        try:
            test_request = GenerationRequest(
                prompt="test electronic beat",
                duration=10,  # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ—Å—Ç
                mastering_purpose="freelance",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                output_dir="test_output"
            )
            
            print("  üéµ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç—Ä–µ–∫...")
            result = self.generate_track_sync(test_request)
            
            if result and result.success:
                print(f"  ‚úÖ –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –£–°–ü–ï–®–ï–ù!")
                print(f"  üìÅ –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {result.final_path}")
                print(f"  ‚è±Ô∏è –í—Ä–µ–º—è: {result.generation_time:.1f}—Å")
                print(f"  üéØ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.2f}/1.0")
                if result.used_samples:
                    print(f"  üéõÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Å—ç–º–ø–ª–æ–≤: {len(result.used_samples)}")
            else:
                print(f"  ‚ùå –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≤–∞–ª–µ–Ω: {result.error_message if result else '–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞'}")
        
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        
        print("\nüìã –°–í–û–î–ö–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
        print("‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã")
        print("‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏")
        print("‚úÖ –ú–∞—Å—Ç–µ—Ä–∏–Ω–≥ –¥–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ")
        print("‚úÖ –ù–æ–≤—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
        
        input("\nüîô –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –≤ –º–µ–Ω—é...")

# ============================================================================
# –¢–û–ß–ö–ê –í–•–û–î–ê - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø
# ============================================================================

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        print("üéµ –ó–∞–ø—É—Å–∫ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø")
        print("‚úÖ –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã")
        print("‚úÖ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ")
        print("‚úÖ –†–∞–±–æ—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏ –∏–∑ –≤–∞—à–µ–π –±–∞–∑—ã")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô launcher
        launcher = FixedWaveDreamLauncher()
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
        launcher.run_interactive_mode()
        
    except KeyboardInterrupt:
        print("\nüëã –í—ã—Ö–æ–¥ –ø–æ Ctrl+C")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()


# ============================================================================
# –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –£–¢–ò–õ–ò–¢–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° –°–≠–ú–ü–õ–ê–ú–ò
# ============================================================================

class SampleBrowserUtility:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π —Å—ç–º–ø–ª–æ–≤"""
    
    def __init__(self, sample_engine: FixedSemanticSampleEngine):
        self.sample_engine = sample_engine
        self.logger = logging.getLogger(__name__)
    
    def search_samples_by_criteria(self, **criteria):
        """–ü–æ–∏—Å–∫ —Å—ç–º–ø–ª–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
        results = []
        
        for sample in self.sample_engine.samples_index:
            match = True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É
            if 'instrument' in criteria:
                if not sample.instrument_role or criteria['instrument'].lower() not in sample.instrument_role.lower():
                    match = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∂–∞–Ω—Ä—É
            if 'genre' in criteria and match:
                if not any(criteria['genre'].lower() in genre.lower() for genre in sample.genres):
                    match = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ BPM –¥–∏–∞–ø–∞–∑–æ–Ω—É
            if 'bpm_min' in criteria and match:
                if sample.tempo < criteria['bmp_min']:  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm_min
                    match = False
                    
            if 'bpm_max' in criteria and match:
                if sample.tempo > criteria['bpm_max']:  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm_max
                    match = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            if 'min_quality' in criteria and match:
                if sample.quality_score < criteria['min_quality']:
                    match = False
            
            if match:
                results.append({
                    'filename': sample.filename,
                    'path': sample.path,
                    'instrument_role': sample.instrument_role,
                    'genres': sample.genres,
                    'tempo': sample.tempo,
                    'quality_score': sample.quality_score,
                    'duration': sample.duration,
                    'energy_level': sample.energy_level
                })
        
        return results
    
    def get_sample_recommendations(self, prompt: str, max_results: int = 5):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å—ç–º–ø–ª–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–º–ø—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        prompt_lower = prompt.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        keywords = prompt_lower.split()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∂–∞–Ω—Ä –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        detected_genre = None
        genres = ['trap', 'drill', 'lofi', 'dnb', 'house', 'techno', 'ambient', 'cinematic']
        for genre in genres:
            if genre in prompt_lower:
                detected_genre = genre
                break
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º BPM –∏–∑ –ø—Ä–æ–º–ø—Ç–∞
        detected_bpm = None
        bmp_match = re.search(r'(\d{2,3})\s*bpm', prompt_lower)  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm
        if bpm_match:
            detected_bpm = int(bpm_match.group(1))
        
        # –ü–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å—ç–º–ø–ª–æ–≤
        search_criteria = {}
        if detected_genre:
            search_criteria['genre'] = detected_genre
        
        if detected_bpm:
            search_criteria['bpm_min'] = detected_bpm - 10  # –ò–°–ü–†–ê–í–õ–ï–ù–û: bmp -> bpm
            search_criteria['bmp_max'] = detected_bpm + 10   # –ò–°–ü–†–ê–í–õ–ï–ù–û: bpm -> bpm
        
        recommendations = self.search_samples_by_criteria(**search_criteria)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        recommendations.sort(key=lambda x: x['quality_score'], reverse=True)
        
        return recommendations[:max_results]

def create_sample_index_from_directory(directory_path: str, output_file: str = "sample_index.json"):
    """
    –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ —Å—ç–º–ø–ª–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    –ù–û–í–û–ï: –ë—ã—Å—Ç—Ä–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞—à–µ–π –ø–∞–ø–∫–∏ —Å —Å—ç–º–ø–ª–∞–º–∏
    """
    print(f"üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {directory_path}")
    
    if not os.path.exists(directory_path):
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory_path}")
        return False
    
    samples_index = []
    audio_extensions = {'.wav', '.mp3', '.aif', '.aiff', '.flac', '.ogg', '.m4a'}
    
    processed_count = 0
    
    for root, dirs, files in os.walk(directory_path):
        for file in files:
            if any(file.lower().endswith(ext) for ext in audio_extensions):
                full_path = os.path.join(root, file)
                
                try:
                    # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞
                    audio = AudioSegment.from_file(full_path)
                    duration = len(audio) / 1000.0
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ/–¥–ª–∏–Ω–Ω—ã–µ
                    if duration < 0.1 or duration > 600:
                        continue
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º BPM –∏–∑ –∏–º–µ–Ω–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–û
                    tempo = 120  # –î–µ—Ñ–æ–ª—Ç
                    bpm_match = re.search(r'(\d{2,3})\s*bpm', file.lower())
                    if bpm_match:
                        found_bmp = int(bpm_match.group(1))
                        if 60 <= found_bpm <= 200:
                            tempo = found_bpm
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–∑ –∏–º–µ–Ω–∏
                    instrument_role = None
                    filename_lower = file.lower()
                    
                    instrument_keywords = {
                        'kick': ['kick', 'bd', 'bassdrum'],
                        'snare': ['snare', 'sd'],
                        'hihat': ['hihat', 'hh', 'hat'],
                        'bass': ['bass', 'sub', '808'],
                        'lead': ['lead', 'melody', 'synth'],
                        'pad': ['pad', 'chord'],
                        'vocal': ['vocal', 'voice']
                    }
                    
                    for instrument, keywords in instrument_keywords.items():
                        if any(kw in filename_lower for kw in keywords):
                            instrument_role = instrument
                            break
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–≥–∏
                    tags = []
                    if 'dark' in filename_lower or 'dark' in root.lower():
                        tags.append('dark')
                    if 'energetic' in filename_lower or 'energy' in filename_lower:
                        tags.append('energetic')
                    if 'chill' in filename_lower or 'calm' in filename_lower:
                        tags.append('calm')
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∂–∞–Ω—Ä –∏–∑ –ø—É—Ç–∏
                    genres = []
                    path_lower = full_path.lower()
                    genre_keywords = ['trap', 'drill', 'lofi', 'dnb', 'house', 'techno', 'ambient']
                    for genre in genre_keywords:
                        if genre in path_lower:
                            genres.append(genre)
                    
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å
                    sample_entry = {
                        "path": full_path,
                        "filename": file,
                        "duration": duration,
                        "tempo": tempo,
                        "key": None,
                        "tags": tags,
                        "genres": genres,
                        "instrument_role": instrument_role,
                        "quality_score": 0.6,
                        "energy_level": 1.0 if 'energetic' in tags else 0.5,
                        "spectral_centroid": 0.0,
                        "spectral_rolloff": 0.0,
                        "zero_crossing_rate": 0.0,
                        "brightness": 0.0,
                        "rhythmic_complexity": 0.0
                    }
                    
                    samples_index.append(sample_entry)
                    processed_count += 1
                    
                    if processed_count % 50 == 0:
                        print(f"  üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} —Ñ–∞–π–ª–æ–≤")
                
                except Exception as e:
                    print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file}: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(samples_index, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤: {output_file}")
        print(f"üìä –í—Å–µ–≥–æ —Å—ç–º–ø–ª–æ–≤: {len(samples_index)}")
        return True
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞: {e}")
        return False

# ============================================================================
# –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢ –î–õ–Ø –ù–û–í–´–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô
# ============================================================================

def quick_start_wizard():
    """–ú–∞—Å—Ç–µ—Ä –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞"""
    print("""
üåü –ë–´–°–¢–†–´–ô –°–¢–ê–†–¢ WaveDream Enhanced Pro v2.1

–≠—Ç–æ—Ç –º–∞—Å—Ç–µ—Ä –ø–æ–º–æ–∂–µ—Ç —Å–æ–∑–¥–∞—Ç—å –≤–∞—à –ø–µ—Ä–≤—ã–π —Ç—Ä–µ–∫ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º.
–í—Å–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã, —Å–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!
    """)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–µ–∫—Å–∞ —Å—ç–º–ø–ª–æ–≤
    index_files = [
        "sample_index ‚Äî –∫–æ–ø–∏—è2025.08.json",
        "sample_index.json"
    ]
    
    index_found = False
    for index_file in index_files:
        if os.path.exists(index_file):
            index_found = True
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤: {index_file}")
            break
    
    if not index_found:
        print("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        create_index = input("–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Å—ç–º–ø–ª–∞–º–∏? (y/N): ").lower()
        
        if create_index == 'y':
            sample_dir = input("–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Å—ç–º–ø–ª–∞–º–∏: ").strip()
            if sample_dir and os.path.exists(sample_dir):
                if create_sample_index_from_directory(sample_dir):
                    print("‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω!")
                else:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å")
                    return
            else:
                print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤—ã—Ö–æ–¥ –∏–∑ –º–∞—Å—Ç–µ—Ä–∞")
                return
    
    # –ü—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    print("\nüìù –°–æ–∑–¥–∞–µ–º –≤–∞—à –ø–µ—Ä–≤—ã–π —Ç—Ä–µ–∫:")
    
    music_prompt = input("–ö–∞–∫—É—é –º—É–∑—ã–∫—É —Ö–æ—Ç–∏—Ç–µ? (–Ω–∞–ø—Ä–∏–º–µ—Ä: 'Melodic & Rhytmic 140-180 bpm'): ").strip()
    if not music_prompt:
        music_prompt = "electronic music"
    
    duration_input = input("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (Enter=300): ").strip()
    try:
        duration = int(duration_input) if duration_input else 300
        duration = max(10, min(6000, duration))
    except ValueError:
        duration = 300
    
    print(f"\nüöÄ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç—Ä–µ–∫ —Å –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ú –ö–ê–ß–ï–°–¢–í–û–ú:")
    print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: '{music_prompt}'")
    print(f"‚è∞ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}—Å")
    print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï (–∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ)")
    print("üéõÔ∏è –ü–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å—ç–º–ø–ª–æ–≤ –≤ –≤–∞—à–µ–π –±–∞–∑–µ...")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    try:
        launcher = FixedWaveDreamLauncher()
        
        request = GenerationRequest(
            prompt=music_prompt,
            duration=duration,
            mastering_purpose="freelance",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            output_dir="quick_start_output",
            export_stems=True
        )
        
        print("\n‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...")
        
        result = launcher.generate_track_sync(request)
        
        if result and result.success:
            print(f"\nüéâ –í–ê–® –¢–†–ï–ö –ì–û–¢–û–í!")
            print(f"üìÅ –§–∞–π–ª: {result.final_path}")
            print(f"üéØ –ö–∞—á–µ—Å—Ç–≤–æ: {result.quality_score:.2f}/1.0 (–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û–ï)")
            print(f"‚è±Ô∏è –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è: {result.generation_time:.1f}—Å")
            
            if result.used_samples:
                print(f"üéõÔ∏è –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤: {len(result.used_samples)}")
                for sample in result.used_samples[:3]:
                    print(f"  - {sample.get('filename', 'unknown')}")
            
            print(f"\nüí° –°–æ–≤–µ—Ç: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π!")
            print(f"üí° –ù–æ–≤–æ–µ: –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å—ç–º–ø–ª—ã –¥–ª—è –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è!")
            
        else:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {result.error_message if result else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}")
            print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º")
            
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞: {e}")
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É")
# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--quick-start":
            quick_start_wizard()
        elif sys.argv[1] == "--create-index":
            if len(sys.argv) > 2:
                create_sample_index_from_directory(sys.argv[2])
            else:
                directory = input("–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Å—ç–º–ø–ª–∞–º–∏: ").strip()
                if directory:
                    create_sample_index_from_directory(directory)
        elif sys.argv[1] == "--help":
            print("""
üéµ WaveDream Enhanced Pro v2.1 - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–ò–°–¢–ï–ú–ê

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python dolbywallbe_FIXED.py                 # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
  python dolbywallbe_FIXED.py --quick-start   # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤
  python dolbywallbe_FIXED.py --create-index <dir>  # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å —Å—ç–º–ø–ª–æ–≤
  python dolbywallbe_FIXED.py --help          # –≠—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞

‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –í v2.1:
- –û—à–∏–±–∫–∞ "AudioSegment objects can't be subtracted from each other" 
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—ç–º–ø–ª–∞–º–∏
- –í—Å–µ –æ–ø–µ—á–∞—Ç–∫–∏ bmp->bpm –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –º–∞—Å—Ç–µ—Ä–∏–Ω–≥–∞ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–π
- –î–æ–±–∞–≤–ª–µ–Ω —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –≤—ã–±–æ—Ä–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
- –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞ –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ
- –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞ –±–µ–∑ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–æ–≤

üéØ –ù–û–í–´–ô –§–£–ù–ö–¶–ò–û–ù–ê–õ:
- –ü—Ä–æ—Å–º–æ—Ç—Ä –±–∞–∑—ã —Å—ç–º–ø–ª–æ–≤
- –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –¥–ª—è –º–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏—è  
- –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ –≤–∞—à–µ–π –ø–∞–ø–∫–∏ —Å —Å—ç–º–ø–ª–∞–º–∏
- –£–ª—É—á—à–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

üí™ –ö–ê–ß–ï–°–¢–í–û: –¢–æ–ª—å–∫–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ, –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–≤—É–∫–∞!
            """)
        else:
            main()
    else:
        main()
